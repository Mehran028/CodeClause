{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RBWbQnTMgEgJ","outputId":"156815ed-2ae3-41e0-b7f4-cdfea21fad9b","executionInfo":{"status":"ok","timestamp":1703786105670,"user_tz":-300,"elapsed":45018,"user":{"displayName":"Muhammad Mehran","userId":"12810853850038077088"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vftoH9wlgJVn","outputId":"5f133530-9f2a-4f28-86d2-1d23dbe12576","executionInfo":{"status":"ok","timestamp":1703786215396,"user_tz":-300,"elapsed":581,"user":{"displayName":"Muhammad Mehran","userId":"12810853850038077088"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8\n"]}],"source":["%cd /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"csjkn5abgKOC","outputId":"951db0d0-af46-48ed-e48e-fb3eb09ea245","executionInfo":{"status":"ok","timestamp":1703786227704,"user_tz":-300,"elapsed":7334,"user":{"displayName":"Muhammad Mehran","userId":"12810853850038077088"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.0.231-py3-none-any.whl (663 kB)\n","\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/663.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m204.8/663.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m573.4/663.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m663.2/663.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Collecting thop>=0.1.1 (from ultralytics)\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.46.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: thop, ultralytics\n","Successfully installed thop-0.1.1.post2209072238 ultralytics-8.0.231\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"markdown","source":["# **Training**"],"metadata":{"id":"k6Wp1iE-Fytt"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EHeJbOWCgKX9","outputId":"5840498c-a2eb-4370-aaa8-bf2fbca9845f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.0.231 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/gdrive/MyDrive/Dataset/PPEDETECTION.v4i.yolov8/data.yaml, epochs=300, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Overriding model.yaml nc=80 with nc=5\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n","Model summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/Dataset/PPEDETECTION.v4i.yolov8/train/labels.cache... 260 images, 6 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 260/260 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"]},{"output_type":"stream","name":"stderr","text":["\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/Dataset/PPEDETECTION.v4i.yolov8/valid/labels.cache... 74 images, 3 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74/74 [00:00<?, ?it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","300 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      1/300      4.61G      1.434      3.478      1.508         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:10<00:00,  1.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:03<00:00,  1.22s/it]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383     0.0211       0.24      0.183      0.124\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      2/300      4.45G      1.323      2.344      1.473         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.21it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383     0.0829      0.538      0.378      0.258\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      3/300      4.39G       1.23      1.881      1.381         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.863      0.309      0.445      0.298\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      4/300      4.39G      1.296      1.689      1.369         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.02it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.685      0.489      0.586      0.397\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      5/300      4.35G       1.28      1.639      1.359         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.82it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.541       0.44      0.485      0.323\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      6/300       4.4G      1.231      1.507      1.363         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.62it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.533      0.515      0.547      0.365\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      7/300      4.38G      1.247      1.452      1.346         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.769      0.415      0.499      0.307\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      8/300      4.49G      1.212      1.493       1.35         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.58it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.98it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.536      0.486      0.532      0.343\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["      9/300      4.34G      1.203      1.382      1.335         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.644      0.684       0.75      0.454\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     10/300      4.48G      1.218      1.406      1.364         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.644      0.694      0.713      0.434\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     11/300      4.46G      1.209      1.346      1.337         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.677      0.659      0.711      0.432\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     12/300      4.36G      1.297      1.399      1.382         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.544      0.724      0.664      0.434\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     13/300      4.45G      1.191       1.27      1.314         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.81it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.721       0.68      0.778      0.492\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     14/300      4.46G      1.206      1.296      1.332         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.676       0.71      0.722       0.46\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     15/300      4.46G      1.183      1.227      1.324         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.67it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.759      0.641      0.761      0.483\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     16/300      4.45G      1.119      1.216      1.276         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.724      0.678      0.757      0.497\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     17/300      4.34G      1.159      1.171      1.283         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.676       0.74      0.767      0.489\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     18/300      4.37G      1.139      1.175      1.273         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.712      0.765      0.777      0.508\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     19/300      4.48G       1.11      1.144      1.267         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.659      0.656      0.738      0.488\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     20/300      4.35G      1.155      1.223      1.303         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.687      0.734      0.777      0.485\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     21/300      4.34G      1.094      1.102      1.241         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.771      0.781      0.837      0.526\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     22/300      4.38G      1.144      1.115      1.271         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.721      0.736      0.787      0.484\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     23/300      4.47G      1.103      1.133      1.248         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.678      0.717      0.769      0.504\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     24/300      4.48G      1.085      1.056      1.238         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.66it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.764      0.692      0.788      0.535\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     25/300      4.42G      1.047     0.9848      1.222         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.16it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.707      0.611      0.706      0.443\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     26/300      4.46G      1.026     0.9795      1.204         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.791      0.656      0.726      0.491\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     27/300      4.37G      1.077      0.986      1.245         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.804       0.61      0.727      0.486\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     28/300      4.46G      1.058     0.9692      1.241         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.783      0.768      0.823      0.534\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     29/300      4.35G      1.031     0.9388      1.203         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.25it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.727      0.791      0.811       0.52\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     30/300      4.37G     0.9948     0.9247      1.199         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.717      0.787      0.792      0.528\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     31/300      4.46G     0.9966     0.9031      1.195         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.74      0.749      0.787      0.517\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     32/300      4.36G      1.021     0.9292      1.214         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.773      0.791      0.823      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     33/300      4.36G      1.012     0.8909      1.199         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.79it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.757      0.777      0.809      0.521\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     34/300      4.43G      1.003     0.9087      1.203         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.768      0.798       0.82      0.526\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     35/300      4.45G      1.013     0.9157       1.21         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.763      0.808      0.814       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     36/300      4.38G      1.021      0.877      1.203         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.77      0.739      0.793      0.508\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     37/300      4.35G      1.008      0.892      1.182         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.703      0.674      0.735       0.48\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     38/300      4.46G     0.9987     0.8872      1.179         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.772      0.756      0.822       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     39/300      4.36G      1.016     0.8585      1.195         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.766      0.813      0.839      0.549\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     40/300      4.46G      0.987     0.8311      1.182         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.811      0.791       0.85      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     41/300      4.47G     0.9918     0.8405      1.176         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.78      0.838      0.864       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     42/300      4.35G     0.9536     0.7873      1.174         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.787      0.842      0.845      0.556\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     43/300      4.49G      1.011     0.8565      1.216          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.801      0.842      0.845      0.544\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     44/300      4.49G     0.9979     0.8215      1.187         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.771      0.878      0.843      0.545\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     45/300      4.45G      1.002     0.8237      1.181         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.66it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.762      0.846      0.855      0.565\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     46/300      4.48G     0.9409     0.7601      1.153         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.784      0.824      0.855      0.561\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     47/300      4.47G     0.9656     0.8018      1.176         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.703      0.742      0.798      0.509\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     48/300      4.42G     0.9556     0.7868      1.138         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.762      0.813      0.826      0.563\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     49/300      4.47G     0.9398      0.772      1.167         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.20it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.819      0.813       0.84      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     50/300      4.46G     0.9608     0.7703       1.16         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.21it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.771      0.731      0.763      0.522\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     51/300      4.47G      0.942     0.7741      1.174         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.744      0.714      0.755      0.529\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     52/300      4.36G     0.9117     0.8005      1.145          7        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.815      0.624       0.73      0.482\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     53/300      4.36G      0.956     0.7707      1.167         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.831      0.635      0.733      0.504\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     54/300      4.38G     0.9509      0.727      1.147         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.81it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.803      0.679      0.745      0.489\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     55/300       4.4G     0.9177     0.7739      1.164         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.74it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.759      0.749      0.775      0.513\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     56/300      4.39G     0.9397     0.7376      1.136         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.791       0.81      0.826      0.551\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     57/300      4.34G     0.9272     0.7155      1.156         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.712      0.827      0.807      0.544\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     58/300      4.35G     0.9359      0.739      1.167         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:08<00:00,  1.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.748      0.789      0.817       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     59/300      4.39G     0.9258      0.747      1.146         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.744      0.738      0.788      0.523\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     60/300      4.36G      0.891     0.7153      1.135         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.744      0.749      0.804      0.541\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     61/300      4.46G     0.8904      0.691      1.133         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.779       0.89      0.859       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     62/300      4.38G     0.8742     0.6651      1.109         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.766      0.803      0.849      0.568\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     63/300      4.48G     0.8928     0.6854       1.13         50        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.772      0.794       0.84      0.564\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     64/300      4.48G     0.9189     0.7103      1.131         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.26it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.33it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.777      0.731      0.793      0.537\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     65/300      4.43G     0.8932     0.7034      1.123         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.779      0.712      0.787      0.526\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     66/300      4.46G      0.889     0.6982      1.107         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.742       0.85      0.835      0.564\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     67/300      4.48G     0.8875     0.6952      1.134         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.796      0.843      0.841      0.567\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     68/300      4.35G     0.8376     0.6467      1.104         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.812      0.759      0.818      0.539\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     69/300      4.41G      0.887      0.666      1.148          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.736      0.776      0.795      0.536\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     70/300      4.49G     0.8665     0.6713      1.113         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.65it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.763      0.816      0.836      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     71/300      4.48G     0.8911     0.7091      1.152         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.778      0.846      0.851       0.55\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     72/300      4.39G     0.8802     0.6697      1.135         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.793      0.789      0.825       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     73/300      4.47G     0.8868     0.6681      1.124         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.75      0.799      0.822       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     74/300       4.5G     0.8807     0.6327      1.092         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.73it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.77      0.823      0.842      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     75/300      4.47G      0.886     0.6647      1.116         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.24it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.774      0.792      0.831      0.549\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     76/300      4.47G      0.878     0.6428      1.115         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.821        0.8      0.856      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     77/300      4.35G     0.8714     0.6681      1.134         43        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.73it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.733      0.789      0.813      0.546\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     78/300      4.36G     0.8467     0.6137       1.08         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.79it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.808      0.771      0.804      0.531\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     79/300       4.4G      0.893     0.6805      1.135         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.81       0.75      0.807      0.525\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     80/300      4.47G     0.8464      0.688      1.129         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.75it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.783      0.774      0.824      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     81/300      4.35G     0.8256     0.6311      1.096         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.802      0.876      0.864      0.576\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     82/300      4.42G      0.839       0.62      1.085         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.826      0.819      0.843      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     83/300      4.47G     0.8089     0.5984      1.086         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.818      0.787      0.815      0.545\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     84/300      4.46G     0.8288      0.624      1.105         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.836      0.791      0.815      0.545\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     85/300      4.45G     0.8222     0.6134      1.102         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.04it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.79      0.804      0.831      0.552\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     86/300      4.49G     0.8548     0.6222      1.108         76        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.764      0.853      0.864       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     87/300      4.35G     0.8434     0.6125      1.095         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.81      0.802      0.857      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     88/300      4.49G     0.8186     0.6093      1.069         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.82it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.828      0.774      0.848      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     89/300      4.37G     0.8116     0.6168      1.092         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.837      0.777      0.821      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     90/300      4.48G     0.8384     0.6106      1.096         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.795      0.791        0.8      0.536\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     91/300      4.48G     0.8078     0.6026      1.058         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.92it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.823      0.759      0.795      0.533\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     92/300      4.49G     0.8387     0.5939      1.089         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.776       0.75      0.816      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     93/300      4.34G     0.8377     0.6006       1.09         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.86it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.79       0.82      0.832      0.561\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     94/300      4.48G     0.7908     0.5742      1.086         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.801      0.841      0.845       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     95/300      4.48G     0.8028     0.5911       1.09         40        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.831      0.723       0.81      0.534\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     96/300      4.35G     0.8608     0.6266      1.106         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.78it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.85      0.719      0.797      0.526\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     97/300      4.38G     0.8215     0.5893      1.071         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.55it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.796      0.805      0.829      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     98/300      4.39G     0.7968     0.5681      1.071         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.92it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.779      0.804      0.822      0.538\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["     99/300      4.36G     0.8114     0.5955       1.08         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.29it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.815      0.736      0.786      0.519\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    100/300      4.48G     0.7801     0.5717      1.058         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.837      0.685      0.758      0.495\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    101/300      4.47G     0.7942     0.5722      1.092         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.849      0.728      0.802      0.544\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    102/300      4.46G     0.7939     0.5911      1.099         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.873      0.746      0.838      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    103/300      4.49G     0.7729     0.5759      1.078         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.828      0.786      0.848      0.552\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    104/300      4.39G     0.8282     0.6105      1.091         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.83      0.752      0.811      0.527\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    105/300      4.48G     0.7686     0.5757      1.077         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.833      0.666      0.771      0.522\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    106/300      4.48G     0.7969      0.582       1.07         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.47it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.65it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.773      0.672      0.764      0.513\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    107/300      4.45G     0.8054     0.5681      1.076         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.23it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.777      0.774      0.789      0.528\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    108/300      4.42G     0.7917     0.5641      1.058         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.783      0.784      0.823      0.532\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    109/300      4.47G     0.7649     0.5762      1.075         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.786      0.795      0.842      0.552\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    110/300      4.37G     0.7972     0.6026      1.091         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.793      0.813      0.859       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    111/300      4.49G     0.7756     0.5467      1.064         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.99it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.82      0.789      0.858      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    112/300      4.35G     0.7589     0.5365      1.053         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.821        0.8      0.838      0.551\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    113/300      4.35G     0.7817     0.5633      1.066         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.822      0.793      0.842      0.552\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    114/300      4.48G     0.7696     0.5533      1.068         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.872      0.755      0.842      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    115/300      4.47G     0.7952     0.5722       1.08         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.792      0.756      0.806      0.555\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    116/300      4.35G     0.7958     0.5616      1.092         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.716      0.788      0.783      0.545\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    117/300      4.36G     0.7503     0.5648      1.081         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.44it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.781      0.789      0.826      0.555\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    118/300      4.49G     0.7837      0.558       1.07         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.789      0.817      0.847      0.559\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    119/300      4.48G     0.7512     0.5362      1.042         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.822      0.806      0.852      0.561\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    120/300      4.48G      0.771     0.5653      1.061         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.794      0.766      0.809      0.552\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    121/300      4.48G      0.749     0.5529       1.06         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.60it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.813      0.724      0.777      0.542\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    122/300      4.42G     0.7472     0.5356      1.058         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.795      0.772      0.803      0.559\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    123/300      4.49G     0.7509     0.5316      1.056         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.775       0.83      0.846      0.575\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    124/300      4.35G       0.76     0.5424      1.063         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.829      0.782       0.84      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    125/300      4.46G     0.7594     0.5534       1.07         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.68it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.42it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.801      0.825      0.852      0.568\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    126/300      4.49G     0.7208      0.514      1.042         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.59it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.791      0.817      0.857      0.576\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    127/300      4.45G     0.7708     0.5327      1.068         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.76it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.775      0.821      0.854      0.587\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    128/300      4.35G     0.7395     0.5282      1.043         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.775       0.82      0.853      0.585\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    129/300      4.48G     0.7316     0.4986      1.041         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.66it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.825      0.796      0.858      0.583\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    130/300      4.37G     0.7289     0.5227      1.058         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.32it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.804      0.828      0.852      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    131/300      4.48G      0.721      0.529      1.034         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.822      0.797      0.847      0.561\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    132/300      4.48G     0.7212     0.5195      1.041         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.824      0.867      0.885      0.584\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    133/300      4.45G     0.7509     0.5262      1.032         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.36it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.842      0.887      0.883      0.585\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    134/300      4.38G     0.7359     0.5278      1.058         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.37it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.828      0.869      0.872      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    135/300      4.47G     0.7206     0.5042      1.041         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.809      0.825      0.848      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    136/300      4.37G       0.74     0.5227      1.049         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.774      0.857      0.843       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    137/300      4.35G     0.7304     0.5149      1.043         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.799      0.863      0.856      0.569\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    138/300      4.46G     0.7099     0.5107      1.019         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.806      0.825      0.838      0.559\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    139/300      4.48G     0.7329     0.5149      1.044         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.825      0.796      0.831      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    140/300      4.48G     0.7143     0.5183      1.048         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.841      0.821      0.846      0.553\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    141/300      4.35G     0.7347     0.5077       1.04         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.801      0.843       0.84      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    142/300      4.46G     0.7225     0.5141      1.043         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.825      0.856      0.856      0.563\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    143/300      4.37G      0.727      0.496      1.033         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.63it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.47it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.83      0.869      0.869       0.58\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    144/300      4.47G     0.7218     0.5068      1.024         42        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.29it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.871      0.871      0.885       0.59\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    145/300      4.45G     0.7196     0.5097      1.042         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.60it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.846        0.9      0.878      0.579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    146/300      4.39G     0.7282     0.4985      1.029         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.801      0.846      0.852      0.565\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    147/300       4.5G     0.7247     0.4982      1.038         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.71it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.822      0.773      0.831       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    148/300      4.48G     0.7003     0.4932       1.04         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.761       0.81      0.832      0.558\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    149/300      4.45G     0.7571     0.5085      1.059         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.59it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.797      0.833      0.852      0.568\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    150/300      4.48G     0.7468     0.5094       1.05         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.822      0.865      0.859      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    151/300      4.46G     0.7213     0.4892      1.028         46        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.56it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.86      0.831      0.877      0.572\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    152/300      4.42G     0.7135     0.4992      1.025         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.863      0.787      0.863      0.575\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    153/300      4.34G     0.6837     0.4581      1.006         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.67it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.806       0.83      0.863      0.577\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    154/300      4.37G     0.6956     0.4941      1.031         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.813      0.818      0.848      0.562\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    155/300      4.36G     0.6958     0.5072      1.027         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.13it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.825      0.805      0.824       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    156/300      4.36G     0.6832     0.4603       1.01         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.816      0.788      0.825      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    157/300      4.47G      0.713     0.4957      1.048         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.33it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.805      0.811      0.832      0.568\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    158/300      4.49G     0.7228     0.4943      1.043          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.87it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.812      0.797      0.825       0.55\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    159/300      4.49G     0.6976     0.4689      1.024         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.876      0.771      0.816      0.542\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    160/300      4.48G     0.6867     0.4766      1.031         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.814      0.799      0.826      0.538\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    161/300      4.36G     0.6968     0.4776      1.018         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.40it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.817      0.795       0.82      0.547\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    162/300      4.37G     0.6768     0.4905      1.015         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.831        0.8      0.832      0.572\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    163/300      4.46G     0.6897      0.492      1.024         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.35it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.80it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.843      0.803      0.839      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    164/300      4.36G     0.6801     0.4791      1.025         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.93it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.838        0.8      0.839      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    165/300      4.46G     0.6743     0.4679      1.022         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.88it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.882      0.744      0.831      0.556\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    166/300      4.39G     0.6645     0.4633      1.013         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.45it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.843      0.733      0.825       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    167/300      4.45G     0.6736     0.4752      1.032          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.854      0.711      0.822      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    168/300      4.36G     0.6816     0.4761      1.029         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.775      0.748      0.831       0.55\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    169/300      4.48G      0.659     0.4618     0.9912         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.828      0.803      0.857      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    170/300      4.36G     0.6924     0.4684      1.028         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.25it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.08it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.845      0.798      0.862      0.577\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    171/300      4.36G     0.6671     0.4595       1.01         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.37it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.876      0.779      0.863      0.579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    172/300      4.49G     0.6822     0.4642      1.012         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.855      0.789      0.849      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    173/300      4.35G     0.6609     0.4704     0.9953         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.56it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.40it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.871       0.77      0.829      0.548\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    174/300      4.48G     0.6533     0.4644      1.008         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.816       0.78      0.823      0.535\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    175/300      4.48G      0.663     0.4443      1.014         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.802      0.794      0.827      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    176/300      4.43G     0.6527     0.4517     0.9763         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.18it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.63it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.813      0.774      0.839      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    177/300      4.45G     0.6607     0.4522     0.9951         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.15it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.29it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.785      0.802       0.84      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    178/300      4.49G     0.6256     0.4337     0.9924         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.61it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.824      0.765       0.83      0.549\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    179/300      4.48G     0.6495     0.4358      1.006         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.869      0.754      0.827      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    180/300      4.48G     0.6557     0.4482      1.002         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.46it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.829      0.774      0.834      0.546\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    181/300      4.42G     0.6502     0.4651      1.006         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.819      0.777       0.85       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    182/300      4.45G     0.6558      0.455      1.008         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.824      0.808       0.86      0.569\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    183/300      4.47G     0.6416     0.4446     0.9953         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.53it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.832      0.827       0.87      0.572\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    184/300      4.35G      0.654     0.4391     0.9874         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.798      0.842      0.857      0.574\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    185/300      4.47G     0.6442     0.4351          1         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.68it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.786      0.848      0.854      0.586\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    186/300      4.37G     0.6335     0.4439     0.9974         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.22it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.808      0.822      0.855      0.588\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    187/300      4.49G     0.6517     0.4503     0.9993         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.46it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.816      0.855      0.878      0.592\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    188/300      4.46G     0.6494     0.4542      1.007         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.81      0.821      0.855      0.575\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    189/300      4.48G     0.6433     0.4351     0.9844         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.779      0.789      0.816      0.549\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    190/300      4.37G     0.6514     0.4427      1.005         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.34it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.786      0.778      0.816      0.546\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    191/300      4.45G     0.6289     0.4284     0.9984         38        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.14it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.34it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.848      0.761      0.826      0.549\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    192/300      4.37G     0.6429     0.4319     0.9897         49        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.87it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.879      0.751      0.831      0.561\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    193/300      4.48G     0.6285     0.4334     0.9985         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.50it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.30it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.836      0.787      0.836      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    194/300      4.47G     0.6241     0.4252     0.9911         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.825      0.802      0.844      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    195/300      4.43G     0.6424     0.4347     0.9926         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.31it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.804      0.808      0.849      0.561\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    196/300      4.48G     0.6136     0.4198     0.9875         15        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.38it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.49it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.817      0.818      0.867      0.583\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    197/300      4.46G     0.6364     0.4444      1.001         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.28it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.812      0.822      0.874      0.589\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    198/300      4.37G     0.6261     0.4427     0.9871         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.62it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.776       0.81       0.87      0.593\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    199/300      4.46G     0.6079     0.4321      0.992         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.845       0.76      0.852      0.574\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    200/300       4.4G     0.6533     0.4452     0.9892         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.72it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.837      0.758      0.844      0.575\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    201/300      4.47G     0.5957     0.4314     0.9771         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.54it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.789      0.799      0.846       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    202/300       4.4G     0.6013     0.4296     0.9827         20        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.70it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.82it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.789      0.783      0.827       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    203/300      4.45G     0.6117     0.4112     0.9735         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.42it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.23it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.764      0.788      0.834      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    204/300      4.35G     0.6165      0.409     0.9723         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.74it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.51it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.748      0.841       0.84      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    205/300      4.36G     0.6172     0.4087     0.9661         30        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.30it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.73it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.776       0.82      0.837       0.54\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    206/300      4.42G      0.638     0.4343     0.9862         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.93it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.813      0.829      0.851      0.557\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    207/300      4.48G     0.6071     0.4232     0.9854         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.839      0.838      0.864      0.578\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    208/300      4.46G      0.616     0.4147     0.9868         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.07it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.45it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.849      0.848      0.873      0.584\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    209/300      4.34G     0.6237     0.4392     0.9797         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.05it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.824      0.827      0.858      0.579\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    210/300      4.48G     0.5977     0.4176     0.9875         22        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.55it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.788      0.788      0.825      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    211/300      4.35G     0.6013     0.4144     0.9829         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.20it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.794      0.792      0.823       0.57\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    212/300      4.45G     0.6216      0.416      0.984         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.48it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.91it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.834      0.812      0.851      0.578\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    213/300      4.46G     0.6104     0.4152      0.985         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.75it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.06it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.832      0.812      0.849      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    214/300      4.49G      0.591     0.4088     0.9893         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.88it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.837      0.787      0.843      0.541\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    215/300      4.36G     0.6025     0.4076     0.9712         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.43it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.24it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.83      0.794      0.836      0.541\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    216/300      4.46G      0.606     0.4072      0.979         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.36it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.64it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.817      0.801      0.836      0.537\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    217/300      4.45G     0.6128     0.4437     0.9866         10        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.31it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.829      0.791      0.835      0.539\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    218/300      4.49G     0.6001     0.4089     0.9693         52        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.52it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.844      0.801      0.849      0.541\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    219/300      4.49G      0.599     0.4161     0.9727         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.27it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.58it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.833      0.822      0.858      0.548\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    220/300      4.37G     0.5841      0.396     0.9705         41        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.81      0.823      0.856      0.543\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    221/300      4.46G     0.5849     0.4126     0.9839          9        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:07<00:00,  2.32it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.84it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.809      0.797      0.849      0.532\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    222/300      4.48G     0.5932     0.4069      0.975         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.41it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.54it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.852      0.804       0.85      0.545\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    223/300      4.42G     0.5846     0.3958     0.9697         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.51it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.53it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.85      0.818      0.855      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    224/300      4.35G     0.5953     0.4127     0.9964         18        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.49it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.38it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.842      0.795      0.846      0.551\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    225/300      4.35G     0.5741     0.3899     0.9703         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.64it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.57it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.825       0.79       0.84       0.56\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    226/300      4.49G     0.5878     0.4067     0.9723         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.57it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383        0.8      0.792      0.835      0.566\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    227/300      4.48G     0.6216     0.4134     0.9964         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:06<00:00,  2.77it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.61it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.818      0.779      0.823      0.554\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    228/300      4.46G     0.6048     0.3999     0.9809         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.39it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.35it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.805       0.77      0.815      0.542\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    229/300      4.41G     0.5778     0.3842     0.9628         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.03it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.43it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.794      0.784      0.831      0.544\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    230/300      4.49G     0.5752     0.3897     0.9752         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.19it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.52it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.784      0.788       0.85      0.553\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    231/300      4.45G     0.5604     0.3826     0.9644         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.06it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.801      0.797      0.849      0.556\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    232/300      4.48G     0.5604     0.3907     0.9484         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.91it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.22it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.806      0.815      0.857      0.565\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    233/300      4.48G     0.5953     0.4208     0.9781         27        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.90it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.59it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.827      0.814       0.85      0.566\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    234/300      4.49G     0.5933     0.4098     0.9894         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.39it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.819      0.818      0.848      0.567\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    235/300      4.46G     0.6312     0.4178     0.9827         16        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  3.28it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.48it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.814      0.824      0.848      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    236/300      4.35G     0.5719     0.3829     0.9632         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:05<00:00,  2.84it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.41it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383       0.83      0.836       0.86      0.559\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"output_type":"stream","name":"stderr","text":["    237/300      4.46G     0.5618     0.3937     0.9644         14        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17/17 [00:04<00:00,  3.44it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.50it/s]"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.832      0.827       0.86      0.557\n","Stopping training early as no improvement observed in last 50 epochs. Best results observed at epoch 187, best model saved as best.pt.\n","To update EarlyStopping(patience=50) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["\n","237 epochs completed in 0.557 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 6.3MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 6.3MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.0.231 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n"]},{"output_type":"stream","name":"stderr","text":["                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["                   all         74        383      0.816      0.855      0.878      0.592\n","                Gloves         74         81      0.897      0.827      0.881      0.477\n","              Hard_hat         74         56      0.818          1      0.987       0.78\n","                Person         74         72      0.799      0.941      0.946      0.699\n","          Safety_boots         74         82       0.67      0.593       0.62      0.282\n","                  Vest         74         92      0.896      0.913      0.957      0.724\n","Speed: 0.3ms preprocess, 3.7ms inference, 0.0ms loss, 4.2ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["ultralytics.utils.metrics.DetMetrics object with attributes:\n","\n","ap_class_index: array([0, 1, 2, 3, 4])\n","box: ultralytics.utils.metrics.Metric object\n","confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7e0cf029cee0>\n","curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n","curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0096525,   0.0048263,           0],\n","       [          1,           1,           1, ...,     0.88889,     0.88889,           0],\n","       [          1,           1,           1, ...,    0.049923,    0.024962,           0],\n","       [    0.83333,     0.83333,     0.83333, ...,   0.0053004,   0.0026502,           0],\n","       [          1,           1,           1, ...,    0.072245,    0.036122,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.51546,     0.51546,     0.62403, ...,           0,           0,           0],\n","       [    0.57143,     0.57143,     0.70198, ...,           0,           0,           0],\n","       [    0.51264,     0.51264,     0.64354, ...,           0,           0,           0],\n","       [    0.47213,     0.47213,     0.55096, ...,           0,           0,           0],\n","       [    0.56173,     0.56173,     0.68272, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.35714,     0.35714,     0.47059, ...,           1,           1,           1],\n","       [        0.4,         0.4,     0.54081, ...,           1,           1,           1],\n","       [    0.34634,     0.34634,     0.48095, ...,           1,           1,           1],\n","       [    0.32287,     0.32287,     0.40673, ...,           1,           1,           1],\n","       [    0.39224,     0.39224,      0.5275, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n","          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n","          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n","          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n","          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n","           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n","           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n","           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n","           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n","           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n","           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n","           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n","           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n","           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n","           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n","           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n","           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n","           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n","           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n","           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n","           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n","            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n","           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n","           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n","           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n","            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n","           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n","           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n","           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n","            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n","           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n","           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n","           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n","           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n","           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n","           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n","           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n","           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n","           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n","           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n","           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n","           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.92593,     0.92593,     0.92593, ...,           0,           0,           0],\n","       [          1,           1,           1, ...,           0,           0,           0],\n","       [    0.98611,     0.98611,     0.97222, ...,           0,           0,           0],\n","       [    0.87805,     0.87805,     0.85366, ...,           0,           0,           0],\n","       [    0.98913,     0.98913,     0.96739, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n","fitness: 0.6210343382295828\n","keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n","maps: array([     0.4767,     0.78042,     0.69943,     0.28191,     0.72368])\n","names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n","plot: True\n","results_dict: {'metrics/precision(B)': 0.8161641838132224, 'metrics/recall(B)': 0.8549992236960643, 'metrics/mAP50(B)': 0.878478233489637, 'metrics/mAP50-95(B)': 0.5924294609784656, 'fitness': 0.6210343382295828}\n","save_dir: PosixPath('runs/detect/train')\n","speed: {'preprocess': 0.2625922898988466, 'inference': 3.6688624201594173, 'loss': 0.0009278993348817568, 'postprocess': 4.225730895996094}\n","task: 'detect'"]},"metadata":{},"execution_count":5}],"source":["\n","import os\n","\n","from ultralytics import YOLO\n","\n","model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n","\n","model.train(data='/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/data.yaml', epochs=300, imgsz=640)\n"]},{"cell_type":"markdown","source":["# **Inference on Image**"],"metadata":{"id":"szkfbfjGFPaE"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"oKsbM3gJHfA2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b9ac03b2-5265-4925-a1e1-15360c657998","executionInfo":{"status":"ok","timestamp":1703787629648,"user_tz":-300,"elapsed":9645,"user":{"displayName":"Muhammad Mehran","userId":"12810853850038077088"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","image 1/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightOne0585_jpg.rf.930afe066dde3ff8169bfc6abf80b5b4.jpg: 640x640 2 Persons, 7.2ms\n","image 2/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightOne0869_jpg.rf.0df88b0b49e4373b7ab5158d79cda296.jpg: 640x640 2 Persons, 1 Vest, 7.3ms\n","image 3/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightOne0967_jpg.rf.2ae8483a4711320c75e273883b4d5ac9.jpg: 640x640 (no detections), 9.9ms\n","image 4/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightSird0235_jpg.rf.9a4e594aed26cfd155b9d5abe520e80f.jpg: 640x640 2 Persons, 2 Vests, 7.8ms\n","image 5/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightSird0243_jpg.rf.5078d725f3aca0e3d3873666316ca982.jpg: 640x640 2 Persons, 2 Vests, 8.4ms\n","image 6/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin0036_jpg.rf.a69889eab3bc78ecd2525687583ccaf4.jpg: 640x640 1 Hard_hat, 8.6ms\n","image 7/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin0586_jpg.rf.e285b7b5848abec78c0f0f96802062e5.jpg: 640x640 1 Person, 2 Vests, 7.1ms\n","image 8/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin0907_jpg.rf.036298fe3c5079304bda1d8217c8f4cc.jpg: 640x640 1 Hard_hat, 7.1ms\n","image 9/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin1170_jpg.rf.2d0c30f5e318170023d1e6784ef3921f.jpg: 640x640 4 Hard_hats, 5 Persons, 1 Safety_boots, 5 Vests, 7.2ms\n","image 10/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin1315_jpg.rf.9a401a980872436624eb205a9d73fab3.jpg: 640x640 6 Hard_hats, 6 Persons, 12 Safety_bootss, 6 Vests, 7.2ms\n","image 11/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin2429_jpg.rf.33cd926c7a6a780337d969e1e5f248c4.jpg: 640x640 1 Hard_hat, 1 Vest, 7.2ms\n","image 12/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin2593_jpg.rf.37169ba3ac9b43999e10142e2a4413a6.jpg: 640x640 (no detections), 7.2ms\n","image 13/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin2742_jpg.rf.f99afc520994a85e8a02f051b905c273.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 14/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Tan0914914_jpg.rf.4ae758f376dc11704b6f82d64d5b3233.jpg: 640x640 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 15/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Tan0972972_jpg.rf.30e8c8947ea307b1ada5658b25e843c3.jpg: 640x640 1 Hard_hat, 2 Persons, 1 Vest, 7.2ms\n","image 16/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/TsirinOne0031_jpg.rf.e9448793466117932b2748d321c0d807.jpg: 640x640 5 Persons, 7.2ms\n","image 17/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/TsirinTu0047_jpg.rf.60d829abcce705bd69490d4ae826be7e.jpg: 640x640 5 Persons, 7.2ms\n","image 18/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0247_jpg.rf.921166e067f6c367a5746e91633db683.jpg: 640x640 1 Vest, 7.2ms\n","image 19/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0512_jpg.rf.fab38e64446ae4740818f1d72a358fa0.jpg: 640x640 1 Vest, 7.2ms\n","image 20/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0513_jpg.rf.56c013b83120e08f01c5d017c7d0e0a6.jpg: 640x640 1 Vest, 7.2ms\n","image 21/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0611_jpg.rf.c339f0bdcdb8aef4d2db320fdcc2e901.jpg: 640x640 1 Hard_hat, 1 Safety_boots, 1 Vest, 7.3ms\n","image 22/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv1069_jpg.rf.108bfd873918d8b58cce197c2a722a1b.jpg: 640x640 1 Vest, 11.2ms\n","image 23/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_0_jpg.rf.b307186eb19bf3f9cbaef03606084394.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 1 Vest, 7.2ms\n","image 24/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_163_jpg.rf.968f379c16daa15a48a82e9ba0675dde.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 25/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_167_jpg.rf.2d6eea6c7b1989609a862135cc64d100.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 26/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_174_jpg.rf.9c80e740ec871bcfc9e32c3bfa7061de.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 9.9ms\n","image 27/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_177_jpg.rf.d798ca65cb6e91a608bd148910b12696.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 28/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_179_jpg.rf.157d4d2a19107d6ad66b964d8d0fa436.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Safety_boots, 1 Vest, 7.3ms\n","image 29/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_180_jpg.rf.c5f87cd2627d86c53024895f60a00aa8.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 30/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_184_jpg.rf.b9bf8fa565bdbf1a0aeec2374ad0e2e6.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 31/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_186_jpg.rf.f4cbf4eb986b83adf8a1ef9584cf18b8.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 32/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_189_jpg.rf.734a8e52c70646ca3295f60fb06f3644.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 7.6ms\n","image 33/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_190_jpg.rf.77f247e46c96e3a386cbc1931acdd7f3.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 1 Vest, 7.2ms\n","image 34/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_150_jpg.rf.2682e3010f1b052f4b70ea9da21e8680.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.5ms\n","image 35/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_150_jpg.rf.f0784e2bb2379fc727e344a8b12de3ca.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 36/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153-1-_jpg.rf.ab2badf32a4bdc61c1f2aaee0868555f.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 37/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.8b203750f32c92b4f82c4215e49605b3.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 38/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.908446806ebe6ef21a4b35cf11090082.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 8.4ms\n","image 39/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.a1454369a44488c0d6c89b4bbf56b337.jpg: 640x640 1 Person, 1 Safety_boots, 1 Vest, 7.2ms\n","image 40/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.f463b2513b1772a8ff7d70f24fb06d7d.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 41/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_154_jpg.rf.530c6b4b5279017605ae83c89e0ac4c6.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 42/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_154_jpg.rf.8d174d7aaa90ce4dad8855ac085bf7cc.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 43/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_154_jpg.rf.ff64dc1915cd89265cc5bb6fbce11230.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 44/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.6dd06cd06be11270a04462bbba76a465.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 45/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.a1ebbcb68d49941048ad6341d0e5c8b0.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 46/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.ac0bca8f72606b91436759e908f42acd.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 47/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.f6cd576f497802ff62c8b9b7516d8a6f.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 48/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_156_jpg.rf.0a1c2b7c4dd6a6ca8566010007cf22dd.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 49/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_156_jpg.rf.c6d967fd444b9b55009eeec746fa9aef.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 3 Safety_bootss, 1 Vest, 7.2ms\n","image 50/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_156_jpg.rf.da01bc87c9b609a7cf931db5cef0c6e6.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 3 Safety_bootss, 1 Vest, 7.2ms\n","image 51/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_157_jpg.rf.7bc7a065c9f381442f0b0c84f4d4b131.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 52/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_157_jpg.rf.9d7d938f62f9543d9710f3fb3806ff99.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 53/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.184363d039129a4530440fd47b993f45.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 54/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.3a9787d86348f90ccb5f7253ef149fa9.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 55/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.78d5dedc880b08452fb0ba68fabb30e6.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 56/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.9f2439c1e5712d35c4543a0b7890b13c.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 57/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.be56abde393288366385bbaf4b4be9fc.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 58/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.c17661e5445ad9d53db1ddc895ff940c.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 59/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.1675e5cce3a6698374ed4999801bbaec.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 60/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.2b3750e88c3578f2d94ca783f1278105.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 61/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.54a2a31cd0ac73505dbc9c48a497df0c.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 62/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.6a621adb5b90c51ca8fee23fd0331ac4.jpg: 640x640 2 Glovess, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 11.5ms\n","image 63/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.75b7179c014114d3094ba8c8d9850a4a.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.3ms\n","image 64/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.8d704239f006004f37c0d1c5a02d5268.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 65/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.26ba921594af14a5bb8124d3b0f51320.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.3ms\n","image 66/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.8fd002f07ed585f56e98f04100bb83fa.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 67/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.a6148d213f9944617eef1e72975bcf95.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 68/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.fec7949409eb2e9be4f353476b9930b9.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 69/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.30452ba2dced959cf9e4aaac49996b13.jpg: 640x640 1 Person, 3 Safety_bootss, 1 Vest, 7.2ms\n","image 70/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.544f973bedd34d07c2d44a7e5ffea87f.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 71/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.83097cc5189d84d7bd8c2ea1790fd837.jpg: 640x640 1 Person, 3 Safety_bootss, 1 Vest, 10.3ms\n","image 72/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.c12c3cd13d4457fe98a90ec3df78ea3a.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.3ms\n","image 73/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_235_jpg.rf.6da18c0817779e9c93d708960148c605.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 74/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_235_jpg.rf.9349cfc458de0b851daa1b59f359c935.jpg: 640x640 1 Gloves, 1 Person, 2 Safety_bootss, 1 Vest, 7.4ms\n","image 75/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.14a4e1250147fcef4a1c9c5fe5f8096f.jpg: 640x640 1 Person, 3 Safety_bootss, 1 Vest, 7.2ms\n","image 76/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.491158d84470a24c67d7a886c37977c7.jpg: 640x640 1 Gloves, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 77/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.5a874846c51f129039d7923bcca7bd96.jpg: 640x640 1 Hard_hat, 3 Persons, 8.5ms\n","image 78/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.fd29a9d6e6b26872ca37ad165bb673d2.jpg: 640x640 1 Person, 3 Safety_bootss, 1 Vest, 7.2ms\n","image 79/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_237_jpg.rf.dbfde5725ba9955c9db90c88a9525163.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 80/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_237_jpg.rf.fb6efc0ef2ce6291dd7213b993b4e380.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 81/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_238_jpg.rf.74426c631fba0b3c130d620d0ecde88b.jpg: 640x640 1 Gloves, 1 Person, 2 Safety_bootss, 1 Vest, 7.3ms\n","image 82/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_238_jpg.rf.d4d42084a2590b13e7f73340dbc86952.jpg: 640x640 1 Gloves, 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 83/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_239_jpg.rf.1b7792c1e4c6c1e1d13d3c89d9b59d03.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 84/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_239_jpg.rf.ac16f00f7ac92f1328764ca76a6ce3fe.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.9ms\n","image 85/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_239_jpg.rf.d6424187438d96296649c8ab1eea4661.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.2ms\n","image 86/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_240_jpg.rf.24945b7e946d47c32af643499e0aa7f8.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.1ms\n","image 87/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_241_jpg.rf.415b64e67ae9c685f173cf785aca4979.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 7.4ms\n","image 88/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_241_jpg.rf.ac377d5b48e1520a380d6218a2ed66d2.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 7.1ms\n","image 89/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_242-1-_jpg.rf.062a807937d2281f2c317ea962099158.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.1ms\n","image 90/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_242_jpg.rf.2807b2bf59dabb24074050c921e1608c.jpg: 640x640 1 Person, 2 Safety_bootss, 7.1ms\n","image 91/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_242_jpg.rf.369a8ccbf0d969978a6a579d8643ea13.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.1ms\n","image 92/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_243_jpg.rf.601d34237b2e744ee9eb466c8d7127af.jpg: 640x640 1 Hard_hat, 1 Person, 8.3ms\n","image 93/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_243_jpg.rf.98032c4785e9bab477f2bf45e8fdd01d.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 94/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_243_jpg.rf.bf54c9ebc5bc90f5afd84ef7ba71cb43.jpg: 640x640 1 Person, 1 Safety_boots, 1 Vest, 7.1ms\n","image 95/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_244_jpg.rf.7aeb8d8934cbfb1b285b10b7c92879bf.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 96/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_244_jpg.rf.d06a6dfde2b22021c07360a2c1165d1d.jpg: 640x640 1 Person, 1 Safety_boots, 1 Vest, 7.2ms\n","image 97/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_245_jpg.rf.74b9626d2655d7f4d44cecbd084fb233.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.3ms\n","image 98/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_245_jpg.rf.7a50c73c1d43ceb4373259141fac159c.jpg: 640x640 1 Safety_boots, 7.3ms\n","image 99/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_247_jpg.rf.dc7d182b5e2cd43ef3d65441465d73d8.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 100/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_248_jpg.rf.c66e4d7dad6a876ee2e13caf66cbc78e.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 101/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_248_jpg.rf.de5dd4f9e457901cd8691be9d3000d0d.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.1ms\n","image 102/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_249_jpg.rf.bea083cff3dde453bff37fc43ae2aaba.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 103/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_249_jpg.rf.f057981e9e27cd39a3e7d7b23f0790c9.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 104/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_251_jpg.rf.60688b93b2dbc3670a61d83f2c646779.jpg: 640x640 1 Hard_hat, 1 Person, 4 Safety_bootss, 1 Vest, 7.1ms\n","image 105/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_252_jpg.rf.55518795999a935be1d69752615ae22d.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 1 Vest, 7.2ms\n","image 106/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_252_jpg.rf.5f65f164a8969fd4767c1cd4d4b72c7e.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 1 Vest, 7.1ms\n","image 107/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_253_jpg.rf.4c570dee11102cb3853ebfa30e61d414.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.1ms\n","image 108/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_253_jpg.rf.6a3f8c5c5a230728a8af1d075ce59f17.jpg: 640x640 1 Hard_hat, 1 Person, 1 Safety_boots, 7.2ms\n","image 109/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_254_jpg.rf.9b377bdb129d8a45c86d4c5a26108600.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 7.1ms\n","image 110/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_255_jpg.rf.2a5370fe431de7b4ae97ad5b286432ff.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.1ms\n","image 111/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_255_jpg.rf.b334d12480ed53a8623a21983c8e2fb0.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 7.1ms\n","image 112/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_256_jpg.rf.143ef39f59c937557a71263909d8378c.jpg: 640x640 1 Person, 1 Safety_boots, 1 Vest, 7.1ms\n","image 113/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_256_jpg.rf.4cd18ce9e5b778a8021e9d79bd4651de.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.2ms\n","image 114/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_256_jpg.rf.f14842f456a1c5567fab2a3a7d7ba8f0.jpg: 640x640 1 Person, 1 Safety_boots, 1 Vest, 7.2ms\n","image 115/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_257_jpg.rf.c30832d4fac283445eccb9370ed4e423.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.6ms\n","image 116/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_258_jpg.rf.fdfaa9339b57036dc1a0ef2a3d81c6aa.jpg: 640x640 1 Person, 2 Safety_bootss, 13.8ms\n","image 117/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_259_jpg.rf.232857fde2743b4936d704c8f871f1dd.jpg: 640x640 1 Person, 1 Safety_boots, 10.9ms\n","image 118/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_259_jpg.rf.708954ae4c941b58048a0e77304cd7fb.jpg: 640x640 1 Person, 1 Safety_boots, 10.4ms\n","image 119/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_260_jpg.rf.51f2f0097765bdf00f208a80161bbd10.jpg: 640x640 1 Person, 2 Safety_bootss, 10.0ms\n","image 120/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_260_jpg.rf.e1e7f12db0d4b332f6433ed68a1c637f.jpg: 640x640 1 Person, 2 Safety_bootss, 8.3ms\n","image 121/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_261_jpg.rf.06ab92238876794707155f2471b98b4c.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 9.1ms\n","image 122/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_261_jpg.rf.efd95b49d5d12cfb7df31eee450cb95e.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 8.0ms\n","image 123/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_263_jpg.rf.2cb166273cb2029d450ed79b22a39dbd.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 8.4ms\n","image 124/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_264_jpg.rf.60444dc0892110a1a05c726c884c2191.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 8.2ms\n","image 125/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_266_jpg.rf.97bb1464553c03a5df00171b2c0978e0.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 8.4ms\n","image 126/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_289_jpg.rf.e5e0734d490ccfefefa0123e17e0cc7c.jpg: 640x640 1 Person, 2 Safety_bootss, 7.7ms\n","image 127/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_292_jpg.rf.6ef2af9d2a4d1619b844e330d3f1db4e.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 8.8ms\n","image 128/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_293_jpg.rf.0a0744ce10023924cf2468df43669093.jpg: 640x640 1 Person, 2 Safety_bootss, 8.2ms\n","image 129/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_296_jpg.rf.7dbfb3956507fa83a7383eb4703db318.jpg: 640x640 1 Person, 2 Safety_bootss, 7.8ms\n","image 130/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_300_jpg.rf.00bba315c367a74b065f6bb57b542bb9.jpg: 640x640 1 Person, 2 Safety_bootss, 1 Vest, 7.9ms\n","image 131/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_310_jpg.rf.8263816cf742d05caf60f1d003d3c258.jpg: 640x640 1 Person, 5 Safety_bootss, 8.1ms\n","image 132/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_317_jpg.rf.cd5f13e808577ad5514b298c848607f2.jpg: 640x640 1 Person, 1 Safety_boots, 7.6ms\n","image 133/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_33_jpg.rf.de8c93cc0d9c53d2c2c0f85a695b6906.jpg: 640x640 1 Hard_hat, 1 Person, 7.6ms\n","image 134/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_34_jpg.rf.ddba711c0a149b1073fe2702a16265ba.jpg: 640x640 1 Hard_hat, 1 Person, 7.8ms\n","image 135/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_4_jpg.rf.be2be5fef583fccc16a58d6600f14a83.jpg: 640x640 1 Person, 2 Safety_bootss, 10.1ms\n","image 136/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_53_jpg.rf.5225c1a3f20e432581ce9b91b01d7c4f.jpg: 640x640 1 Person, 2 Safety_bootss, 8.6ms\n","image 137/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_53_jpg.rf.9e4f3466092221422afc0fd157a0ad2b.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 9.2ms\n","image 138/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_54_jpg.rf.c9106a0f0a6ad928e63ea1bae305d6be.jpg: 640x640 1 Hard_hat, 1 Safety_boots, 7.9ms\n","image 139/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_62_jpg.rf.af83013739b7cf375b0813d0d85f83e0.jpg: 640x640 1 Hard_hat, 2 Safety_bootss, 7.9ms\n","image 140/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_86_jpg.rf.4b22b1105238426807d4e4a5c800de5f.jpg: 640x640 1 Gloves, 1 Hard_hat, 1 Person, 2 Safety_bootss, 10.9ms\n","image 141/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_93_jpg.rf.d19720cdc7bcf5b8d789d9bfaeca2022.jpg: 640x640 (no detections), 8.1ms\n","image 142/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_94_jpg.rf.a7fea66027fa9e855c8d150fc40eda50.jpg: 640x640 1 Hard_hat, 1 Person, 7.8ms\n","image 143/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_97_jpg.rf.c9701142df40271a2a17a9c0f3e64001.jpg: 640x640 1 Hard_hat, 1 Person, 2 Safety_bootss, 1 Vest, 11.8ms\n","image 144/144 /content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/images-2022-07-04T012922_jpg.rf.a1091a2a972babb350e51c636f857222.jpg: 640x640 1 Person, 9.7ms\n","Speed: 2.1ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/predict4\u001b[0m\n","141 labels saved to runs/detect/predict4/labels\n"]},{"output_type":"execute_result","data":{"text/plain":["[ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[156, 128, 117],\n","         [156, 128, 117],\n","         [156, 128, 117],\n","         ...,\n","         [141, 104,  90],\n","         [140, 103,  89],\n","         [140, 103,  89]],\n"," \n","        [[156, 128, 117],\n","         [156, 128, 117],\n","         [156, 128, 117],\n","         ...,\n","         [141, 104,  90],\n","         [140, 103,  89],\n","         [140, 103,  89]],\n"," \n","        [[156, 128, 117],\n","         [156, 128, 117],\n","         [156, 128, 117],\n","         ...,\n","         [141, 104,  90],\n","         [140, 103,  89],\n","         [140, 103,  89]],\n"," \n","        ...,\n"," \n","        [[108,  79,  70],\n","         [110,  81,  72],\n","         [110,  81,  72],\n","         ...,\n","         [ 72,  56,  57],\n","         [ 73,  57,  58],\n","         [ 75,  59,  60]],\n"," \n","        [[105,  76,  67],\n","         [107,  78,  69],\n","         [107,  78,  69],\n","         ...,\n","         [ 68,  52,  53],\n","         [ 69,  53,  54],\n","         [ 72,  56,  57]],\n"," \n","        [[103,  74,  65],\n","         [105,  76,  67],\n","         [105,  76,  67],\n","         ...,\n","         [ 67,  51,  52],\n","         [ 67,  51,  52],\n","         [ 70,  54,  55]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightOne0585_jpg.rf.930afe066dde3ff8169bfc6abf80b5b4.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.8880367279052734, 'inference': 7.234334945678711, 'postprocess': 1.9664764404296875},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[158, 126, 113],\n","         [158, 126, 113],\n","         [158, 126, 113],\n","         ...,\n","         [144, 104,  86],\n","         [144, 104,  86],\n","         [144, 104,  86]],\n"," \n","        [[158, 126, 113],\n","         [158, 126, 113],\n","         [158, 126, 113],\n","         ...,\n","         [144, 104,  86],\n","         [144, 104,  86],\n","         [144, 104,  86]],\n"," \n","        [[158, 126, 113],\n","         [158, 126, 113],\n","         [158, 126, 113],\n","         ...,\n","         [144, 104,  86],\n","         [144, 104,  86],\n","         [144, 104,  86]],\n"," \n","        ...,\n"," \n","        [[ 99,  68,  59],\n","         [ 96,  65,  56],\n","         [ 97,  66,  57],\n","         ...,\n","         [ 75,  60,  57],\n","         [ 75,  60,  57],\n","         [ 76,  61,  58]],\n"," \n","        [[ 94,  63,  54],\n","         [ 93,  62,  53],\n","         [ 94,  63,  54],\n","         ...,\n","         [ 72,  57,  54],\n","         [ 72,  57,  54],\n","         [ 72,  57,  54]],\n"," \n","        [[ 91,  60,  51],\n","         [ 91,  60,  51],\n","         [ 92,  61,  52],\n","         ...,\n","         [ 70,  55,  52],\n","         [ 70,  55,  52],\n","         [ 71,  56,  53]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightOne0869_jpg.rf.0df88b0b49e4373b7ab5158d79cda296.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1131038665771484, 'inference': 7.253408432006836, 'postprocess': 1.3980865478515625},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 88,  87,  83],\n","         [ 88,  87,  83],\n","         [ 88,  87,  83],\n","         ...,\n","         [ 93, 105, 115],\n","         [ 91, 106, 115],\n","         [ 92, 107, 116]],\n"," \n","        [[ 88,  87,  83],\n","         [ 88,  87,  83],\n","         [ 88,  87,  83],\n","         ...,\n","         [ 94, 106, 116],\n","         [ 92, 107, 116],\n","         [ 93, 108, 117]],\n"," \n","        [[ 88,  87,  83],\n","         [ 88,  87,  83],\n","         [ 88,  87,  83],\n","         ...,\n","         [ 94, 106, 116],\n","         [ 92, 107, 116],\n","         [ 93, 108, 117]],\n"," \n","        ...,\n"," \n","        [[ 88,  87,  83],\n","         [ 88,  87,  83],\n","         [ 89,  88,  84],\n","         ...,\n","         [121, 133, 145],\n","         [116, 128, 140],\n","         [112, 124, 136]],\n"," \n","        [[ 79,  78,  74],\n","         [ 79,  78,  74],\n","         [ 80,  79,  75],\n","         ...,\n","         [101, 113, 125],\n","         [ 94, 106, 118],\n","         [ 89, 101, 113]],\n"," \n","        [[ 69,  68,  64],\n","         [ 69,  68,  64],\n","         [ 69,  68,  64],\n","         ...,\n","         [ 76,  88, 100],\n","         [ 66,  78,  90],\n","         [ 58,  70,  82]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightOne0967_jpg.rf.2ae8483a4711320c75e273883b4d5ac9.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.194643020629883, 'inference': 9.891986846923828, 'postprocess': 1.453399658203125},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         ...,\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1]],\n"," \n","        [[ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         ...,\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1]],\n"," \n","        [[ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         ...,\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1]],\n"," \n","        ...,\n"," \n","        [[41, 31, 31],\n","         [42, 36, 37],\n","         [44, 40, 45],\n","         ...,\n","         [16, 46, 73],\n","         [15, 45, 72],\n","         [14, 44, 71]],\n"," \n","        [[39, 27, 25],\n","         [37, 29, 29],\n","         [34, 31, 33],\n","         ...,\n","         [17, 47, 74],\n","         [16, 46, 73],\n","         [15, 45, 72]],\n"," \n","        [[40, 28, 26],\n","         [34, 26, 26],\n","         [30, 25, 27],\n","         ...,\n","         [17, 47, 74],\n","         [17, 47, 74],\n","         [16, 46, 73]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightSird0235_jpg.rf.9a4e594aed26cfd155b9d5abe520e80f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9290447235107422, 'inference': 7.843732833862305, 'postprocess': 3.210306167602539},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         ...,\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1]],\n"," \n","        [[ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         ...,\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1]],\n"," \n","        [[ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         ...,\n","         [ 1,  1,  1],\n","         [ 1,  1,  1],\n","         [ 1,  1,  1]],\n"," \n","        ...,\n"," \n","        [[38, 40, 51],\n","         [40, 43, 57],\n","         [51, 55, 73],\n","         ...,\n","         [20, 45, 77],\n","         [20, 45, 77],\n","         [20, 45, 77]],\n"," \n","        [[41, 41, 53],\n","         [29, 30, 44],\n","         [29, 31, 49],\n","         ...,\n","         [20, 45, 77],\n","         [20, 45, 77],\n","         [20, 45, 77]],\n"," \n","        [[21, 21, 33],\n","         [ 8,  9, 23],\n","         [10, 12, 30],\n","         ...,\n","         [20, 45, 77],\n","         [20, 45, 77],\n","         [20, 45, 77]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/AightSird0243_jpg.rf.5078d725f3aca0e3d3873666316ca982.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9910335540771484, 'inference': 8.402585983276367, 'postprocess': 1.4300346374511719},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[254, 238, 249],\n","         [254, 238, 249],\n","         [254, 238, 249],\n","         ...,\n","         [251, 251, 251],\n","         [243, 243, 243],\n","         [237, 237, 237]],\n"," \n","        [[254, 238, 249],\n","         [254, 238, 249],\n","         [254, 238, 249],\n","         ...,\n","         [251, 251, 251],\n","         [243, 243, 243],\n","         [237, 237, 237]],\n"," \n","        [[254, 238, 249],\n","         [254, 238, 249],\n","         [254, 238, 249],\n","         ...,\n","         [251, 251, 251],\n","         [243, 243, 243],\n","         [237, 237, 237]],\n"," \n","        ...,\n"," \n","        [[ 98,  69,  72],\n","         [118,  89,  92],\n","         [163, 134, 137],\n","         ...,\n","         [209, 179, 184],\n","         [214, 184, 189],\n","         [202, 172, 177]],\n"," \n","        [[115,  86,  89],\n","         [134, 105, 108],\n","         [180, 151, 154],\n","         ...,\n","         [200, 170, 175],\n","         [205, 175, 180],\n","         [193, 163, 168]],\n"," \n","        [[126,  97, 100],\n","         [151, 122, 125],\n","         [207, 178, 181],\n","         ...,\n","         [192, 162, 167],\n","         [194, 164, 169],\n","         [182, 152, 157]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin0036_jpg.rf.a69889eab3bc78ecd2525687583ccaf4.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9657611846923828, 'inference': 8.55708122253418, 'postprocess': 1.4259815216064453},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[197, 163, 164],\n","         [196, 163, 160],\n","         [193, 164, 157],\n","         ...,\n","         [ 87,  83,  78],\n","         [ 87,  83,  78],\n","         [ 87,  83,  78]],\n"," \n","        [[197, 163, 164],\n","         [196, 163, 160],\n","         [193, 164, 157],\n","         ...,\n","         [ 88,  84,  79],\n","         [ 88,  84,  79],\n","         [ 88,  84,  79]],\n"," \n","        [[197, 163, 164],\n","         [196, 163, 160],\n","         [193, 164, 157],\n","         ...,\n","         [ 89,  85,  80],\n","         [ 88,  84,  79],\n","         [ 88,  84,  79]],\n"," \n","        ...,\n"," \n","        [[170, 181, 185],\n","         [170, 181, 185],\n","         [169, 181, 185],\n","         ...,\n","         [130, 116, 118],\n","         [124, 110, 112],\n","         [117, 103, 105]],\n"," \n","        [[170, 181, 185],\n","         [170, 181, 185],\n","         [169, 181, 185],\n","         ...,\n","         [133, 119, 121],\n","         [126, 112, 114],\n","         [118, 104, 106]],\n"," \n","        [[170, 181, 185],\n","         [170, 181, 185],\n","         [169, 181, 185],\n","         ...,\n","         [133, 119, 121],\n","         [126, 112, 114],\n","         [118, 104, 106]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin0586_jpg.rf.e285b7b5848abec78c0f0f96802062e5.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.974344253540039, 'inference': 7.139921188354492, 'postprocess': 1.3074874877929688},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[133, 144, 148],\n","         [133, 144, 148],\n","         [133, 144, 148],\n","         ...,\n","         [ 93,  82,  90],\n","         [ 93,  82,  90],\n","         [ 93,  82,  90]],\n"," \n","        [[133, 144, 148],\n","         [133, 144, 148],\n","         [133, 144, 148],\n","         ...,\n","         [ 93,  82,  90],\n","         [ 93,  82,  90],\n","         [ 93,  82,  90]],\n"," \n","        [[133, 144, 148],\n","         [133, 144, 148],\n","         [133, 144, 148],\n","         ...,\n","         [ 93,  82,  90],\n","         [ 93,  82,  90],\n","         [ 93,  82,  90]],\n"," \n","        ...,\n"," \n","        [[114, 114, 120],\n","         [114, 114, 120],\n","         [115, 115, 121],\n","         ...,\n","         [112, 110, 116],\n","         [112, 110, 116],\n","         [111, 109, 115]],\n"," \n","        [[114, 114, 120],\n","         [114, 114, 120],\n","         [115, 115, 121],\n","         ...,\n","         [112, 110, 116],\n","         [111, 109, 115],\n","         [111, 109, 115]],\n"," \n","        [[114, 114, 120],\n","         [114, 114, 120],\n","         [115, 115, 121],\n","         ...,\n","         [111, 109, 115],\n","         [111, 109, 115],\n","         [111, 109, 115]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin0907_jpg.rf.036298fe3c5079304bda1d8217c8f4cc.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9769668579101562, 'inference': 7.140636444091797, 'postprocess': 1.3146400451660156},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[130, 144, 138],\n","         [130, 144, 138],\n","         [130, 144, 138],\n","         ...,\n","         [112, 103, 100],\n","         [113, 104, 101],\n","         [113, 104, 101]],\n"," \n","        [[130, 144, 138],\n","         [130, 144, 138],\n","         [130, 144, 138],\n","         ...,\n","         [114, 105, 102],\n","         [114, 105, 102],\n","         [114, 105, 102]],\n"," \n","        [[130, 144, 138],\n","         [130, 144, 138],\n","         [130, 144, 138],\n","         ...,\n","         [118, 106, 104],\n","         [119, 107, 105],\n","         [119, 107, 105]],\n"," \n","        ...,\n"," \n","        [[ 70,  85,  81],\n","         [ 74,  89,  85],\n","         [ 78,  95,  91],\n","         ...,\n","         [136, 164, 151],\n","         [136, 164, 151],\n","         [136, 164, 151]],\n"," \n","        [[ 69,  84,  80],\n","         [ 73,  88,  84],\n","         [ 77,  94,  90],\n","         ...,\n","         [136, 164, 151],\n","         [136, 164, 151],\n","         [137, 165, 152]],\n"," \n","        [[ 70,  85,  81],\n","         [ 74,  89,  85],\n","         [ 79,  96,  92],\n","         ...,\n","         [136, 164, 151],\n","         [137, 165, 152],\n","         [137, 165, 152]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin1170_jpg.rf.2d0c30f5e318170023d1e6784ef3921f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0453929901123047, 'inference': 7.191181182861328, 'postprocess': 1.3363361358642578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[250, 247, 216],\n","         [249, 246, 215],\n","         [248, 245, 214],\n","         ...,\n","         [249, 247, 212],\n","         [249, 247, 212],\n","         [250, 248, 213]],\n"," \n","        [[250, 247, 216],\n","         [249, 246, 215],\n","         [248, 245, 214],\n","         ...,\n","         [249, 247, 212],\n","         [249, 247, 212],\n","         [249, 247, 212]],\n"," \n","        [[250, 247, 216],\n","         [249, 246, 215],\n","         [248, 245, 214],\n","         ...,\n","         [249, 247, 212],\n","         [249, 247, 212],\n","         [249, 247, 212]],\n"," \n","        ...,\n"," \n","        [[ 85,  47,  53],\n","         [ 79,  41,  47],\n","         [ 84,  46,  52],\n","         ...,\n","         [109,  78,  81],\n","         [156, 125, 128],\n","         [154, 123, 126]],\n"," \n","        [[ 95,  57,  63],\n","         [101,  63,  69],\n","         [121,  83,  89],\n","         ...,\n","         [119,  88,  91],\n","         [142, 111, 114],\n","         [134, 103, 106]],\n"," \n","        [[114,  76,  82],\n","         [132,  94, 100],\n","         [163, 125, 131],\n","         ...,\n","         [151, 120, 123],\n","         [134, 103, 106],\n","         [113,  82,  85]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin1315_jpg.rf.9a401a980872436624eb205a9d73fab3.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.016305923461914, 'inference': 7.187843322753906, 'postprocess': 1.56402587890625},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  24,  28],\n","         [ 57,  43,  47],\n","         [ 68,  54,  58],\n","         ...,\n","         [ 55,  55,  61],\n","         [ 55,  55,  61],\n","         [ 55,  55,  61]],\n"," \n","        [[ 38,  27,  30],\n","         [ 56,  45,  48],\n","         [ 65,  54,  57],\n","         ...,\n","         [ 55,  55,  61],\n","         [ 55,  55,  61],\n","         [ 55,  55,  61]],\n"," \n","        [[ 40,  34,  39],\n","         [ 55,  49,  54],\n","         [ 61,  55,  60],\n","         ...,\n","         [ 55,  55,  61],\n","         [ 55,  55,  61],\n","         [ 55,  55,  61]],\n"," \n","        ...,\n"," \n","        [[ 98, 115, 118],\n","         [ 98, 115, 118],\n","         [ 98, 115, 118],\n","         ...,\n","         [108, 148, 160],\n","         [109, 149, 161],\n","         [110, 150, 162]],\n"," \n","        [[ 98, 115, 118],\n","         [ 98, 115, 118],\n","         [ 98, 115, 118],\n","         ...,\n","         [108, 148, 160],\n","         [109, 149, 161],\n","         [110, 150, 162]],\n"," \n","        [[ 98, 115, 118],\n","         [ 98, 115, 118],\n","         [ 98, 115, 118],\n","         ...,\n","         [108, 148, 160],\n","         [109, 149, 161],\n","         [110, 150, 162]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin2429_jpg.rf.33cd926c7a6a780337d969e1e5f248c4.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.016305923461914, 'inference': 7.205963134765625, 'postprocess': 1.3456344604492188},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 29,  23,  28],\n","         [ 29,  23,  28],\n","         [ 29,  23,  28],\n","         ...,\n","         [ 59,  45,  46],\n","         [ 60,  46,  47],\n","         [ 60,  46,  47]],\n"," \n","        [[ 29,  23,  28],\n","         [ 29,  23,  28],\n","         [ 29,  23,  28],\n","         ...,\n","         [ 59,  45,  46],\n","         [ 60,  46,  47],\n","         [ 60,  46,  47]],\n"," \n","        [[ 29,  23,  28],\n","         [ 29,  23,  28],\n","         [ 29,  23,  28],\n","         ...,\n","         [ 59,  45,  46],\n","         [ 60,  46,  47],\n","         [ 60,  46,  47]],\n"," \n","        ...,\n"," \n","        [[132, 148, 137],\n","         [124, 140, 129],\n","         [113, 129, 118],\n","         ...,\n","         [125, 138, 124],\n","         [124, 137, 123],\n","         [124, 137, 123]],\n"," \n","        [[113, 129, 118],\n","         [114, 130, 119],\n","         [112, 128, 117],\n","         ...,\n","         [125, 138, 124],\n","         [124, 137, 123],\n","         [124, 137, 123]],\n"," \n","        [[106, 122, 111],\n","         [114, 130, 119],\n","         [119, 135, 124],\n","         ...,\n","         [125, 138, 124],\n","         [124, 137, 123],\n","         [124, 137, 123]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin2593_jpg.rf.37169ba3ac9b43999e10142e2a4413a6.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9948482513427734, 'inference': 7.179975509643555, 'postprocess': 0.6525516510009766},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[247, 247, 247],\n","         [246, 246, 246],\n","         [245, 245, 245],\n","         ...,\n","         [219, 187, 168],\n","         [216, 182, 158],\n","         [215, 180, 154]],\n"," \n","        [[247, 247, 247],\n","         [246, 246, 246],\n","         [245, 245, 245],\n","         ...,\n","         [218, 187, 166],\n","         [214, 180, 156],\n","         [212, 178, 149]],\n"," \n","        [[246, 246, 246],\n","         [246, 246, 246],\n","         [246, 246, 246],\n","         ...,\n","         [215, 183, 160],\n","         [213, 178, 152],\n","         [211, 175, 145]],\n"," \n","        ...,\n"," \n","        [[167, 136, 139],\n","         [168, 137, 140],\n","         [168, 137, 140],\n","         ...,\n","         [114,  91,  96],\n","         [112,  89,  94],\n","         [114,  91,  96]],\n"," \n","        [[168, 137, 140],\n","         [170, 139, 142],\n","         [170, 139, 142],\n","         ...,\n","         [105,  82,  87],\n","         [105,  82,  87],\n","         [107,  84,  89]],\n"," \n","        [[169, 138, 141],\n","         [171, 140, 143],\n","         [172, 141, 144],\n","         ...,\n","         [ 98,  75,  80],\n","         [ 99,  76,  81],\n","         [101,  78,  83]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Aitin2742_jpg.rf.f99afc520994a85e8a02f051b905c273.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.955270767211914, 'inference': 7.172822952270508, 'postprocess': 1.3206005096435547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[129, 119, 109],\n","         [129, 119, 109],\n","         [128, 118, 108],\n","         ...,\n","         [158, 179, 194],\n","         [158, 179, 194],\n","         [158, 179, 194]],\n"," \n","        [[138, 128, 118],\n","         [136, 126, 116],\n","         [132, 122, 112],\n","         ...,\n","         [158, 179, 194],\n","         [158, 179, 194],\n","         [158, 179, 194]],\n"," \n","        [[138, 128, 118],\n","         [136, 126, 116],\n","         [134, 124, 114],\n","         ...,\n","         [158, 179, 194],\n","         [158, 179, 194],\n","         [158, 179, 194]],\n"," \n","        ...,\n"," \n","        [[190, 194, 205],\n","         [190, 194, 205],\n","         [190, 194, 205],\n","         ...,\n","         [ 97, 110, 126],\n","         [ 97, 110, 126],\n","         [ 97, 110, 126]],\n"," \n","        [[190, 194, 205],\n","         [190, 194, 205],\n","         [190, 194, 205],\n","         ...,\n","         [ 97, 110, 126],\n","         [ 97, 110, 126],\n","         [ 97, 110, 126]],\n"," \n","        [[190, 194, 205],\n","         [190, 194, 205],\n","         [190, 194, 205],\n","         ...,\n","         [ 97, 110, 126],\n","         [ 97, 110, 126],\n","         [ 97, 110, 126]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Tan0914914_jpg.rf.4ae758f376dc11704b6f82d64d5b3233.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.356290817260742, 'inference': 7.23576545715332, 'postprocess': 1.3396739959716797},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[134, 124, 114],\n","         [134, 124, 114],\n","         [133, 123, 113],\n","         ...,\n","         [159, 180, 195],\n","         [159, 180, 195],\n","         [159, 180, 195]],\n"," \n","        [[135, 125, 115],\n","         [134, 124, 114],\n","         [133, 123, 113],\n","         ...,\n","         [159, 180, 195],\n","         [159, 180, 195],\n","         [159, 180, 195]],\n"," \n","        [[130, 120, 110],\n","         [131, 121, 111],\n","         [133, 123, 113],\n","         ...,\n","         [159, 180, 195],\n","         [159, 180, 195],\n","         [159, 180, 195]],\n"," \n","        ...,\n"," \n","        [[190, 192, 210],\n","         [190, 192, 210],\n","         [190, 192, 210],\n","         ...,\n","         [ 99, 112, 128],\n","         [ 99, 112, 128],\n","         [ 99, 112, 128]],\n"," \n","        [[190, 192, 210],\n","         [190, 192, 210],\n","         [190, 192, 210],\n","         ...,\n","         [ 99, 112, 128],\n","         [ 99, 112, 128],\n","         [ 99, 112, 128]],\n"," \n","        [[190, 192, 210],\n","         [190, 192, 210],\n","         [190, 192, 210],\n","         ...,\n","         [ 99, 112, 128],\n","         [ 99, 112, 128],\n","         [ 99, 112, 128]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Tan0972972_jpg.rf.30e8c8947ea307b1ada5658b25e843c3.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9869804382324219, 'inference': 7.1773529052734375, 'postprocess': 1.268148422241211},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 85,  83,  89],\n","         [ 83,  81,  87],\n","         [ 78,  76,  82],\n","         ...,\n","         [ 33,  35,  45],\n","         [ 33,  35,  45],\n","         [ 33,  35,  45]],\n"," \n","        [[ 84,  82,  88],\n","         [ 82,  80,  86],\n","         [ 79,  77,  83],\n","         ...,\n","         [ 33,  35,  45],\n","         [ 33,  35,  45],\n","         [ 33,  35,  45]],\n"," \n","        [[ 82,  80,  86],\n","         [ 81,  79,  85],\n","         [ 79,  77,  83],\n","         ...,\n","         [ 33,  35,  45],\n","         [ 33,  35,  45],\n","         [ 33,  35,  45]],\n"," \n","        ...,\n"," \n","        [[ 46,  44,  50],\n","         [ 46,  44,  50],\n","         [ 46,  44,  50],\n","         ...,\n","         [ 38, 150, 108],\n","         [ 38, 150, 108],\n","         [ 38, 150, 108]],\n"," \n","        [[ 46,  44,  50],\n","         [ 46,  44,  50],\n","         [ 46,  44,  50],\n","         ...,\n","         [ 38, 150, 110],\n","         [ 38, 150, 110],\n","         [ 38, 150, 110]],\n"," \n","        [[ 46,  44,  50],\n","         [ 46,  44,  50],\n","         [ 46,  44,  50],\n","         ...,\n","         [ 38, 150, 110],\n","         [ 38, 150, 110],\n","         [ 38, 150, 110]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/TsirinOne0031_jpg.rf.e9448793466117932b2748d321c0d807.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0570755004882812, 'inference': 7.186412811279297, 'postprocess': 1.4362335205078125},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 56,  54,  60],\n","         [ 56,  54,  60],\n","         [ 56,  54,  60],\n","         ...,\n","         [ 41,  43,  54],\n","         [ 41,  43,  54],\n","         [ 41,  43,  54]],\n"," \n","        [[ 57,  55,  61],\n","         [ 57,  55,  61],\n","         [ 57,  55,  61],\n","         ...,\n","         [ 41,  43,  54],\n","         [ 41,  43,  54],\n","         [ 41,  43,  54]],\n"," \n","        [[ 59,  57,  63],\n","         [ 59,  57,  63],\n","         [ 59,  57,  63],\n","         ...,\n","         [ 41,  43,  54],\n","         [ 41,  43,  54],\n","         [ 41,  43,  54]],\n"," \n","        ...,\n"," \n","        [[ 43,  41,  47],\n","         [ 43,  41,  47],\n","         [ 43,  41,  47],\n","         ...,\n","         [ 30, 145, 105],\n","         [ 30, 145, 105],\n","         [ 30, 145, 105]],\n"," \n","        [[ 43,  41,  47],\n","         [ 43,  41,  47],\n","         [ 43,  41,  47],\n","         ...,\n","         [ 29, 144, 105],\n","         [ 29, 144, 105],\n","         [ 29, 144, 105]],\n"," \n","        [[ 43,  41,  47],\n","         [ 43,  41,  47],\n","         [ 43,  41,  47],\n","         ...,\n","         [ 28, 143, 104],\n","         [ 28, 143, 104],\n","         [ 28, 143, 104]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/TsirinTu0047_jpg.rf.60d829abcce705bd69490d4ae826be7e.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9426345825195312, 'inference': 7.1659088134765625, 'postprocess': 1.346588134765625},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 98, 130, 135],\n","         [ 97, 127, 132],\n","         [111, 134, 142],\n","         ...,\n","         [215, 209, 214],\n","         [216, 209, 214],\n","         [216, 209, 214]],\n"," \n","        [[ 93, 125, 130],\n","         [ 95, 125, 130],\n","         [109, 132, 140],\n","         ...,\n","         [215, 209, 214],\n","         [216, 209, 214],\n","         [216, 209, 214]],\n"," \n","        [[ 93, 123, 128],\n","         [ 97, 126, 131],\n","         [114, 135, 143],\n","         ...,\n","         [215, 209, 214],\n","         [216, 209, 214],\n","         [216, 209, 214]],\n"," \n","        ...,\n"," \n","        [[ 50,  58,  58],\n","         [ 54,  62,  62],\n","         [ 49,  57,  57],\n","         ...,\n","         [138,  53,  31],\n","         [138,  53,  31],\n","         [137,  54,  32]],\n"," \n","        [[ 44,  52,  52],\n","         [ 47,  55,  55],\n","         [ 43,  51,  51],\n","         ...,\n","         [144,  57,  30],\n","         [144,  57,  30],\n","         [145,  58,  31]],\n"," \n","        [[ 40,  48,  48],\n","         [ 44,  52,  52],\n","         [ 40,  48,  48],\n","         ...,\n","         [149,  59,  29],\n","         [147,  59,  29],\n","         [148,  60,  30]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0247_jpg.rf.921166e067f6c367a5746e91633db683.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0580291748046875, 'inference': 7.167816162109375, 'postprocess': 1.3554096221923828},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 62,  62,  48],\n","         [ 71,  71,  57],\n","         [ 82,  81,  67],\n","         ...,\n","         [127, 127, 127],\n","         [137, 137, 137],\n","         [106, 106, 106]],\n"," \n","        [[ 70,  73,  58],\n","         [ 75,  78,  63],\n","         [ 86,  86,  72],\n","         ...,\n","         [140, 142, 142],\n","         [151, 153, 153],\n","         [120, 122, 122]],\n"," \n","        [[ 88,  95,  80],\n","         [ 87,  94,  79],\n","         [ 92,  97,  82],\n","         ...,\n","         [139, 143, 144],\n","         [149, 153, 154],\n","         [120, 124, 125]],\n"," \n","        ...,\n"," \n","        [[ 46,  49,  54],\n","         [ 46,  49,  54],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 75,  31,  14],\n","         [ 75,  31,  14],\n","         [ 75,  31,  14]],\n"," \n","        [[ 46,  49,  54],\n","         [ 46,  49,  54],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 76,  32,  15],\n","         [ 76,  32,  15],\n","         [ 76,  32,  15]],\n"," \n","        [[ 46,  49,  54],\n","         [ 46,  49,  54],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 76,  32,  15],\n","         [ 77,  33,  16],\n","         [ 77,  33,  16]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0512_jpg.rf.fab38e64446ae4740818f1d72a358fa0.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.026796340942383, 'inference': 7.159948348999023, 'postprocess': 1.3186931610107422},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 63,  66,  51],\n","         [ 71,  74,  59],\n","         [ 81,  81,  67],\n","         ...,\n","         [132, 134, 134],\n","         [127, 129, 129],\n","         [130, 132, 132]],\n"," \n","        [[ 69,  74,  59],\n","         [ 73,  78,  63],\n","         [ 83,  86,  71],\n","         ...,\n","         [143, 148, 147],\n","         [141, 146, 145],\n","         [145, 150, 149]],\n"," \n","        [[ 86,  96,  80],\n","         [ 84,  94,  78],\n","         [ 89,  96,  81],\n","         ...,\n","         [136, 144, 144],\n","         [133, 141, 141],\n","         [136, 144, 144]],\n"," \n","        ...,\n"," \n","        [[ 46,  49,  54],\n","         [ 46,  49,  54],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 74,  30,  13],\n","         [ 74,  30,  13],\n","         [ 75,  31,  14]],\n"," \n","        [[ 46,  49,  54],\n","         [ 46,  49,  54],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 75,  31,  14],\n","         [ 75,  31,  14],\n","         [ 75,  31,  14]],\n"," \n","        [[ 46,  49,  54],\n","         [ 46,  49,  54],\n","         [ 47,  50,  55],\n","         ...,\n","         [ 76,  32,  15],\n","         [ 76,  32,  15],\n","         [ 75,  31,  14]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0513_jpg.rf.56c013b83120e08f01c5d017c7d0e0a6.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9757747650146484, 'inference': 7.167816162109375, 'postprocess': 1.4955997467041016},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 23,  22,  32],\n","         [ 24,  23,  33],\n","         [ 22,  23,  33],\n","         ...,\n","         [  5, 147,  82],\n","         [  5, 147,  82],\n","         [  5, 147,  82]],\n"," \n","        [[ 22,  21,  31],\n","         [ 23,  22,  32],\n","         [ 21,  22,  32],\n","         ...,\n","         [  5, 147,  82],\n","         [  5, 147,  82],\n","         [  5, 147,  82]],\n"," \n","        [[ 22,  21,  31],\n","         [ 23,  22,  32],\n","         [ 21,  22,  32],\n","         ...,\n","         [  5, 147,  82],\n","         [  5, 147,  82],\n","         [  5, 147,  82]],\n"," \n","        ...,\n"," \n","        [[ 12,  18,  23],\n","         [ 12,  18,  23],\n","         [ 12,  18,  23],\n","         ...,\n","         [ 81,  64,  37],\n","         [ 79,  65,  37],\n","         [ 79,  65,  37]],\n"," \n","        [[ 12,  18,  23],\n","         [ 12,  18,  23],\n","         [ 12,  18,  23],\n","         ...,\n","         [ 79,  65,  37],\n","         [ 79,  65,  37],\n","         [ 79,  65,  37]],\n"," \n","        [[ 12,  18,  23],\n","         [ 12,  18,  23],\n","         [ 12,  18,  23],\n","         ...,\n","         [ 79,  65,  37],\n","         [ 79,  65,  37],\n","         [ 79,  65,  37]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv0611_jpg.rf.c339f0bdcdb8aef4d2db320fdcc2e901.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2521018981933594, 'inference': 7.323741912841797, 'postprocess': 1.5399456024169922},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 88,  96,  95],\n","         [ 88,  96,  95],\n","         [ 88,  96,  95],\n","         ...,\n","         [185, 186, 190],\n","         [185, 186, 190],\n","         [185, 186, 190]],\n"," \n","        [[ 97, 105, 104],\n","         [ 97, 105, 104],\n","         [ 97, 105, 104],\n","         ...,\n","         [185, 186, 190],\n","         [185, 186, 190],\n","         [185, 186, 190]],\n"," \n","        [[100, 108, 107],\n","         [100, 108, 107],\n","         [100, 108, 107],\n","         ...,\n","         [185, 186, 190],\n","         [185, 186, 190],\n","         [185, 186, 190]],\n"," \n","        ...,\n"," \n","        [[ 45,  42,  44],\n","         [ 48,  45,  47],\n","         [ 49,  46,  48],\n","         ...,\n","         [ 67,  66,  70],\n","         [ 67,  66,  70],\n","         [ 66,  65,  69]],\n"," \n","        [[ 46,  43,  45],\n","         [ 49,  46,  48],\n","         [ 49,  46,  48],\n","         ...,\n","         [ 67,  66,  70],\n","         [ 67,  66,  70],\n","         [ 66,  65,  69]],\n"," \n","        [[ 48,  45,  47],\n","         [ 49,  46,  48],\n","         [ 49,  46,  48],\n","         ...,\n","         [ 67,  66,  70],\n","         [ 67,  66,  70],\n","         [ 66,  65,  69]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Twalv1069_jpg.rf.108bfd873918d8b58cce197c2a722a1b.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.72369384765625, 'inference': 11.167049407958984, 'postprocess': 2.2797584533691406},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[233, 224, 221],\n","         [233, 224, 221],\n","         [234, 225, 222],\n","         ...,\n","         [238, 226, 226],\n","         [238, 226, 226],\n","         [238, 226, 226]],\n"," \n","        [[233, 224, 221],\n","         [233, 224, 221],\n","         [233, 224, 221],\n","         ...,\n","         [238, 226, 226],\n","         [238, 226, 226],\n","         [238, 226, 226]],\n"," \n","        [[232, 223, 220],\n","         [232, 223, 220],\n","         [233, 224, 221],\n","         ...,\n","         [238, 226, 226],\n","         [238, 226, 226],\n","         [238, 226, 226]],\n"," \n","        ...,\n"," \n","        [[184, 194, 204],\n","         [185, 195, 205],\n","         [186, 196, 206],\n","         ...,\n","         [199, 209, 219],\n","         [199, 209, 219],\n","         [199, 209, 219]],\n"," \n","        [[186, 196, 206],\n","         [187, 197, 207],\n","         [188, 198, 208],\n","         ...,\n","         [199, 208, 218],\n","         [198, 207, 217],\n","         [198, 207, 217]],\n"," \n","        [[188, 198, 208],\n","         [188, 198, 208],\n","         [189, 199, 209],\n","         ...,\n","         [197, 206, 216],\n","         [196, 205, 215],\n","         [196, 205, 215]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_0_jpg.rf.b307186eb19bf3f9cbaef03606084394.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0291805267333984, 'inference': 7.187366485595703, 'postprocess': 1.3532638549804688},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 99, 104,  89],\n","         [ 98, 103,  88],\n","         [ 97, 102,  87],\n","         ...,\n","         [167, 164, 160],\n","         [167, 164, 160],\n","         [167, 164, 160]],\n"," \n","        [[101, 106,  91],\n","         [100, 105,  90],\n","         [ 98, 103,  88],\n","         ...,\n","         [163, 162, 158],\n","         [165, 162, 158],\n","         [163, 162, 158]],\n"," \n","        [[102, 107,  92],\n","         [101, 106,  91],\n","         [ 99, 104,  89],\n","         ...,\n","         [162, 163, 161],\n","         [164, 162, 161],\n","         [162, 163, 161]],\n"," \n","        ...,\n"," \n","        [[184, 193, 202],\n","         [177, 186, 195],\n","         [186, 195, 204],\n","         ...,\n","         [213, 230, 233],\n","         [213, 230, 233],\n","         [213, 230, 233]],\n"," \n","        [[186, 195, 204],\n","         [181, 190, 199],\n","         [190, 199, 208],\n","         ...,\n","         [213, 230, 233],\n","         [213, 230, 233],\n","         [213, 230, 233]],\n"," \n","        [[191, 200, 209],\n","         [186, 195, 204],\n","         [196, 205, 214],\n","         ...,\n","         [213, 230, 233],\n","         [213, 230, 233],\n","         [213, 230, 233]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_163_jpg.rf.968f379c16daa15a48a82e9ba0675dde.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0241737365722656, 'inference': 7.199764251708984, 'postprocess': 1.7096996307373047},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[107, 108,  98],\n","         [107, 108,  98],\n","         [108, 110,  98],\n","         ...,\n","         [135, 147, 147],\n","         [135, 147, 147],\n","         [135, 147, 147]],\n"," \n","        [[106, 107,  97],\n","         [106, 107,  97],\n","         [107, 109,  97],\n","         ...,\n","         [133, 145, 145],\n","         [133, 145, 145],\n","         [133, 145, 145]],\n"," \n","        [[102, 106,  95],\n","         [102, 106,  95],\n","         [103, 107,  96],\n","         ...,\n","         [131, 143, 143],\n","         [131, 143, 143],\n","         [131, 143, 143]],\n"," \n","        ...,\n"," \n","        [[174, 184, 194],\n","         [176, 186, 196],\n","         [181, 191, 201],\n","         ...,\n","         [215, 230, 233],\n","         [215, 230, 233],\n","         [215, 230, 233]],\n"," \n","        [[155, 166, 174],\n","         [157, 168, 176],\n","         [162, 173, 181],\n","         ...,\n","         [215, 230, 233],\n","         [215, 230, 233],\n","         [215, 230, 233]],\n"," \n","        [[140, 151, 159],\n","         [140, 151, 159],\n","         [147, 158, 166],\n","         ...,\n","         [215, 230, 233],\n","         [215, 230, 233],\n","         [215, 230, 233]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_167_jpg.rf.2d6eea6c7b1989609a862135cc64d100.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.026796340942383, 'inference': 7.186412811279297, 'postprocess': 1.3592243194580078},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 80,  86,  67],\n","         [ 79,  85,  66],\n","         [ 79,  85,  66],\n","         ...,\n","         [252, 237, 234],\n","         [252, 237, 234],\n","         [252, 237, 234]],\n"," \n","        [[ 98, 104,  85],\n","         [ 98, 104,  85],\n","         [ 97, 103,  84],\n","         ...,\n","         [252, 237, 234],\n","         [252, 237, 234],\n","         [252, 237, 234]],\n"," \n","        [[ 88,  94,  77],\n","         [ 87,  93,  76],\n","         [ 87,  93,  76],\n","         ...,\n","         [252, 237, 234],\n","         [252, 237, 234],\n","         [252, 237, 234]],\n"," \n","        ...,\n"," \n","        [[185, 195, 205],\n","         [185, 195, 205],\n","         [186, 196, 206],\n","         ...,\n","         [209, 218, 228],\n","         [209, 218, 228],\n","         [209, 218, 228]],\n"," \n","        [[194, 204, 214],\n","         [194, 204, 214],\n","         [195, 205, 215],\n","         ...,\n","         [209, 218, 228],\n","         [209, 218, 228],\n","         [209, 218, 228]],\n"," \n","        [[202, 212, 222],\n","         [202, 212, 222],\n","         [202, 212, 222],\n","         ...,\n","         [209, 218, 228],\n","         [209, 218, 228],\n","         [209, 218, 228]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_174_jpg.rf.9c80e740ec871bcfc9e32c3bfa7061de.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2547245025634766, 'inference': 9.858846664428711, 'postprocess': 1.4243125915527344},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[106, 108,  96],\n","         [104, 106,  94],\n","         [104, 106,  94],\n","         ...,\n","         [242, 230, 226],\n","         [242, 230, 226],\n","         [242, 230, 226]],\n"," \n","        [[105, 107,  95],\n","         [102, 104,  92],\n","         [100, 102,  90],\n","         ...,\n","         [242, 230, 226],\n","         [242, 230, 226],\n","         [242, 230, 226]],\n"," \n","        [[108, 110,  98],\n","         [104, 106,  94],\n","         [100, 102,  90],\n","         ...,\n","         [242, 230, 226],\n","         [242, 230, 226],\n","         [242, 230, 226]],\n"," \n","        ...,\n"," \n","        [[162, 172, 182],\n","         [162, 172, 182],\n","         [157, 167, 177],\n","         ...,\n","         [200, 215, 218],\n","         [200, 215, 218],\n","         [200, 215, 218]],\n"," \n","        [[134, 144, 154],\n","         [136, 146, 156],\n","         [138, 148, 158],\n","         ...,\n","         [201, 216, 219],\n","         [201, 216, 219],\n","         [201, 216, 219]],\n"," \n","        [[147, 157, 167],\n","         [155, 165, 175],\n","         [168, 178, 188],\n","         ...,\n","         [202, 217, 220],\n","         [202, 217, 220],\n","         [202, 217, 220]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_177_jpg.rf.d798ca65cb6e91a608bd148910b12696.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0227432250976562, 'inference': 7.184028625488281, 'postprocess': 1.3880729675292969},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[161, 167, 148],\n","         [154, 160, 141],\n","         [146, 152, 133],\n","         ...,\n","         [238, 226, 222],\n","         [238, 226, 222],\n","         [238, 226, 222]],\n"," \n","        [[162, 168, 149],\n","         [155, 161, 142],\n","         [147, 153, 134],\n","         ...,\n","         [238, 226, 222],\n","         [238, 226, 222],\n","         [238, 226, 222]],\n"," \n","        [[163, 169, 150],\n","         [157, 163, 144],\n","         [150, 156, 137],\n","         ...,\n","         [238, 226, 222],\n","         [238, 226, 222],\n","         [238, 226, 222]],\n"," \n","        ...,\n"," \n","        [[138, 147, 156],\n","         [134, 145, 153],\n","         [136, 145, 154],\n","         ...,\n","         [126, 141, 150],\n","         [ 99, 114, 123],\n","         [ 80,  95, 104]],\n"," \n","        [[167, 179, 185],\n","         [167, 181, 187],\n","         [177, 189, 195],\n","         ...,\n","         [177, 194, 203],\n","         [161, 178, 187],\n","         [149, 166, 175]],\n"," \n","        [[181, 195, 201],\n","         [185, 199, 205],\n","         [187, 201, 207],\n","         ...,\n","         [199, 216, 225],\n","         [198, 215, 224],\n","         [196, 213, 222]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_179_jpg.rf.157d4d2a19107d6ad66b964d8d0fa436.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1975040435791016, 'inference': 7.250785827636719, 'postprocess': 1.4569759368896484},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[168, 170, 158],\n","         [163, 165, 153],\n","         [158, 160, 148],\n","         ...,\n","         [250, 235, 232],\n","         [250, 235, 232],\n","         [250, 235, 232]],\n"," \n","        [[151, 153, 141],\n","         [142, 144, 132],\n","         [130, 132, 120],\n","         ...,\n","         [249, 234, 231],\n","         [250, 235, 232],\n","         [250, 235, 232]],\n"," \n","        [[169, 171, 159],\n","         [152, 154, 142],\n","         [128, 130, 118],\n","         ...,\n","         [249, 234, 231],\n","         [249, 234, 231],\n","         [250, 235, 232]],\n"," \n","        ...,\n"," \n","        [[178, 186, 199],\n","         [162, 171, 184],\n","         [139, 147, 160],\n","         ...,\n","         [203, 220, 229],\n","         [203, 220, 229],\n","         [203, 220, 229]],\n"," \n","        [[109, 118, 131],\n","         [116, 128, 140],\n","         [134, 143, 156],\n","         ...,\n","         [202, 221, 229],\n","         [202, 221, 229],\n","         [202, 221, 229]],\n"," \n","        [[180, 192, 204],\n","         [178, 190, 202],\n","         [179, 191, 203],\n","         ...,\n","         [202, 221, 229],\n","         [202, 221, 229],\n","         [202, 221, 229]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_180_jpg.rf.c5f87cd2627d86c53024895f60a00aa8.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9555091857910156, 'inference': 7.171392440795898, 'postprocess': 1.2617111206054688},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[137, 140, 131],\n","         [135, 138, 129],\n","         [131, 133, 127],\n","         ...,\n","         [228, 214, 208],\n","         [228, 214, 208],\n","         [228, 214, 208]],\n"," \n","        [[162, 165, 156],\n","         [163, 166, 157],\n","         [165, 168, 159],\n","         ...,\n","         [228, 214, 208],\n","         [228, 214, 208],\n","         [228, 214, 208]],\n"," \n","        [[125, 129, 118],\n","         [133, 137, 126],\n","         [144, 148, 137],\n","         ...,\n","         [227, 213, 207],\n","         [227, 213, 207],\n","         [227, 213, 207]],\n"," \n","        ...,\n"," \n","        [[204, 213, 223],\n","         [204, 213, 223],\n","         [204, 213, 223],\n","         ...,\n","         [210, 220, 230],\n","         [208, 218, 228],\n","         [208, 218, 228]],\n"," \n","        [[203, 212, 222],\n","         [204, 213, 223],\n","         [204, 213, 223],\n","         ...,\n","         [211, 221, 231],\n","         [210, 220, 230],\n","         [209, 219, 229]],\n"," \n","        [[202, 211, 221],\n","         [202, 211, 221],\n","         [203, 212, 222],\n","         ...,\n","         [212, 222, 232],\n","         [211, 221, 231],\n","         [211, 221, 231]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_184_jpg.rf.b9bf8fa565bdbf1a0aeec2374ad0e2e6.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.117156982421875, 'inference': 7.204532623291016, 'postprocess': 1.379251480102539},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[116, 121, 124],\n","         [116, 121, 124],\n","         [116, 121, 124],\n","         ...,\n","         [224, 209, 206],\n","         [224, 209, 206],\n","         [224, 209, 206]],\n"," \n","        [[116, 121, 124],\n","         [116, 121, 124],\n","         [116, 121, 124],\n","         ...,\n","         [224, 209, 206],\n","         [224, 209, 206],\n","         [224, 209, 206]],\n"," \n","        [[114, 119, 122],\n","         [114, 119, 122],\n","         [114, 119, 122],\n","         ...,\n","         [224, 209, 206],\n","         [224, 209, 206],\n","         [224, 209, 206]],\n"," \n","        ...,\n"," \n","        [[187, 198, 206],\n","         [187, 198, 206],\n","         [187, 198, 206],\n","         ...,\n","         [197, 206, 215],\n","         [197, 206, 215],\n","         [197, 206, 215]],\n"," \n","        [[188, 197, 206],\n","         [188, 197, 206],\n","         [188, 197, 206],\n","         ...,\n","         [198, 207, 216],\n","         [198, 207, 216],\n","         [198, 207, 216]],\n"," \n","        [[188, 197, 206],\n","         [188, 197, 206],\n","         [188, 197, 206],\n","         ...,\n","         [199, 208, 217],\n","         [199, 208, 217],\n","         [199, 208, 217]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_186_jpg.rf.f4cbf4eb986b83adf8a1ef9584cf18b8.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.066373825073242, 'inference': 7.229804992675781, 'postprocess': 1.3418197631835938},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[155, 164, 167],\n","         [153, 162, 165],\n","         [149, 158, 161],\n","         ...,\n","         [220, 208, 204],\n","         [220, 208, 204],\n","         [220, 208, 204]],\n"," \n","        [[137, 146, 149],\n","         [139, 148, 151],\n","         [143, 152, 155],\n","         ...,\n","         [220, 208, 204],\n","         [220, 208, 204],\n","         [220, 208, 204]],\n"," \n","        [[ 83,  92,  95],\n","         [ 89,  98, 101],\n","         [ 99, 108, 111],\n","         ...,\n","         [220, 208, 204],\n","         [220, 208, 204],\n","         [220, 208, 204]],\n"," \n","        ...,\n"," \n","        [[176, 191, 193],\n","         [175, 190, 192],\n","         [174, 189, 191],\n","         ...,\n","         [115, 130, 133],\n","         [120, 135, 138],\n","         [124, 139, 142]],\n"," \n","        [[169, 184, 187],\n","         [170, 185, 188],\n","         [170, 185, 187],\n","         ...,\n","         [117, 132, 135],\n","         [118, 133, 136],\n","         [119, 134, 137]],\n"," \n","        [[177, 192, 195],\n","         [180, 195, 198],\n","         [181, 196, 198],\n","         ...,\n","         [138, 153, 156],\n","         [140, 155, 158],\n","         [142, 157, 160]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_189_jpg.rf.734a8e52c70646ca3295f60fb06f3644.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0873546600341797, 'inference': 7.579803466796875, 'postprocess': 1.36566162109375},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 92,  88,  93],\n","         [ 99,  95, 100],\n","         [111, 107, 112],\n","         ...,\n","         [229, 217, 213],\n","         [229, 217, 213],\n","         [229, 217, 213]],\n"," \n","        [[ 88,  84,  89],\n","         [ 95,  91,  96],\n","         [108, 104, 109],\n","         ...,\n","         [229, 217, 213],\n","         [229, 217, 213],\n","         [229, 217, 213]],\n"," \n","        [[ 82,  78,  83],\n","         [ 89,  85,  90],\n","         [102,  98, 103],\n","         ...,\n","         [230, 218, 214],\n","         [230, 218, 214],\n","         [230, 218, 214]],\n"," \n","        ...,\n"," \n","        [[189, 195, 200],\n","         [189, 195, 200],\n","         [189, 195, 200],\n","         ...,\n","         [163, 175, 177],\n","         [163, 175, 177],\n","         [163, 175, 177]],\n"," \n","        [[189, 195, 200],\n","         [189, 195, 200],\n","         [189, 195, 200],\n","         ...,\n","         [170, 181, 185],\n","         [170, 181, 185],\n","         [170, 181, 185]],\n"," \n","        [[189, 195, 200],\n","         [189, 195, 200],\n","         [189, 195, 200],\n","         ...,\n","         [175, 186, 190],\n","         [175, 186, 190],\n","         [175, 186, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/Video1_190_jpg.rf.77f247e46c96e3a386cbc1931acdd7f3.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0971298217773438, 'inference': 7.24029541015625, 'postprocess': 2.953052520751953},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 66,  55,  57],\n","         [ 41,  33,  34],\n","         [ 43,  35,  36],\n","         ...,\n","         [ 95, 110, 102],\n","         [ 93, 110, 101],\n","         [ 97, 114, 105]],\n"," \n","        [[ 75,  64,  66],\n","         [ 60,  52,  53],\n","         [ 55,  47,  48],\n","         ...,\n","         [ 83, 100,  91],\n","         [ 82,  99,  90],\n","         [ 89, 106,  97]],\n"," \n","        [[ 82,  71,  73],\n","         [ 77,  69,  70],\n","         [ 62,  54,  55],\n","         ...,\n","         [ 87, 106,  97],\n","         [ 94, 113, 104],\n","         [107, 126, 117]],\n"," \n","        ...,\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [156, 169, 185],\n","         [156, 169, 185],\n","         [156, 169, 185]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [158, 171, 187],\n","         [158, 171, 187],\n","         [158, 171, 187]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [160, 173, 189],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_150_jpg.rf.2682e3010f1b052f4b70ea9da21e8680.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0592212677001953, 'inference': 7.500171661376953, 'postprocess': 1.4023780822753906},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 39,  32,  37],\n","         [ 48,  39,  42],\n","         [ 73,  61,  61],\n","         ...,\n","         [ 15,  16,  14],\n","         [ 18,  19,  17],\n","         [ 27,  28,  26]],\n"," \n","        [[ 56,  49,  54],\n","         [ 54,  45,  48],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 21,  22,  20],\n","         [ 25,  26,  24],\n","         [ 35,  36,  34]],\n"," \n","        [[ 66,  59,  64],\n","         [ 57,  48,  51],\n","         [ 61,  49,  49],\n","         ...,\n","         [ 26,  27,  25],\n","         [ 33,  34,  32],\n","         [ 43,  44,  42]],\n"," \n","        ...,\n"," \n","        [[211, 221, 238],\n","         [211, 221, 238],\n","         [211, 221, 238],\n","         ...,\n","         [159, 171, 189],\n","         [160, 172, 190],\n","         [160, 172, 190]],\n"," \n","        [[213, 223, 240],\n","         [213, 223, 240],\n","         [213, 223, 240],\n","         ...,\n","         [158, 170, 188],\n","         [159, 171, 189],\n","         [159, 171, 189]],\n"," \n","        [[214, 224, 241],\n","         [214, 224, 241],\n","         [214, 224, 241],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_150_jpg.rf.f0784e2bb2379fc727e344a8b12de3ca.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9936561584472656, 'inference': 7.196187973022461, 'postprocess': 1.4154911041259766},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 31,  37,  44],\n","         [ 66,  69,  74],\n","         [ 65,  59,  60],\n","         ...,\n","         [ 19,  20,  16],\n","         [ 26,  27,  23],\n","         [ 32,  33,  29]],\n"," \n","        [[ 32,  38,  45],\n","         [ 64,  67,  72],\n","         [ 62,  56,  57],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 29,  30,  26],\n","         [ 36,  37,  33]],\n"," \n","        [[ 33,  36,  44],\n","         [ 62,  62,  68],\n","         [ 61,  53,  54],\n","         ...,\n","         [ 22,  23,  19],\n","         [ 32,  33,  29],\n","         [ 40,  41,  37]],\n"," \n","        ...,\n"," \n","        [[207, 214, 234],\n","         [207, 214, 234],\n","         [207, 214, 234],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 214, 234],\n","         [207, 214, 234],\n","         [207, 214, 234],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[207, 214, 234],\n","         [207, 214, 234],\n","         [207, 214, 234],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153-1-_jpg.rf.ab2badf32a4bdc61c1f2aaee0868555f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0432472229003906, 'inference': 7.239580154418945, 'postprocess': 1.4624595642089844},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 42,  38,  43],\n","         [ 68,  63,  65],\n","         [ 66,  56,  56],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 27,  30,  28],\n","         [ 27,  30,  28]],\n"," \n","        [[ 54,  50,  55],\n","         [ 74,  69,  71],\n","         [ 70,  60,  60],\n","         ...,\n","         [ 21,  24,  22],\n","         [ 33,  36,  34],\n","         [ 33,  36,  34]],\n"," \n","        [[ 54,  50,  55],\n","         [ 66,  61,  63],\n","         [ 60,  50,  50],\n","         ...,\n","         [ 23,  26,  24],\n","         [ 37,  40,  38],\n","         [ 38,  41,  39]],\n"," \n","        ...,\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[215, 223, 240],\n","         [215, 223, 240],\n","         [215, 223, 240],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[216, 224, 241],\n","         [216, 224, 241],\n","         [216, 224, 241],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.8b203750f32c92b4f82c4215e49605b3.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.060413360595703, 'inference': 7.203340530395508, 'postprocess': 3.4651756286621094},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  26,  31],\n","         [ 53,  48,  50],\n","         [ 71,  61,  61],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 23,  26,  24],\n","         [ 28,  31,  29]],\n"," \n","        [[ 42,  38,  43],\n","         [ 57,  52,  54],\n","         [ 65,  55,  55],\n","         ...,\n","         [ 19,  22,  20],\n","         [ 26,  29,  27],\n","         [ 32,  35,  33]],\n"," \n","        [[ 49,  45,  50],\n","         [ 58,  53,  55],\n","         [ 58,  48,  48],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 28,  31,  29],\n","         [ 35,  38,  36]],\n"," \n","        ...,\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [162, 175, 201],\n","         [163, 176, 202],\n","         [163, 176, 202]],\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [161, 174, 200],\n","         [162, 175, 201],\n","         [162, 175, 201]],\n"," \n","        [[197, 205, 228],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [161, 174, 200],\n","         [162, 175, 201],\n","         [162, 175, 201]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.908446806ebe6ef21a4b35cf11090082.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0973682403564453, 'inference': 8.448362350463867, 'postprocess': 1.3892650604248047},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[105, 102, 104],\n","         [107, 104, 106],\n","         [ 97,  94,  96],\n","         ...,\n","         [126, 125, 121],\n","         [214, 214, 208],\n","         [255, 255, 249]],\n"," \n","        [[130, 127, 129],\n","         [104, 101, 103],\n","         [ 80,  77,  79],\n","         ...,\n","         [194, 193, 189],\n","         [248, 248, 242],\n","         [250, 250, 244]],\n"," \n","        [[148, 145, 147],\n","         [106, 103, 105],\n","         [ 75,  72,  74],\n","         ...,\n","         [240, 239, 235],\n","         [255, 255, 251],\n","         [239, 239, 233]],\n"," \n","        ...,\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [161, 173, 191],\n","         [160, 172, 190],\n","         [160, 172, 190]],\n"," \n","        [[199, 208, 222],\n","         [199, 208, 222],\n","         [199, 208, 222],\n","         ...,\n","         [161, 173, 191],\n","         [161, 173, 191],\n","         [161, 173, 191]],\n"," \n","        [[199, 208, 222],\n","         [199, 208, 222],\n","         [199, 208, 222],\n","         ...,\n","         [161, 173, 191],\n","         [162, 174, 192],\n","         [161, 173, 191]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.a1454369a44488c0d6c89b4bbf56b337.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.086639404296875, 'inference': 7.184743881225586, 'postprocess': 1.3184547424316406},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  26,  31],\n","         [ 53,  48,  50],\n","         [ 71,  61,  61],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 23,  26,  24],\n","         [ 28,  31,  29]],\n"," \n","        [[ 42,  38,  43],\n","         [ 57,  52,  54],\n","         [ 65,  55,  55],\n","         ...,\n","         [ 19,  22,  20],\n","         [ 26,  29,  27],\n","         [ 32,  35,  33]],\n"," \n","        [[ 49,  45,  50],\n","         [ 58,  53,  55],\n","         [ 58,  48,  48],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 28,  31,  29],\n","         [ 35,  38,  36]],\n"," \n","        ...,\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [162, 175, 201],\n","         [163, 176, 202],\n","         [163, 176, 202]],\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [161, 174, 200],\n","         [162, 175, 201],\n","         [162, 175, 201]],\n"," \n","        [[197, 205, 228],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [161, 174, 200],\n","         [162, 175, 201],\n","         [162, 175, 201]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_153_jpg.rf.f463b2513b1772a8ff7d70f24fb06d7d.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2430419921875, 'inference': 7.211923599243164, 'postprocess': 1.5952587127685547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 26,  28,  46],\n","         [ 62,  62,  76],\n","         [ 65,  55,  67],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 25,  26,  24],\n","         [ 30,  31,  29]],\n"," \n","        [[ 35,  37,  55],\n","         [ 65,  65,  79],\n","         [ 60,  51,  61],\n","         ...,\n","         [ 21,  22,  20],\n","         [ 28,  29,  27],\n","         [ 33,  34,  32]],\n"," \n","        [[ 41,  41,  57],\n","         [ 66,  63,  78],\n","         [ 60,  49,  59],\n","         ...,\n","         [ 21,  22,  20],\n","         [ 29,  30,  28],\n","         [ 35,  36,  34]],\n"," \n","        ...,\n"," \n","        [[208, 215, 235],\n","         [208, 215, 235],\n","         [208, 215, 235],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[209, 216, 236],\n","         [209, 216, 236],\n","         [209, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[208, 215, 235],\n","         [208, 215, 235],\n","         [208, 215, 235],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_154_jpg.rf.530c6b4b5279017605ae83c89e0ac4c6.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0401477813720703, 'inference': 7.231235504150391, 'postprocess': 1.5609264373779297},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 39,  32,  37],\n","         [ 52,  43,  46],\n","         [ 69,  57,  57],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 22,  25,  23],\n","         [ 27,  30,  28]],\n"," \n","        [[ 51,  44,  49],\n","         [ 57,  48,  51],\n","         [ 61,  49,  49],\n","         ...,\n","         [ 15,  18,  16],\n","         [ 20,  23,  21],\n","         [ 26,  29,  27]],\n"," \n","        [[ 58,  51,  56],\n","         [ 62,  53,  56],\n","         [ 56,  44,  44],\n","         ...,\n","         [ 15,  18,  16],\n","         [ 25,  28,  26],\n","         [ 34,  37,  35]],\n"," \n","        ...,\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [167, 180, 202]],\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [168, 181, 203]],\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [168, 181, 203]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_154_jpg.rf.8d174d7aaa90ce4dad8855ac085bf7cc.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1338462829589844, 'inference': 7.230520248413086, 'postprocess': 1.573324203491211},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 39,  32,  37],\n","         [ 52,  43,  46],\n","         [ 69,  57,  57],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 22,  25,  23],\n","         [ 27,  30,  28]],\n"," \n","        [[ 51,  44,  49],\n","         [ 57,  48,  51],\n","         [ 61,  49,  49],\n","         ...,\n","         [ 15,  18,  16],\n","         [ 20,  23,  21],\n","         [ 26,  29,  27]],\n"," \n","        [[ 58,  51,  56],\n","         [ 62,  53,  56],\n","         [ 56,  44,  44],\n","         ...,\n","         [ 15,  18,  16],\n","         [ 25,  28,  26],\n","         [ 34,  37,  35]],\n"," \n","        ...,\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [167, 180, 202]],\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [168, 181, 203]],\n"," \n","        [[198, 206, 229],\n","         [198, 206, 229],\n","         [198, 206, 229],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [168, 181, 203]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_154_jpg.rf.ff64dc1915cd89265cc5bb6fbce11230.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.054929733276367, 'inference': 7.236719131469727, 'postprocess': 1.4617443084716797},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 23,  22,  31],\n","         [ 67,  63,  69],\n","         [ 74,  61,  63],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 22,  25,  23],\n","         [ 27,  30,  28]],\n"," \n","        [[ 33,  32,  41],\n","         [ 69,  65,  71],\n","         [ 70,  57,  59],\n","         ...,\n","         [ 21,  24,  22],\n","         [ 29,  32,  30],\n","         [ 35,  38,  36]],\n"," \n","        [[ 41,  40,  49],\n","         [ 70,  66,  72],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 33,  36,  34],\n","         [ 40,  43,  41]],\n"," \n","        ...,\n"," \n","        [[207, 216, 236],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 216, 236],\n","         [207, 216, 236],\n","         [207, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[206, 215, 235],\n","         [206, 215, 235],\n","         [206, 215, 235],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.6dd06cd06be11270a04462bbba76a465.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.065896987915039, 'inference': 7.238864898681641, 'postprocess': 1.4505386352539062},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 35,  36,  40],\n","         [ 51,  48,  50],\n","         [ 70,  58,  58],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 24,  27,  25],\n","         [ 27,  30,  28]],\n"," \n","        [[ 49,  50,  54],\n","         [ 58,  55,  57],\n","         [ 64,  52,  52],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 29,  32,  30],\n","         [ 33,  36,  34]],\n"," \n","        [[ 56,  57,  61],\n","         [ 63,  60,  62],\n","         [ 61,  49,  49],\n","         ...,\n","         [ 26,  29,  27],\n","         [ 33,  36,  34],\n","         [ 38,  41,  39]],\n"," \n","        ...,\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[209, 219, 236],\n","         [209, 219, 236],\n","         [209, 219, 236],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.a1ebbcb68d49941048ad6341d0e5c8b0.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0439624786376953, 'inference': 7.227420806884766, 'postprocess': 1.3818740844726562},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 23,  22,  31],\n","         [ 67,  63,  69],\n","         [ 74,  61,  63],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 22,  25,  23],\n","         [ 27,  30,  28]],\n"," \n","        [[ 33,  32,  41],\n","         [ 69,  65,  71],\n","         [ 70,  57,  59],\n","         ...,\n","         [ 21,  24,  22],\n","         [ 29,  32,  30],\n","         [ 35,  38,  36]],\n"," \n","        [[ 41,  40,  49],\n","         [ 70,  66,  72],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 33,  36,  34],\n","         [ 40,  43,  41]],\n"," \n","        ...,\n"," \n","        [[207, 216, 236],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 216, 236],\n","         [207, 216, 236],\n","         [207, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[206, 215, 235],\n","         [206, 215, 235],\n","         [206, 215, 235],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.ac0bca8f72606b91436759e908f42acd.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.210378646850586, 'inference': 7.205963134765625, 'postprocess': 1.4083385467529297},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 35,  36,  40],\n","         [ 51,  48,  50],\n","         [ 70,  58,  58],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 24,  27,  25],\n","         [ 27,  30,  28]],\n"," \n","        [[ 49,  50,  54],\n","         [ 58,  55,  57],\n","         [ 64,  52,  52],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 29,  32,  30],\n","         [ 33,  36,  34]],\n"," \n","        [[ 56,  57,  61],\n","         [ 63,  60,  62],\n","         [ 61,  49,  49],\n","         ...,\n","         [ 26,  29,  27],\n","         [ 33,  36,  34],\n","         [ 38,  41,  39]],\n"," \n","        ...,\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[209, 219, 236],\n","         [209, 219, 236],\n","         [209, 219, 236],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_155_jpg.rf.f6cd576f497802ff62c8b9b7516d8a6f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1321773529052734, 'inference': 7.243871688842773, 'postprocess': 2.6988983154296875},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 35,  31,  36],\n","         [ 56,  51,  53],\n","         [ 70,  60,  60],\n","         ...,\n","         [ 14,  15,  13],\n","         [ 20,  21,  19],\n","         [ 29,  30,  28]],\n"," \n","        [[ 47,  43,  48],\n","         [ 58,  53,  55],\n","         [ 61,  51,  51],\n","         ...,\n","         [ 16,  17,  15],\n","         [ 23,  24,  22],\n","         [ 32,  33,  31]],\n"," \n","        [[ 53,  49,  54],\n","         [ 57,  52,  54],\n","         [ 53,  43,  43],\n","         ...,\n","         [ 17,  18,  16],\n","         [ 25,  26,  24],\n","         [ 34,  35,  33]],\n"," \n","        ...,\n"," \n","        [[202, 210, 233],\n","         [202, 210, 233],\n","         [202, 210, 233],\n","         ...,\n","         [163, 177, 199],\n","         [165, 179, 201],\n","         [166, 180, 202]],\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [163, 177, 199],\n","         [165, 179, 201],\n","         [166, 180, 202]],\n"," \n","        [[202, 210, 233],\n","         [202, 210, 233],\n","         [202, 210, 233],\n","         ...,\n","         [163, 177, 199],\n","         [165, 179, 201],\n","         [166, 180, 202]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_156_jpg.rf.0a1c2b7c4dd6a6ca8566010007cf22dd.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.130746841430664, 'inference': 7.194042205810547, 'postprocess': 1.3494491577148438},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  29,  38],\n","         [ 61,  57,  63],\n","         [ 62,  49,  51],\n","         ...,\n","         [ 18,  19,  17],\n","         [ 21,  22,  20],\n","         [ 24,  25,  23]],\n"," \n","        [[ 38,  37,  46],\n","         [ 66,  62,  68],\n","         [ 62,  49,  51],\n","         ...,\n","         [ 24,  25,  23],\n","         [ 29,  30,  28],\n","         [ 34,  35,  33]],\n"," \n","        [[ 44,  43,  52],\n","         [ 69,  65,  71],\n","         [ 65,  52,  54],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 35,  36,  34],\n","         [ 41,  42,  40]],\n"," \n","        ...,\n"," \n","        [[208, 217, 237],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[205, 214, 234],\n","         [205, 214, 234],\n","         [206, 215, 235],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[202, 211, 231],\n","         [202, 211, 231],\n","         [203, 212, 232],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_156_jpg.rf.c6d967fd444b9b55009eeec746fa9aef.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0766258239746094, 'inference': 7.224321365356445, 'postprocess': 1.3551712036132812},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  29,  38],\n","         [ 61,  57,  63],\n","         [ 62,  49,  51],\n","         ...,\n","         [ 18,  19,  17],\n","         [ 21,  22,  20],\n","         [ 24,  25,  23]],\n"," \n","        [[ 38,  37,  46],\n","         [ 66,  62,  68],\n","         [ 62,  49,  51],\n","         ...,\n","         [ 24,  25,  23],\n","         [ 29,  30,  28],\n","         [ 34,  35,  33]],\n"," \n","        [[ 44,  43,  52],\n","         [ 69,  65,  71],\n","         [ 65,  52,  54],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 35,  36,  34],\n","         [ 41,  42,  40]],\n"," \n","        ...,\n"," \n","        [[208, 217, 237],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[205, 214, 234],\n","         [205, 214, 234],\n","         [206, 215, 235],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[202, 211, 231],\n","         [202, 211, 231],\n","         [203, 212, 232],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_156_jpg.rf.da01bc87c9b609a7cf931db5cef0c6e6.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9824504852294922, 'inference': 7.175683975219727, 'postprocess': 1.3206005096435547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  37,  40],\n","         [ 55,  60,  61],\n","         [ 51,  47,  46],\n","         ...,\n","         [ 13,  16,  14],\n","         [ 17,  20,  18],\n","         [ 20,  23,  21]],\n"," \n","        [[ 25,  34,  37],\n","         [ 54,  59,  60],\n","         [ 52,  48,  47],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 21,  24,  22],\n","         [ 26,  29,  27]],\n"," \n","        [[ 28,  35,  38],\n","         [ 54,  58,  59],\n","         [ 55,  50,  49],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 25,  28,  26],\n","         [ 30,  33,  31]],\n"," \n","        ...,\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [163, 176, 202],\n","         [165, 178, 204],\n","         [166, 179, 205]],\n"," \n","        [[204, 212, 235],\n","         [204, 212, 235],\n","         [204, 212, 235],\n","         ...,\n","         [163, 176, 202],\n","         [165, 178, 204],\n","         [166, 179, 205]],\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [163, 176, 202],\n","         [165, 178, 204],\n","         [166, 179, 205]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_157_jpg.rf.7bc7a065c9f381442f0b0c84f4d4b131.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.097606658935547, 'inference': 7.210731506347656, 'postprocess': 1.377105712890625},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  37,  40],\n","         [ 55,  60,  61],\n","         [ 51,  47,  46],\n","         ...,\n","         [ 13,  16,  14],\n","         [ 17,  20,  18],\n","         [ 20,  23,  21]],\n"," \n","        [[ 25,  34,  37],\n","         [ 54,  59,  60],\n","         [ 52,  48,  47],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 21,  24,  22],\n","         [ 26,  29,  27]],\n"," \n","        [[ 28,  35,  38],\n","         [ 54,  58,  59],\n","         [ 55,  50,  49],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 25,  28,  26],\n","         [ 30,  33,  31]],\n"," \n","        ...,\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [163, 176, 202],\n","         [165, 178, 204],\n","         [166, 179, 205]],\n"," \n","        [[204, 212, 235],\n","         [204, 212, 235],\n","         [204, 212, 235],\n","         ...,\n","         [163, 176, 202],\n","         [165, 178, 204],\n","         [166, 179, 205]],\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [163, 176, 202],\n","         [165, 178, 204],\n","         [166, 179, 205]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_157_jpg.rf.9d7d938f62f9543d9710f3fb3806ff99.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.157926559448242, 'inference': 7.221698760986328, 'postprocess': 1.3506412506103516},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 29,  38,  41],\n","         [ 48,  53,  54],\n","         [ 62,  58,  57],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 19,  22,  20],\n","         [ 23,  26,  24]],\n"," \n","        [[ 32,  41,  44],\n","         [ 45,  50,  51],\n","         [ 53,  49,  48],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 22,  25,  23],\n","         [ 26,  29,  27]],\n"," \n","        [[ 39,  46,  49],\n","         [ 45,  49,  50],\n","         [ 47,  42,  41],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 24,  27,  25],\n","         [ 29,  32,  30]],\n"," \n","        ...,\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [164, 177, 203],\n","         [166, 179, 205],\n","         [167, 180, 206]],\n"," \n","        [[204, 212, 235],\n","         [204, 212, 235],\n","         [204, 212, 235],\n","         ...,\n","         [165, 178, 204],\n","         [167, 180, 206],\n","         [168, 181, 207]],\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [165, 178, 204],\n","         [167, 180, 206],\n","         [168, 181, 207]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.184363d039129a4530440fd47b993f45.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.046823501586914, 'inference': 7.21287727355957, 'postprocess': 1.4319419860839844},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 45,  40,  37],\n","         [ 47,  42,  39],\n","         [ 49,  46,  42],\n","         ...,\n","         [ 83, 105,  93],\n","         [ 90, 112, 100],\n","         [100, 122, 110]],\n"," \n","        [[ 66,  61,  58],\n","         [ 55,  50,  47],\n","         [ 41,  38,  34],\n","         ...,\n","         [ 86, 110,  98],\n","         [ 86, 108,  96],\n","         [ 86, 110,  98]],\n"," \n","        [[ 75,  70,  69],\n","         [ 64,  59,  58],\n","         [ 42,  38,  37],\n","         ...,\n","         [ 89, 115, 102],\n","         [ 93, 117, 105],\n","         [100, 126, 113]],\n"," \n","        ...,\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [155, 167, 185],\n","         [155, 167, 185],\n","         [154, 166, 184]],\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [158, 170, 188],\n","         [158, 170, 188],\n","         [158, 170, 188]],\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [160, 172, 190],\n","         [160, 172, 190],\n","         [160, 172, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.3a9787d86348f90ccb5f7253ef149fa9.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1409988403320312, 'inference': 7.217645645141602, 'postprocess': 1.4481544494628906},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 45,  40,  37],\n","         [ 47,  42,  39],\n","         [ 49,  46,  42],\n","         ...,\n","         [ 83, 105,  93],\n","         [ 90, 112, 100],\n","         [100, 122, 110]],\n"," \n","        [[ 66,  61,  58],\n","         [ 55,  50,  47],\n","         [ 41,  38,  34],\n","         ...,\n","         [ 86, 110,  98],\n","         [ 86, 108,  96],\n","         [ 86, 110,  98]],\n"," \n","        [[ 75,  70,  69],\n","         [ 64,  59,  58],\n","         [ 42,  38,  37],\n","         ...,\n","         [ 89, 115, 102],\n","         [ 93, 117, 105],\n","         [100, 126, 113]],\n"," \n","        ...,\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [155, 167, 185],\n","         [155, 167, 185],\n","         [154, 166, 184]],\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [158, 170, 188],\n","         [158, 170, 188],\n","         [158, 170, 188]],\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [160, 172, 190],\n","         [160, 172, 190],\n","         [160, 172, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.78d5dedc880b08452fb0ba68fabb30e6.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0782947540283203, 'inference': 7.224321365356445, 'postprocess': 1.415252685546875},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 29,  38,  41],\n","         [ 48,  53,  54],\n","         [ 62,  58,  57],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 19,  22,  20],\n","         [ 23,  26,  24]],\n"," \n","        [[ 32,  41,  44],\n","         [ 45,  50,  51],\n","         [ 53,  49,  48],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 22,  25,  23],\n","         [ 26,  29,  27]],\n"," \n","        [[ 39,  46,  49],\n","         [ 45,  49,  50],\n","         [ 47,  42,  41],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 24,  27,  25],\n","         [ 29,  32,  30]],\n"," \n","        ...,\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [164, 177, 203],\n","         [166, 179, 205],\n","         [167, 180, 206]],\n"," \n","        [[204, 212, 235],\n","         [204, 212, 235],\n","         [204, 212, 235],\n","         ...,\n","         [165, 178, 204],\n","         [167, 180, 206],\n","         [168, 181, 207]],\n"," \n","        [[203, 211, 234],\n","         [203, 211, 234],\n","         [203, 211, 234],\n","         ...,\n","         [165, 178, 204],\n","         [167, 180, 206],\n","         [168, 181, 207]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.9f2439c1e5712d35c4543a0b7890b13c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0377635955810547, 'inference': 7.211923599243164, 'postprocess': 1.394033432006836},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  44,  49],\n","         [ 51,  54,  58],\n","         [ 67,  61,  62],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 26,  27,  25],\n","         [ 31,  32,  30]],\n"," \n","        [[ 39,  45,  50],\n","         [ 50,  53,  57],\n","         [ 60,  54,  55],\n","         ...,\n","         [ 24,  25,  23],\n","         [ 32,  33,  31],\n","         [ 37,  38,  36]],\n"," \n","        [[ 43,  48,  51],\n","         [ 53,  55,  56],\n","         [ 56,  48,  49],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 36,  37,  35],\n","         [ 42,  43,  41]],\n"," \n","        ...,\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[209, 219, 236],\n","         [209, 219, 236],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[208, 218, 235],\n","         [208, 218, 235],\n","         [209, 219, 236],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.be56abde393288366385bbaf4b4be9fc.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1779537200927734, 'inference': 7.195711135864258, 'postprocess': 1.3728141784667969},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  44,  49],\n","         [ 51,  54,  58],\n","         [ 67,  61,  62],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 26,  27,  25],\n","         [ 31,  32,  30]],\n"," \n","        [[ 39,  45,  50],\n","         [ 50,  53,  57],\n","         [ 60,  54,  55],\n","         ...,\n","         [ 24,  25,  23],\n","         [ 32,  33,  31],\n","         [ 37,  38,  36]],\n"," \n","        [[ 43,  48,  51],\n","         [ 53,  55,  56],\n","         [ 56,  48,  49],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 36,  37,  35],\n","         [ 42,  43,  41]],\n"," \n","        ...,\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[209, 219, 236],\n","         [209, 219, 236],\n","         [210, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[208, 218, 235],\n","         [208, 218, 235],\n","         [209, 219, 236],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_158_jpg.rf.c17661e5445ad9d53db1ddc895ff940c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0868778228759766, 'inference': 7.211208343505859, 'postprocess': 1.9803047180175781},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  30,  37],\n","         [ 71,  61,  67],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 22,  25,  23],\n","         [ 25,  28,  26]],\n"," \n","        [[ 42,  34,  41],\n","         [ 72,  62,  68],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 29,  32,  30],\n","         [ 34,  37,  35]],\n"," \n","        [[ 40,  33,  38],\n","         [ 64,  55,  58],\n","         [ 58,  45,  47],\n","         ...,\n","         [ 27,  30,  28],\n","         [ 35,  38,  36],\n","         [ 41,  44,  42]],\n"," \n","        ...,\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.1675e5cce3a6698374ed4999801bbaec.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0036697387695312, 'inference': 7.194042205810547, 'postprocess': 1.390695571899414},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 33,  34,  38],\n","         [ 60,  57,  59],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 21,  24,  22],\n","         [ 24,  27,  25],\n","         [ 26,  29,  27]],\n"," \n","        [[ 42,  43,  47],\n","         [ 67,  64,  66],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 26,  29,  27],\n","         [ 29,  32,  30]],\n"," \n","        [[ 47,  48,  52],\n","         [ 72,  69,  71],\n","         [ 68,  56,  56],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 28,  31,  29],\n","         [ 32,  35,  33]],\n"," \n","        ...,\n"," \n","        [[208, 217, 237],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 216, 236],\n","         [207, 216, 236],\n","         [207, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[205, 214, 234],\n","         [205, 214, 234],\n","         [205, 214, 234],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.2b3750e88c3578f2d94ca783f1278105.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9893646240234375, 'inference': 7.178068161010742, 'postprocess': 1.306295394897461},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 48,  41,  44],\n","         [ 45,  38,  41],\n","         [ 54,  49,  51],\n","         ...,\n","         [ 95, 114, 105],\n","         [ 91, 111,  99],\n","         [ 91, 111,  99]],\n"," \n","        [[ 69,  62,  65],\n","         [ 53,  46,  49],\n","         [ 45,  40,  42],\n","         ...,\n","         [ 88, 108,  96],\n","         [ 92, 112, 100],\n","         [100, 122, 110]],\n"," \n","        [[ 79,  72,  75],\n","         [ 65,  58,  61],\n","         [ 46,  41,  43],\n","         ...,\n","         [ 76,  98,  86],\n","         [ 88, 110,  98],\n","         [106, 131, 117]],\n"," \n","        ...,\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [156, 169, 185],\n","         [156, 169, 185],\n","         [156, 169, 185]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [159, 172, 188],\n","         [159, 172, 188],\n","         [159, 172, 188]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [161, 174, 190],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.54a2a31cd0ac73505dbc9c48a497df0c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9979476928710938, 'inference': 7.17616081237793, 'postprocess': 1.6565322875976562},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 33,  34,  38],\n","         [ 60,  57,  59],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 21,  24,  22],\n","         [ 24,  27,  25],\n","         [ 26,  29,  27]],\n"," \n","        [[ 42,  43,  47],\n","         [ 67,  64,  66],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 26,  29,  27],\n","         [ 29,  32,  30]],\n"," \n","        [[ 47,  48,  52],\n","         [ 72,  69,  71],\n","         [ 68,  56,  56],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 28,  31,  29],\n","         [ 32,  35,  33]],\n"," \n","        ...,\n"," \n","        [[208, 217, 237],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 216, 236],\n","         [207, 216, 236],\n","         [207, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[205, 214, 234],\n","         [205, 214, 234],\n","         [205, 214, 234],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.6a621adb5b90c51ca8fee23fd0331ac4.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.267599105834961, 'inference': 11.456966400146484, 'postprocess': 1.5711784362792969},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 48,  41,  44],\n","         [ 45,  38,  41],\n","         [ 54,  49,  51],\n","         ...,\n","         [ 95, 114, 105],\n","         [ 91, 111,  99],\n","         [ 91, 111,  99]],\n"," \n","        [[ 69,  62,  65],\n","         [ 53,  46,  49],\n","         [ 45,  40,  42],\n","         ...,\n","         [ 88, 108,  96],\n","         [ 92, 112, 100],\n","         [100, 122, 110]],\n"," \n","        [[ 79,  72,  75],\n","         [ 65,  58,  61],\n","         [ 46,  41,  43],\n","         ...,\n","         [ 76,  98,  86],\n","         [ 88, 110,  98],\n","         [106, 131, 117]],\n"," \n","        ...,\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [156, 169, 185],\n","         [156, 169, 185],\n","         [156, 169, 185]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [159, 172, 188],\n","         [159, 172, 188],\n","         [159, 172, 188]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [161, 174, 190],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.75b7179c014114d3094ba8c8d9850a4a.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2284984588623047, 'inference': 7.2994232177734375, 'postprocess': 1.4643669128417969},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  30,  37],\n","         [ 71,  61,  67],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 22,  25,  23],\n","         [ 25,  28,  26]],\n"," \n","        [[ 42,  34,  41],\n","         [ 72,  62,  68],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 29,  32,  30],\n","         [ 34,  37,  35]],\n"," \n","        [[ 40,  33,  38],\n","         [ 64,  55,  58],\n","         [ 58,  45,  47],\n","         ...,\n","         [ 27,  30,  28],\n","         [ 35,  38,  36],\n","         [ 41,  44,  42]],\n"," \n","        ...,\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [156, 168, 186],\n","         [158, 170, 188],\n","         [158, 170, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_159_jpg.rf.8d704239f006004f37c0d1c5a02d5268.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.178192138671875, 'inference': 7.213115692138672, 'postprocess': 1.3594627380371094},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 29,  29,  35],\n","         [ 67,  63,  68],\n","         [ 72,  59,  61],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 19,  22,  20],\n","         [ 26,  29,  27]],\n"," \n","        [[ 41,  41,  47],\n","         [ 71,  67,  72],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 24,  27,  25],\n","         [ 31,  34,  32]],\n"," \n","        [[ 48,  48,  54],\n","         [ 72,  68,  73],\n","         [ 67,  54,  56],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 28,  31,  29],\n","         [ 34,  37,  35]],\n"," \n","        ...,\n"," \n","        [[208, 217, 237],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 216, 236],\n","         [207, 216, 236],\n","         [207, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[205, 214, 234],\n","         [205, 214, 234],\n","         [205, 214, 234],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.26ba921594af14a5bb8124d3b0f51320.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.239227294921875, 'inference': 7.275819778442383, 'postprocess': 2.0377635955810547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 29,  29,  35],\n","         [ 67,  63,  68],\n","         [ 72,  59,  61],\n","         ...,\n","         [ 17,  20,  18],\n","         [ 19,  22,  20],\n","         [ 26,  29,  27]],\n"," \n","        [[ 41,  41,  47],\n","         [ 71,  67,  72],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 24,  27,  25],\n","         [ 31,  34,  32]],\n"," \n","        [[ 48,  48,  54],\n","         [ 72,  68,  73],\n","         [ 67,  54,  56],\n","         ...,\n","         [ 22,  25,  23],\n","         [ 28,  31,  29],\n","         [ 34,  37,  35]],\n"," \n","        ...,\n"," \n","        [[208, 217, 237],\n","         [208, 217, 237],\n","         [208, 217, 237],\n","         ...,\n","         [160, 173, 195],\n","         [162, 175, 197],\n","         [163, 176, 198]],\n"," \n","        [[207, 216, 236],\n","         [207, 216, 236],\n","         [207, 216, 236],\n","         ...,\n","         [160, 173, 195],\n","         [161, 174, 196],\n","         [162, 175, 197]],\n"," \n","        [[205, 214, 234],\n","         [205, 214, 234],\n","         [205, 214, 234],\n","         ...,\n","         [159, 172, 194],\n","         [161, 174, 196],\n","         [161, 174, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.8fd002f07ed585f56e98f04100bb83fa.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1009445190429688, 'inference': 7.243871688842773, 'postprocess': 1.3608932495117188},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 49,  41,  48],\n","         [ 53,  43,  49],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 23,  26,  24],\n","         [ 27,  30,  28]],\n"," \n","        [[ 53,  45,  52],\n","         [ 58,  48,  54],\n","         [ 71,  58,  60],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 30,  33,  31],\n","         [ 35,  38,  36]],\n"," \n","        [[ 55,  48,  53],\n","         [ 58,  49,  52],\n","         [ 69,  56,  58],\n","         ...,\n","         [ 27,  30,  28],\n","         [ 35,  38,  36],\n","         [ 41,  44,  42]],\n"," \n","        ...,\n"," \n","        [[211, 221, 238],\n","         [210, 220, 237],\n","         [209, 219, 236],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[211, 221, 238],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [156, 168, 186],\n","         [157, 169, 187],\n","         [158, 170, 188]],\n"," \n","        [[211, 221, 238],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [155, 167, 185],\n","         [157, 169, 187],\n","         [157, 169, 187]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.a6148d213f9944617eef1e72975bcf95.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0155906677246094, 'inference': 7.24339485168457, 'postprocess': 1.4109611511230469},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 49,  41,  48],\n","         [ 53,  43,  49],\n","         [ 68,  55,  57],\n","         ...,\n","         [ 20,  23,  21],\n","         [ 23,  26,  24],\n","         [ 27,  30,  28]],\n"," \n","        [[ 53,  45,  52],\n","         [ 58,  48,  54],\n","         [ 71,  58,  60],\n","         ...,\n","         [ 24,  27,  25],\n","         [ 30,  33,  31],\n","         [ 35,  38,  36]],\n"," \n","        [[ 55,  48,  53],\n","         [ 58,  49,  52],\n","         [ 69,  56,  58],\n","         ...,\n","         [ 27,  30,  28],\n","         [ 35,  38,  36],\n","         [ 41,  44,  42]],\n"," \n","        ...,\n"," \n","        [[211, 221, 238],\n","         [210, 220, 237],\n","         [209, 219, 236],\n","         ...,\n","         [157, 169, 187],\n","         [158, 170, 188],\n","         [159, 171, 189]],\n"," \n","        [[211, 221, 238],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [156, 168, 186],\n","         [157, 169, 187],\n","         [158, 170, 188]],\n"," \n","        [[211, 221, 238],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [155, 167, 185],\n","         [157, 169, 187],\n","         [157, 169, 187]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_160_jpg.rf.fec7949409eb2e9be4f353476b9930b9.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9948482513427734, 'inference': 7.19451904296875, 'postprocess': 1.3420581817626953},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 42,  36,  37],\n","         [ 46,  40,  41],\n","         [ 39,  34,  35],\n","         ...,\n","         [ 71,  93,  81],\n","         [ 74,  96,  84],\n","         [ 81, 103,  91]],\n"," \n","        [[ 65,  59,  60],\n","         [ 55,  49,  50],\n","         [ 32,  27,  28],\n","         ...,\n","         [ 82, 104,  92],\n","         [ 79, 101,  89],\n","         [ 79, 101,  89]],\n"," \n","        [[ 78,  72,  73],\n","         [ 66,  60,  61],\n","         [ 33,  28,  29],\n","         ...,\n","         [ 77, 100,  86],\n","         [ 81, 104,  90],\n","         [ 85, 108,  94]],\n"," \n","        ...,\n"," \n","        [[194, 201, 216],\n","         [194, 201, 216],\n","         [194, 201, 216],\n","         ...,\n","         [144, 154, 171],\n","         [144, 154, 171],\n","         [144, 154, 171]],\n"," \n","        [[194, 201, 216],\n","         [194, 201, 216],\n","         [194, 201, 216],\n","         ...,\n","         [146, 156, 173],\n","         [146, 156, 173],\n","         [146, 156, 173]],\n"," \n","        [[194, 201, 216],\n","         [194, 201, 216],\n","         [194, 201, 216],\n","         ...,\n","         [147, 157, 174],\n","         [147, 157, 174],\n","         [148, 158, 175]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.30452ba2dced959cf9e4aaac49996b13.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.270221710205078, 'inference': 7.214784622192383, 'postprocess': 1.440286636352539},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  28,  34],\n","         [ 70,  59,  62],\n","         [ 67,  53,  54],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 24,  25,  21],\n","         [ 28,  29,  25]],\n"," \n","        [[ 49,  39,  45],\n","         [ 73,  62,  65],\n","         [ 66,  52,  53],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 31,  32,  28],\n","         [ 36,  37,  33]],\n"," \n","        [[ 58,  49,  52],\n","         [ 72,  61,  63],\n","         [ 61,  47,  48],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 36,  37,  33],\n","         [ 42,  43,  39]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [160, 173, 189],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[209, 218, 232],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.544f973bedd34d07c2d44a7e5ffea87f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1092891693115234, 'inference': 7.224321365356445, 'postprocess': 1.3918876647949219},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 42,  36,  37],\n","         [ 46,  40,  41],\n","         [ 39,  34,  35],\n","         ...,\n","         [ 71,  93,  81],\n","         [ 74,  96,  84],\n","         [ 81, 103,  91]],\n"," \n","        [[ 65,  59,  60],\n","         [ 55,  49,  50],\n","         [ 32,  27,  28],\n","         ...,\n","         [ 82, 104,  92],\n","         [ 79, 101,  89],\n","         [ 79, 101,  89]],\n"," \n","        [[ 78,  72,  73],\n","         [ 66,  60,  61],\n","         [ 33,  28,  29],\n","         ...,\n","         [ 77, 100,  86],\n","         [ 81, 104,  90],\n","         [ 85, 108,  94]],\n"," \n","        ...,\n"," \n","        [[194, 201, 216],\n","         [194, 201, 216],\n","         [194, 201, 216],\n","         ...,\n","         [144, 154, 171],\n","         [144, 154, 171],\n","         [144, 154, 171]],\n"," \n","        [[194, 201, 216],\n","         [194, 201, 216],\n","         [194, 201, 216],\n","         ...,\n","         [146, 156, 173],\n","         [146, 156, 173],\n","         [146, 156, 173]],\n"," \n","        [[194, 201, 216],\n","         [194, 201, 216],\n","         [194, 201, 216],\n","         ...,\n","         [147, 157, 174],\n","         [147, 157, 174],\n","         [148, 158, 175]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.83097cc5189d84d7bd8c2ea1790fd837.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.126932144165039, 'inference': 10.32257080078125, 'postprocess': 1.4178752899169922},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  28,  34],\n","         [ 70,  59,  62],\n","         [ 67,  53,  54],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 24,  25,  21],\n","         [ 28,  29,  25]],\n"," \n","        [[ 49,  39,  45],\n","         [ 73,  62,  65],\n","         [ 66,  52,  53],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 31,  32,  28],\n","         [ 36,  37,  33]],\n"," \n","        [[ 58,  49,  52],\n","         [ 72,  61,  63],\n","         [ 61,  47,  48],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 36,  37,  33],\n","         [ 42,  43,  39]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [160, 173, 189],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[209, 218, 232],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_234_jpg.rf.c12c3cd13d4457fe98a90ec3df78ea3a.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.344846725463867, 'inference': 7.314443588256836, 'postprocess': 1.4946460723876953},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  29,  33],\n","         [ 54,  51,  53],\n","         [ 56,  44,  44],\n","         ...,\n","         [ 14,  15,  13],\n","         [ 21,  22,  20],\n","         [ 27,  28,  26]],\n"," \n","        [[ 39,  40,  44],\n","         [ 63,  60,  62],\n","         [ 59,  47,  47],\n","         ...,\n","         [ 16,  17,  15],\n","         [ 24,  25,  23],\n","         [ 31,  32,  30]],\n"," \n","        [[ 44,  45,  49],\n","         [ 69,  66,  68],\n","         [ 62,  50,  50],\n","         ...,\n","         [ 17,  18,  16],\n","         [ 27,  28,  26],\n","         [ 35,  36,  34]],\n"," \n","        ...,\n"," \n","        [[202, 210, 227],\n","         [203, 211, 228],\n","         [203, 211, 228],\n","         ...,\n","         [165, 179, 198],\n","         [167, 181, 200],\n","         [168, 182, 201]],\n"," \n","        [[203, 211, 228],\n","         [203, 211, 228],\n","         [203, 211, 228],\n","         ...,\n","         [165, 179, 198],\n","         [167, 181, 200],\n","         [168, 182, 201]],\n"," \n","        [[200, 208, 225],\n","         [200, 208, 225],\n","         [200, 208, 225],\n","         ...,\n","         [165, 179, 198],\n","         [167, 181, 200],\n","         [168, 182, 201]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_235_jpg.rf.6da18c0817779e9c93d708960148c605.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1593570709228516, 'inference': 7.236003875732422, 'postprocess': 1.363992691040039},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 46,  36,  42],\n","         [ 61,  50,  53],\n","         [ 70,  56,  57],\n","         ...,\n","         [ 19,  20,  16],\n","         [ 27,  28,  24],\n","         [ 24,  25,  21]],\n"," \n","        [[ 48,  38,  44],\n","         [ 58,  47,  50],\n","         [ 62,  48,  49],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 34,  35,  31],\n","         [ 34,  35,  31]],\n"," \n","        [[ 62,  52,  58],\n","         [ 64,  53,  56],\n","         [ 59,  45,  46],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 40,  41,  37],\n","         [ 41,  42,  38]],\n"," \n","        ...,\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [158, 171, 187],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_235_jpg.rf.9349cfc458de0b851daa1b59f359c935.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.033710479736328, 'inference': 7.439136505126953, 'postprocess': 1.3856887817382812},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 53,  42,  45],\n","         [ 33,  24,  27],\n","         [ 31,  22,  25],\n","         ...,\n","         [ 70,  90,  78],\n","         [ 75,  95,  83],\n","         [ 81, 101,  89]],\n"," \n","        [[ 61,  50,  53],\n","         [ 51,  42,  45],\n","         [ 41,  32,  35],\n","         ...,\n","         [ 85, 105,  93],\n","         [ 82, 102,  90],\n","         [ 75,  97,  85]],\n"," \n","        [[ 70,  59,  62],\n","         [ 67,  58,  61],\n","         [ 48,  39,  42],\n","         ...,\n","         [ 83, 106,  92],\n","         [ 82, 105,  91],\n","         [ 77, 102,  88]],\n"," \n","        ...,\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [142, 152, 169],\n","         [141, 151, 168],\n","         [141, 151, 168]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [144, 154, 171],\n","         [144, 154, 171],\n","         [143, 153, 170]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [146, 156, 173],\n","         [146, 156, 173],\n","         [145, 155, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.14a4e1250147fcef4a1c9c5fe5f8096f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.151012420654297, 'inference': 7.2193145751953125, 'postprocess': 1.4255046844482422},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 50,  40,  46],\n","         [ 65,  54,  57],\n","         [ 73,  59,  60],\n","         ...,\n","         [ 17,  18,  14],\n","         [ 25,  26,  22],\n","         [ 30,  31,  27]],\n"," \n","        [[ 56,  46,  52],\n","         [ 64,  53,  56],\n","         [ 67,  53,  54],\n","         ...,\n","         [ 22,  23,  19],\n","         [ 32,  33,  29],\n","         [ 38,  39,  35]],\n"," \n","        [[ 62,  52,  58],\n","         [ 64,  53,  56],\n","         [ 59,  45,  46],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 37,  38,  34],\n","         [ 43,  44,  40]],\n"," \n","        ...,\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [210, 219, 233],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.491158d84470a24c67d7a886c37977c7.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0966529846191406, 'inference': 7.169246673583984, 'postprocess': 1.3051033020019531},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[170, 178, 177],\n","         [184, 192, 191],\n","         [143, 154, 151],\n","         ...,\n","         [ 78,  97,  80],\n","         [ 75,  95,  76],\n","         [ 78,  98,  79]],\n"," \n","        [[182, 190, 189],\n","         [179, 190, 188],\n","         [124, 135, 133],\n","         ...,\n","         [ 67,  86,  69],\n","         [ 68,  88,  69],\n","         [ 91, 111,  92]],\n"," \n","        [[201, 211, 211],\n","         [188, 198, 198],\n","         [117, 127, 127],\n","         ...,\n","         [ 61,  80,  63],\n","         [ 57,  76,  59],\n","         [ 78,  97,  80]],\n"," \n","        ...,\n"," \n","        [[203, 212, 226],\n","         [202, 211, 225],\n","         [200, 209, 223],\n","         ...,\n","         [167, 169, 180],\n","         [168, 170, 181],\n","         [168, 170, 181]],\n"," \n","        [[203, 212, 226],\n","         [201, 210, 224],\n","         [199, 208, 222],\n","         ...,\n","         [168, 170, 181],\n","         [170, 172, 183],\n","         [172, 174, 185]],\n"," \n","        [[203, 212, 226],\n","         [201, 210, 224],\n","         [199, 208, 222],\n","         ...,\n","         [170, 172, 183],\n","         [173, 175, 186],\n","         [175, 177, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.5a874846c51f129039d7923bcca7bd96.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0554065704345703, 'inference': 8.536338806152344, 'postprocess': 1.512765884399414},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 53,  42,  45],\n","         [ 33,  24,  27],\n","         [ 31,  22,  25],\n","         ...,\n","         [ 70,  90,  78],\n","         [ 75,  95,  83],\n","         [ 81, 101,  89]],\n"," \n","        [[ 61,  50,  53],\n","         [ 51,  42,  45],\n","         [ 41,  32,  35],\n","         ...,\n","         [ 85, 105,  93],\n","         [ 82, 102,  90],\n","         [ 75,  97,  85]],\n"," \n","        [[ 70,  59,  62],\n","         [ 67,  58,  61],\n","         [ 48,  39,  42],\n","         ...,\n","         [ 83, 106,  92],\n","         [ 82, 105,  91],\n","         [ 77, 102,  88]],\n"," \n","        ...,\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [142, 152, 169],\n","         [141, 151, 168],\n","         [141, 151, 168]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [144, 154, 171],\n","         [144, 154, 171],\n","         [143, 153, 170]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [146, 156, 173],\n","         [146, 156, 173],\n","         [145, 155, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_236_jpg.rf.fd29a9d6e6b26872ca37ad165bb673d2.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1085739135742188, 'inference': 7.184028625488281, 'postprocess': 1.4564990997314453},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 37,  27,  33],\n","         [ 67,  56,  59],\n","         [ 61,  47,  48],\n","         ...,\n","         [ 16,  17,  15],\n","         [ 21,  22,  20],\n","         [ 25,  26,  24]],\n"," \n","        [[ 37,  27,  33],\n","         [ 67,  56,  59],\n","         [ 62,  48,  49],\n","         ...,\n","         [ 18,  19,  17],\n","         [ 24,  25,  23],\n","         [ 30,  31,  29]],\n"," \n","        [[ 42,  33,  36],\n","         [ 68,  57,  59],\n","         [ 62,  48,  49],\n","         ...,\n","         [ 19,  20,  18],\n","         [ 27,  28,  26],\n","         [ 34,  35,  33]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [203, 211, 228],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [167, 180, 202]],\n"," \n","        [[207, 215, 232],\n","         [206, 214, 231],\n","         [205, 213, 230],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [168, 181, 203]],\n"," \n","        [[208, 216, 233],\n","         [207, 215, 232],\n","         [206, 214, 231],\n","         ...,\n","         [165, 178, 200],\n","         [167, 180, 202],\n","         [168, 181, 203]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_237_jpg.rf.dbfde5725ba9955c9db90c88a9525163.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1140575408935547, 'inference': 7.199525833129883, 'postprocess': 1.3301372528076172},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 42,  35,  40],\n","         [ 71,  62,  65],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 23,  18,  15],\n","         [ 28,  23,  20],\n","         [ 36,  31,  28]],\n"," \n","        [[ 41,  34,  39],\n","         [ 70,  61,  64],\n","         [ 66,  54,  54],\n","         ...,\n","         [ 26,  21,  18],\n","         [ 32,  27,  24],\n","         [ 40,  35,  32]],\n"," \n","        [[ 44,  37,  42],\n","         [ 70,  61,  64],\n","         [ 66,  54,  54],\n","         ...,\n","         [ 26,  23,  19],\n","         [ 34,  31,  27],\n","         [ 42,  39,  35]],\n"," \n","        ...,\n"," \n","        [[205, 215, 232],\n","         [205, 215, 232],\n","         [205, 215, 232],\n","         ...,\n","         [165, 177, 195],\n","         [165, 177, 195],\n","         [165, 177, 195]],\n"," \n","        [[205, 215, 232],\n","         [205, 215, 232],\n","         [205, 215, 232],\n","         ...,\n","         [164, 176, 194],\n","         [164, 176, 194],\n","         [164, 176, 194]],\n"," \n","        [[205, 215, 232],\n","         [205, 215, 232],\n","         [205, 215, 232],\n","         ...,\n","         [164, 176, 194],\n","         [164, 176, 194],\n","         [164, 176, 194]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_237_jpg.rf.fb6efc0ef2ce6291dd7213b993b4e380.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2382736206054688, 'inference': 7.202625274658203, 'postprocess': 1.5139579772949219},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 31,  30,  34],\n","         [ 68,  63,  65],\n","         [ 71,  57,  58],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 26,  27,  23],\n","         [ 30,  31,  27]],\n"," \n","        [[ 40,  39,  43],\n","         [ 69,  64,  66],\n","         [ 67,  53,  54],\n","         ...,\n","         [ 26,  27,  23],\n","         [ 33,  34,  30],\n","         [ 39,  40,  36]],\n"," \n","        [[ 46,  45,  49],\n","         [ 66,  61,  63],\n","         [ 60,  46,  47],\n","         ...,\n","         [ 29,  30,  26],\n","         [ 38,  39,  35],\n","         [ 45,  46,  42]],\n"," \n","        ...,\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[210, 218, 235],\n","         [210, 218, 235],\n","         [210, 218, 235],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_238_jpg.rf.74426c631fba0b3c130d620d0ecde88b.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0890235900878906, 'inference': 7.2536468505859375, 'postprocess': 1.3358592987060547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 31,  30,  34],\n","         [ 68,  63,  65],\n","         [ 71,  57,  58],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 26,  27,  23],\n","         [ 30,  31,  27]],\n"," \n","        [[ 40,  39,  43],\n","         [ 69,  64,  66],\n","         [ 67,  53,  54],\n","         ...,\n","         [ 26,  27,  23],\n","         [ 33,  34,  30],\n","         [ 39,  40,  36]],\n"," \n","        [[ 46,  45,  49],\n","         [ 66,  61,  63],\n","         [ 60,  46,  47],\n","         ...,\n","         [ 29,  30,  26],\n","         [ 38,  39,  35],\n","         [ 45,  46,  42]],\n"," \n","        ...,\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[210, 218, 235],\n","         [210, 218, 235],\n","         [210, 218, 235],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_238_jpg.rf.d4d42084a2590b13e7f73340dbc86952.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.934051513671875, 'inference': 7.16710090637207, 'postprocess': 1.2676715850830078},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 36,  34,  46],\n","         [ 63,  57,  68],\n","         [ 66,  52,  58],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 20,  23,  21],\n","         [ 24,  27,  25]],\n"," \n","        [[ 30,  28,  40],\n","         [ 56,  51,  60],\n","         [ 62,  48,  54],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 24,  27,  25],\n","         [ 28,  31,  29]],\n"," \n","        [[ 29,  28,  38],\n","         [ 51,  47,  53],\n","         [ 57,  43,  47],\n","         ...,\n","         [ 19,  22,  20],\n","         [ 26,  29,  27],\n","         [ 32,  35,  33]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [161, 175, 194],\n","         [162, 176, 195],\n","         [163, 177, 196]],\n"," \n","        [[203, 211, 228],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [160, 174, 193],\n","         [162, 176, 195],\n","         [163, 177, 196]],\n"," \n","        [[203, 211, 228],\n","         [203, 211, 228],\n","         [204, 212, 229],\n","         ...,\n","         [160, 174, 193],\n","         [162, 176, 195],\n","         [163, 177, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_239_jpg.rf.1b7792c1e4c6c1e1d13d3c89d9b59d03.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.00653076171875, 'inference': 7.174968719482422, 'postprocess': 1.3446807861328125},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 48,  41,  44],\n","         [ 37,  30,  33],\n","         [ 38,  33,  35],\n","         ...,\n","         [ 80, 100,  87],\n","         [ 84, 104,  91],\n","         [ 81, 101,  88]],\n"," \n","        [[ 64,  57,  60],\n","         [ 46,  39,  42],\n","         [ 26,  21,  23],\n","         ...,\n","         [ 80, 100,  87],\n","         [ 78,  98,  85],\n","         [ 70,  90,  77]],\n"," \n","        [[ 73,  66,  69],\n","         [ 63,  56,  59],\n","         [ 28,  23,  25],\n","         ...,\n","         [ 79,  97,  84],\n","         [ 81,  99,  86],\n","         [ 84, 102,  89]],\n"," \n","        ...,\n"," \n","        [[196, 203, 220],\n","         [196, 203, 220],\n","         [196, 203, 220],\n","         ...,\n","         [141, 151, 168],\n","         [141, 151, 168],\n","         [141, 151, 168]],\n"," \n","        [[196, 203, 220],\n","         [196, 203, 220],\n","         [196, 203, 220],\n","         ...,\n","         [143, 153, 170],\n","         [143, 153, 170],\n","         [143, 153, 170]],\n"," \n","        [[196, 203, 220],\n","         [196, 203, 220],\n","         [196, 203, 220],\n","         ...,\n","         [144, 154, 171],\n","         [144, 154, 171],\n","         [144, 154, 171]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_239_jpg.rf.ac16f00f7ac92f1328764ca76a6ce3fe.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9192695617675781, 'inference': 7.871150970458984, 'postprocess': 1.7936229705810547},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 36,  34,  46],\n","         [ 63,  57,  68],\n","         [ 66,  52,  58],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 20,  23,  21],\n","         [ 24,  27,  25]],\n"," \n","        [[ 30,  28,  40],\n","         [ 56,  51,  60],\n","         [ 62,  48,  54],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 24,  27,  25],\n","         [ 28,  31,  29]],\n"," \n","        [[ 29,  28,  38],\n","         [ 51,  47,  53],\n","         [ 57,  43,  47],\n","         ...,\n","         [ 19,  22,  20],\n","         [ 26,  29,  27],\n","         [ 32,  35,  33]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [161, 175, 194],\n","         [162, 176, 195],\n","         [163, 177, 196]],\n"," \n","        [[203, 211, 228],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [160, 174, 193],\n","         [162, 176, 195],\n","         [163, 177, 196]],\n"," \n","        [[203, 211, 228],\n","         [203, 211, 228],\n","         [204, 212, 229],\n","         ...,\n","         [160, 174, 193],\n","         [162, 176, 195],\n","         [163, 177, 196]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_239_jpg.rf.d6424187438d96296649c8ab1eea4661.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9276142120361328, 'inference': 7.158041000366211, 'postprocess': 1.4193058013916016},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 26,  24,  36],\n","         [ 63,  57,  68],\n","         [ 65,  51,  57],\n","         ...,\n","         [  8,  11,   9],\n","         [ 13,  16,  14],\n","         [ 24,  27,  25]],\n"," \n","        [[ 33,  31,  43],\n","         [ 62,  57,  66],\n","         [ 60,  46,  52],\n","         ...,\n","         [ 12,  15,  13],\n","         [ 17,  20,  18],\n","         [ 29,  32,  30]],\n"," \n","        [[ 42,  41,  51],\n","         [ 61,  57,  63],\n","         [ 56,  42,  46],\n","         ...,\n","         [ 15,  18,  16],\n","         [ 22,  25,  23],\n","         [ 33,  36,  34]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [144, 158, 177],\n","         [142, 156, 178],\n","         [141, 155, 177]],\n"," \n","        [[203, 211, 228],\n","         [203, 211, 228],\n","         [204, 212, 229],\n","         ...,\n","         [144, 158, 177],\n","         [142, 156, 178],\n","         [141, 155, 177]],\n"," \n","        [[202, 210, 227],\n","         [202, 210, 227],\n","         [203, 211, 228],\n","         ...,\n","         [144, 158, 177],\n","         [143, 157, 179],\n","         [142, 156, 178]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_240_jpg.rf.24945b7e946d47c32af643499e0aa7f8.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9116401672363281, 'inference': 7.142782211303711, 'postprocess': 1.2345314025878906},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  24,  25],\n","         [ 63,  55,  55],\n","         [ 59,  47,  45],\n","         ...,\n","         [ 13,  17,  12],\n","         [ 17,  21,  16],\n","         [ 26,  30,  25]],\n"," \n","        [[ 38,  32,  33],\n","         [ 68,  60,  60],\n","         [ 61,  49,  47],\n","         ...,\n","         [ 16,  20,  15],\n","         [ 22,  26,  21],\n","         [ 31,  35,  30]],\n"," \n","        [[ 44,  38,  39],\n","         [ 70,  62,  62],\n","         [ 62,  50,  48],\n","         ...,\n","         [ 18,  22,  17],\n","         [ 26,  30,  25],\n","         [ 35,  39,  34]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [146, 156, 173],\n","         [146, 156, 173],\n","         [146, 156, 173]],\n"," \n","        [[205, 213, 230],\n","         [205, 213, 230],\n","         [205, 213, 230],\n","         ...,\n","         [149, 159, 176],\n","         [149, 159, 176],\n","         [149, 159, 176]],\n"," \n","        [[205, 213, 230],\n","         [205, 213, 230],\n","         [205, 213, 230],\n","         ...,\n","         [152, 162, 179],\n","         [151, 161, 178],\n","         [151, 161, 178]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_241_jpg.rf.415b64e67ae9c685f173cf785aca4979.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.8491744995117188, 'inference': 7.411718368530273, 'postprocess': 1.2292861938476562},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  24,  25],\n","         [ 63,  55,  55],\n","         [ 59,  47,  45],\n","         ...,\n","         [ 13,  17,  12],\n","         [ 17,  21,  16],\n","         [ 26,  30,  25]],\n"," \n","        [[ 38,  32,  33],\n","         [ 68,  60,  60],\n","         [ 61,  49,  47],\n","         ...,\n","         [ 16,  20,  15],\n","         [ 22,  26,  21],\n","         [ 31,  35,  30]],\n"," \n","        [[ 44,  38,  39],\n","         [ 70,  62,  62],\n","         [ 62,  50,  48],\n","         ...,\n","         [ 18,  22,  17],\n","         [ 26,  30,  25],\n","         [ 35,  39,  34]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [146, 156, 173],\n","         [146, 156, 173],\n","         [146, 156, 173]],\n"," \n","        [[205, 213, 230],\n","         [205, 213, 230],\n","         [205, 213, 230],\n","         ...,\n","         [149, 159, 176],\n","         [149, 159, 176],\n","         [149, 159, 176]],\n"," \n","        [[205, 213, 230],\n","         [205, 213, 230],\n","         [205, 213, 230],\n","         ...,\n","         [152, 162, 179],\n","         [151, 161, 178],\n","         [151, 161, 178]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_241_jpg.rf.ac377d5b48e1520a380d6218a2ed66d2.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9297599792480469, 'inference': 7.140398025512695, 'postprocess': 1.2001991271972656},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 42,  40,  40],\n","         [ 55,  51,  50],\n","         [ 66,  57,  54],\n","         ...,\n","         [ 23,  24,  22],\n","         [ 26,  27,  25],\n","         [ 29,  30,  28]],\n"," \n","        [[ 56,  54,  54],\n","         [ 63,  59,  58],\n","         [ 65,  56,  53],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 33,  34,  32],\n","         [ 37,  38,  36]],\n"," \n","        [[ 56,  54,  54],\n","         [ 58,  54,  53],\n","         [ 55,  46,  43],\n","         ...,\n","         [ 29,  30,  28],\n","         [ 37,  38,  36],\n","         [ 43,  44,  42]],\n"," \n","        ...,\n"," \n","        [[209, 217, 234],\n","         [210, 218, 235],\n","         [211, 219, 236],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [210, 218, 235],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[212, 220, 237],\n","         [211, 219, 236],\n","         [209, 217, 234],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_242-1-_jpg.rf.062a807937d2281f2c317ea962099158.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9564628601074219, 'inference': 7.147789001464844, 'postprocess': 1.2562274932861328},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 48,  37,  40],\n","         [ 44,  35,  38],\n","         [ 50,  41,  44],\n","         ...,\n","         [ 71,  94,  79],\n","         [ 76,  99,  84],\n","         [ 80, 103,  88]],\n"," \n","        [[ 61,  50,  53],\n","         [ 54,  45,  48],\n","         [ 53,  44,  47],\n","         ...,\n","         [ 77, 100,  85],\n","         [ 73,  96,  81],\n","         [ 68,  91,  76]],\n"," \n","        [[ 74,  63,  66],\n","         [ 64,  55,  58],\n","         [ 52,  43,  46],\n","         ...,\n","         [ 78, 101,  86],\n","         [ 77, 100,  85],\n","         [ 76,  99,  84]],\n"," \n","        ...,\n"," \n","        [[197, 206, 220],\n","         [196, 205, 219],\n","         [195, 204, 218],\n","         ...,\n","         [129, 138, 151],\n","         [128, 137, 150],\n","         [128, 137, 150]],\n"," \n","        [[197, 206, 220],\n","         [196, 205, 219],\n","         [195, 204, 218],\n","         ...,\n","         [129, 138, 151],\n","         [128, 137, 150],\n","         [128, 137, 150]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [195, 204, 218],\n","         ...,\n","         [129, 138, 151],\n","         [129, 138, 151],\n","         [128, 137, 150]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_242_jpg.rf.2807b2bf59dabb24074050c921e1608c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.8913745880126953, 'inference': 7.13801383972168, 'postprocess': 1.4264583587646484},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 32,  26,  27],\n","         [ 67,  59,  59],\n","         [ 64,  52,  50],\n","         ...,\n","         [ 13,  17,  12],\n","         [ 17,  21,  16],\n","         [ 26,  30,  25]],\n"," \n","        [[ 42,  36,  37],\n","         [ 71,  63,  63],\n","         [ 62,  50,  48],\n","         ...,\n","         [ 16,  20,  15],\n","         [ 22,  26,  21],\n","         [ 31,  35,  30]],\n"," \n","        [[ 46,  40,  41],\n","         [ 71,  63,  63],\n","         [ 60,  48,  46],\n","         ...,\n","         [ 18,  22,  17],\n","         [ 26,  30,  25],\n","         [ 35,  39,  34]],\n"," \n","        ...,\n"," \n","        [[203, 211, 228],\n","         [203, 211, 228],\n","         [203, 211, 228],\n","         ...,\n","         [159, 172, 188],\n","         [159, 172, 188],\n","         [159, 172, 188]],\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [157, 170, 186],\n","         [158, 171, 187],\n","         [158, 171, 187]],\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [156, 169, 185],\n","         [156, 169, 185],\n","         [156, 169, 185]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_242_jpg.rf.369a8ccbf0d969978a6a579d8643ea13.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.848459243774414, 'inference': 7.128238677978516, 'postprocess': 1.1944770812988281},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 33,  35,  35],\n","         [ 59,  57,  56],\n","         [ 60,  48,  46],\n","         ...,\n","         [ 15,  16,  14],\n","         [ 18,  19,  17],\n","         [ 22,  23,  21]],\n"," \n","        [[ 41,  43,  43],\n","         [ 65,  63,  62],\n","         [ 61,  49,  47],\n","         ...,\n","         [ 17,  18,  16],\n","         [ 22,  23,  21],\n","         [ 27,  28,  26]],\n"," \n","        [[ 44,  46,  46],\n","         [ 68,  66,  65],\n","         [ 61,  49,  47],\n","         ...,\n","         [ 18,  19,  17],\n","         [ 25,  26,  24],\n","         [ 31,  32,  30]],\n"," \n","        ...,\n"," \n","        [[204, 212, 229],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [154, 168, 187],\n","         [156, 170, 189],\n","         [157, 171, 190]],\n"," \n","        [[203, 211, 228],\n","         [204, 212, 229],\n","         [204, 212, 229],\n","         ...,\n","         [154, 168, 187],\n","         [155, 169, 188],\n","         [156, 170, 189]],\n"," \n","        [[203, 211, 228],\n","         [203, 211, 228],\n","         [204, 212, 229],\n","         ...,\n","         [153, 167, 186],\n","         [155, 169, 188],\n","         [155, 169, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_243_jpg.rf.601d34237b2e744ee9eb466c8d7127af.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9960403442382812, 'inference': 8.307695388793945, 'postprocess': 1.3628005981445312},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  33,  36],\n","         [ 49,  51,  52],\n","         [ 68,  58,  58],\n","         ...,\n","         [ 21,  22,  20],\n","         [ 23,  24,  22],\n","         [ 25,  26,  24]],\n"," \n","        [[ 37,  42,  45],\n","         [ 56,  55,  57],\n","         [ 69,  59,  59],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 31,  32,  30],\n","         [ 34,  35,  33]],\n"," \n","        [[ 44,  47,  51],\n","         [ 58,  57,  59],\n","         [ 65,  55,  55],\n","         ...,\n","         [ 30,  31,  29],\n","         [ 37,  38,  36],\n","         [ 42,  43,  41]],\n"," \n","        ...,\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [160, 169, 189],\n","         [162, 171, 191],\n","         [163, 172, 192]],\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [160, 169, 189],\n","         [161, 170, 190],\n","         [162, 171, 191]],\n"," \n","        [[209, 219, 236],\n","         [209, 219, 236],\n","         [209, 219, 236],\n","         ...,\n","         [159, 168, 188],\n","         [161, 170, 190],\n","         [161, 170, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_243_jpg.rf.98032c4785e9bab477f2bf45e8fdd01d.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.931905746459961, 'inference': 7.155418395996094, 'postprocess': 1.8961429595947266},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 73,  59,  63],\n","         [ 30,  19,  22],\n","         [ 38,  31,  34],\n","         ...,\n","         [ 77, 107,  96],\n","         [ 74, 106,  95],\n","         [ 60,  92,  81]],\n"," \n","        [[ 73,  59,  63],\n","         [ 50,  39,  42],\n","         [ 46,  39,  42],\n","         ...,\n","         [ 71, 101,  90],\n","         [ 72, 102,  91],\n","         [ 65,  97,  86]],\n"," \n","        [[ 69,  55,  59],\n","         [ 72,  61,  64],\n","         [ 51,  44,  47],\n","         ...,\n","         [ 63,  93,  82],\n","         [ 69,  99,  88],\n","         [ 76, 106,  95]],\n"," \n","        ...,\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [121, 130, 143],\n","         [121, 130, 143],\n","         [120, 129, 142]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [124, 133, 146],\n","         [123, 132, 145],\n","         [123, 132, 145]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [126, 135, 148],\n","         [125, 134, 147],\n","         [125, 134, 147]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_243_jpg.rf.bf54c9ebc5bc90f5afd84ef7ba71cb43.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.045154571533203, 'inference': 7.135629653930664, 'postprocess': 1.2366771697998047},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 34,  39,  42],\n","         [ 54,  56,  57],\n","         [ 70,  60,  60],\n","         ...,\n","         [ 21,  22,  20],\n","         [ 23,  24,  22],\n","         [ 25,  26,  24]],\n"," \n","        [[ 41,  46,  49],\n","         [ 59,  58,  60],\n","         [ 69,  59,  59],\n","         ...,\n","         [ 27,  28,  26],\n","         [ 31,  32,  30],\n","         [ 34,  35,  33]],\n"," \n","        [[ 47,  50,  54],\n","         [ 58,  57,  59],\n","         [ 63,  53,  53],\n","         ...,\n","         [ 30,  31,  29],\n","         [ 37,  38,  36],\n","         [ 42,  43,  41]],\n"," \n","        ...,\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [160, 173, 189],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[211, 219, 236],\n","         [211, 219, 236],\n","         [211, 219, 236],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_244_jpg.rf.7aeb8d8934cbfb1b285b10b7c92879bf.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9755363464355469, 'inference': 7.163524627685547, 'postprocess': 1.2691020965576172},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 72,  61,  64],\n","         [ 20,  11,  14],\n","         [ 47,  38,  41],\n","         ...,\n","         [ 74,  98,  86],\n","         [ 70,  96,  83],\n","         [ 66,  92,  79]],\n"," \n","        [[ 74,  63,  66],\n","         [ 41,  32,  35],\n","         [ 53,  44,  47],\n","         ...,\n","         [ 75,  99,  87],\n","         [ 76, 102,  89],\n","         [ 77, 103,  90]],\n"," \n","        [[ 75,  64,  67],\n","         [ 63,  54,  57],\n","         [ 56,  47,  50],\n","         ...,\n","         [ 71,  96,  82],\n","         [ 81, 106,  92],\n","         [ 89, 114, 100]],\n"," \n","        ...,\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [116, 129, 145],\n","         [114, 127, 143],\n","         [113, 126, 142]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [117, 130, 146],\n","         [116, 129, 145],\n","         [114, 127, 143]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [118, 131, 147],\n","         [116, 129, 145],\n","         [115, 128, 144]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_244_jpg.rf.d06a6dfde2b22021c07360a2c1165d1d.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9664764404296875, 'inference': 7.180213928222656, 'postprocess': 1.2907981872558594},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 40,  39,  43],\n","         [ 70,  67,  69],\n","         [ 65,  57,  57],\n","         ...,\n","         [ 23,  24,  20],\n","         [ 32,  33,  29],\n","         [ 30,  31,  27]],\n"," \n","        [[ 31,  30,  34],\n","         [ 62,  59,  61],\n","         [ 61,  53,  53],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 39,  40,  36],\n","         [ 39,  40,  36]],\n"," \n","        [[ 40,  39,  43],\n","         [ 66,  63,  65],\n","         [ 63,  55,  55],\n","         ...,\n","         [ 32,  33,  29],\n","         [ 45,  46,  42],\n","         [ 45,  46,  42]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [162, 175, 191],\n","         [163, 176, 192],\n","         [164, 177, 193]],\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_245_jpg.rf.74b9626d2655d7f4d44cecbd084fb233.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.0105838775634766, 'inference': 7.257223129272461, 'postprocess': 1.300811767578125},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 55,  44,  46],\n","         [ 35,  27,  28],\n","         [ 38,  30,  31],\n","         ...,\n","         [ 69,  90,  81],\n","         [ 76,  97,  88],\n","         [ 77,  98,  89]],\n"," \n","        [[ 63,  52,  54],\n","         [ 51,  43,  44],\n","         [ 47,  39,  40],\n","         ...,\n","         [ 80, 101,  92],\n","         [ 81, 102,  93],\n","         [ 76,  97,  88]],\n"," \n","        [[ 71,  60,  62],\n","         [ 67,  59,  60],\n","         [ 54,  46,  47],\n","         ...,\n","         [ 76,  97,  88],\n","         [ 80, 101,  92],\n","         [ 86, 107,  98]],\n"," \n","        ...,\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [128, 139, 153],\n","         [128, 139, 153],\n","         [128, 139, 153]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [132, 143, 157],\n","         [132, 143, 157],\n","         [132, 143, 157]],\n"," \n","        [[195, 204, 218],\n","         [195, 204, 218],\n","         [195, 204, 218],\n","         ...,\n","         [135, 146, 160],\n","         [135, 146, 160],\n","         [135, 146, 160]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_245_jpg.rf.7a50c73c1d43ceb4373259141fac159c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1660327911376953, 'inference': 7.25102424621582, 'postprocess': 1.4297962188720703},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 41,  30,  40],\n","         [ 77,  64,  72],\n","         [ 75,  61,  63],\n","         ...,\n","         [ 25,  20,  17],\n","         [ 36,  31,  28],\n","         [ 36,  31,  28]],\n"," \n","        [[ 47,  36,  46],\n","         [ 75,  62,  70],\n","         [ 69,  55,  57],\n","         ...,\n","         [ 29,  24,  21],\n","         [ 41,  36,  33],\n","         [ 42,  37,  34]],\n"," \n","        [[ 54,  43,  53],\n","         [ 73,  60,  68],\n","         [ 63,  49,  51],\n","         ...,\n","         [ 32,  29,  25],\n","         [ 44,  41,  37],\n","         [ 45,  42,  38]],\n"," \n","        ...,\n"," \n","        [[210, 219, 233],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [210, 219, 233],\n","         ...,\n","         [160, 173, 189],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [210, 219, 233],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_247_jpg.rf.dc7d182b5e2cd43ef3d65441465d73d8.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.027273178100586, 'inference': 7.192373275756836, 'postprocess': 1.3244152069091797},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 37,  24,  40],\n","         [ 73,  59,  71],\n","         [ 70,  53,  62],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 26,  27,  25],\n","         [ 35,  36,  34]],\n"," \n","        [[ 44,  31,  47],\n","         [ 75,  61,  73],\n","         [ 70,  54,  61],\n","         ...,\n","         [ 25,  26,  24],\n","         [ 33,  34,  32],\n","         [ 43,  44,  42]],\n"," \n","        [[ 50,  37,  51],\n","         [ 73,  59,  71],\n","         [ 66,  50,  57],\n","         ...,\n","         [ 28,  29,  27],\n","         [ 37,  38,  36],\n","         [ 47,  48,  46]],\n"," \n","        ...,\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[209, 218, 232],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[208, 217, 231],\n","         [208, 217, 231],\n","         [209, 218, 232],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_248_jpg.rf.c66e4d7dad6a876ee2e13caf66cbc78e.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.101421356201172, 'inference': 7.210254669189453, 'postprocess': 1.4886856079101562},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 37,  24,  40],\n","         [ 73,  59,  71],\n","         [ 70,  53,  62],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 26,  27,  25],\n","         [ 35,  36,  34]],\n"," \n","        [[ 44,  31,  47],\n","         [ 75,  61,  73],\n","         [ 70,  54,  61],\n","         ...,\n","         [ 25,  26,  24],\n","         [ 33,  34,  32],\n","         [ 43,  44,  42]],\n"," \n","        [[ 50,  37,  51],\n","         [ 73,  59,  71],\n","         [ 66,  50,  57],\n","         ...,\n","         [ 28,  29,  27],\n","         [ 37,  38,  36],\n","         [ 47,  48,  46]],\n"," \n","        ...,\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[209, 218, 232],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[208, 217, 231],\n","         [208, 217, 231],\n","         [209, 218, 232],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_248_jpg.rf.de5dd4f9e457901cd8691be9d3000d0d.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9009113311767578, 'inference': 7.129669189453125, 'postprocess': 1.7895698547363281},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  33,  36],\n","         [ 66,  68,  69],\n","         [ 71,  61,  61],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 24,  25,  21],\n","         [ 27,  28,  24]],\n"," \n","        [[ 31,  36,  39],\n","         [ 66,  65,  67],\n","         [ 70,  60,  60],\n","         ...,\n","         [ 26,  27,  23],\n","         [ 30,  31,  27],\n","         [ 34,  35,  31]],\n"," \n","        [[ 38,  41,  45],\n","         [ 64,  63,  65],\n","         [ 63,  53,  53],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 35,  36,  32],\n","         [ 41,  42,  38]],\n"," \n","        ...,\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [160, 173, 189],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_249_jpg.rf.bea083cff3dde453bff37fc43ae2aaba.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9075870513916016, 'inference': 7.17926025390625, 'postprocess': 1.3005733489990234},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  33,  36],\n","         [ 66,  68,  69],\n","         [ 71,  61,  61],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 24,  25,  21],\n","         [ 27,  28,  24]],\n"," \n","        [[ 31,  36,  39],\n","         [ 66,  65,  67],\n","         [ 70,  60,  60],\n","         ...,\n","         [ 26,  27,  23],\n","         [ 30,  31,  27],\n","         [ 34,  35,  31]],\n"," \n","        [[ 38,  41,  45],\n","         [ 64,  63,  65],\n","         [ 63,  53,  53],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 35,  36,  32],\n","         [ 41,  42,  38]],\n"," \n","        ...,\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [163, 176, 192]],\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [160, 173, 189],\n","         [161, 174, 190],\n","         [162, 175, 191]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [159, 172, 188],\n","         [161, 174, 190],\n","         [161, 174, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_249_jpg.rf.f057981e9e27cd39a3e7d7b23f0790c9.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9683837890625, 'inference': 7.171392440795898, 'postprocess': 1.2657642364501953},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 34,  34,  34],\n","         [ 73,  69,  68],\n","         [ 76,  63,  61],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 23,  24,  20],\n","         [ 24,  25,  21]],\n"," \n","        [[ 52,  52,  52],\n","         [ 78,  74,  73],\n","         [ 70,  57,  55],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 30,  31,  27],\n","         [ 33,  34,  30]],\n"," \n","        [[ 54,  54,  54],\n","         [ 68,  64,  63],\n","         [ 56,  43,  41],\n","         ...,\n","         [ 29,  30,  26],\n","         [ 36,  37,  33],\n","         [ 41,  42,  38]],\n"," \n","        ...,\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [160, 173, 189],\n","         [162, 175, 191],\n","         [162, 175, 191]],\n"," \n","        [[210, 220, 237],\n","         [210, 220, 237],\n","         [210, 220, 237],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[209, 219, 236],\n","         [209, 219, 236],\n","         [209, 219, 236],\n","         ...,\n","         [155, 168, 184],\n","         [156, 169, 185],\n","         [157, 170, 186]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_251_jpg.rf.60688b93b2dbc3670a61d83f2c646779.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9240379333496094, 'inference': 7.136821746826172, 'postprocess': 1.2183189392089844},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  38,  38],\n","         [ 74,  70,  69],\n","         [ 73,  60,  58],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 23,  24,  20],\n","         [ 25,  26,  22]],\n"," \n","        [[ 42,  42,  42],\n","         [ 70,  66,  65],\n","         [ 64,  51,  49],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 30,  31,  27],\n","         [ 33,  34,  30]],\n"," \n","        [[ 51,  51,  51],\n","         [ 68,  64,  63],\n","         [ 59,  46,  44],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 35,  36,  32],\n","         [ 39,  40,  36]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_252_jpg.rf.55518795999a935be1d69752615ae22d.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.1886825561523438, 'inference': 7.190465927124023, 'postprocess': 1.3704299926757812},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  38,  38],\n","         [ 74,  70,  69],\n","         [ 73,  60,  58],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 23,  24,  20],\n","         [ 25,  26,  22]],\n"," \n","        [[ 42,  42,  42],\n","         [ 70,  66,  65],\n","         [ 64,  51,  49],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 30,  31,  27],\n","         [ 33,  34,  30]],\n"," \n","        [[ 51,  51,  51],\n","         [ 68,  64,  63],\n","         [ 59,  46,  44],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 35,  36,  32],\n","         [ 39,  40,  36]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_252_jpg.rf.5f65f164a8969fd4767c1cd4d4b72c7e.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.979827880859375, 'inference': 7.144689559936523, 'postprocess': 1.8153190612792969},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 32,  29,  38],\n","         [ 64,  57,  64],\n","         [ 72,  58,  60],\n","         ...,\n","         [ 17,  18,  16],\n","         [ 23,  24,  22],\n","         [ 24,  25,  23]],\n"," \n","        [[ 37,  34,  43],\n","         [ 67,  61,  66],\n","         [ 68,  54,  56],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 27,  28,  26],\n","         [ 28,  29,  27]],\n"," \n","        [[ 40,  38,  44],\n","         [ 70,  64,  69],\n","         [ 67,  53,  55],\n","         ...,\n","         [ 22,  23,  21],\n","         [ 31,  32,  30],\n","         [ 32,  33,  31]],\n"," \n","        ...,\n"," \n","        [[207, 215, 232],\n","         [207, 215, 232],\n","         [207, 215, 232],\n","         ...,\n","         [164, 176, 194],\n","         [166, 178, 196],\n","         [167, 179, 197]],\n"," \n","        [[207, 215, 232],\n","         [207, 215, 232],\n","         [207, 215, 232],\n","         ...,\n","         [164, 176, 194],\n","         [165, 177, 195],\n","         [166, 178, 196]],\n"," \n","        [[207, 215, 232],\n","         [207, 215, 232],\n","         [207, 215, 232],\n","         ...,\n","         [163, 175, 193],\n","         [165, 177, 195],\n","         [165, 177, 195]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_253_jpg.rf.4c570dee11102cb3853ebfa30e61d414.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9528865814208984, 'inference': 7.143259048461914, 'postprocess': 1.3539791107177734},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  35,  44],\n","         [ 48,  44,  50],\n","         [ 68,  60,  61],\n","         ...,\n","         [ 18,  19,  15],\n","         [ 28,  29,  25],\n","         [ 27,  28,  24]],\n"," \n","        [[ 46,  43,  52],\n","         [ 53,  49,  55],\n","         [ 65,  57,  58],\n","         ...,\n","         [ 24,  25,  21],\n","         [ 35,  36,  32],\n","         [ 36,  37,  33]],\n"," \n","        [[ 50,  47,  56],\n","         [ 55,  51,  57],\n","         [ 60,  52,  53],\n","         ...,\n","         [ 28,  29,  25],\n","         [ 41,  42,  38],\n","         [ 43,  44,  40]],\n"," \n","        ...,\n"," \n","        [[213, 222, 236],\n","         [213, 222, 236],\n","         [213, 222, 236],\n","         ...,\n","         [158, 171, 187],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[213, 222, 236],\n","         [213, 222, 236],\n","         [213, 222, 236],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_253_jpg.rf.6a3f8c5c5a230728a8af1d075ce59f17.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.015352249145508, 'inference': 7.178544998168945, 'postprocess': 1.2845993041992188},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 37,  34,  43],\n","         [ 55,  51,  57],\n","         [ 67,  59,  60],\n","         ...,\n","         [ 19,  20,  16],\n","         [ 29,  30,  26],\n","         [ 29,  30,  26]],\n"," \n","        [[ 41,  38,  47],\n","         [ 56,  52,  58],\n","         [ 65,  57,  58],\n","         ...,\n","         [ 24,  25,  21],\n","         [ 36,  37,  33],\n","         [ 37,  38,  34]],\n"," \n","        [[ 47,  44,  53],\n","         [ 57,  53,  59],\n","         [ 60,  52,  53],\n","         ...,\n","         [ 27,  28,  24],\n","         [ 40,  41,  37],\n","         [ 42,  43,  39]],\n"," \n","        ...,\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [159, 172, 188],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[213, 221, 238],\n","         [213, 221, 238],\n","         [213, 221, 238],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[212, 220, 237],\n","         [212, 220, 237],\n","         [212, 220, 237],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_254_jpg.rf.9b377bdb129d8a45c86d4c5a26108600.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9268989562988281, 'inference': 7.136106491088867, 'postprocess': 1.3113021850585938},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 34,  35,  39],\n","         [ 56,  53,  55],\n","         [ 76,  64,  64],\n","         ...,\n","         [ 28,  24,  23],\n","         [ 31,  27,  26],\n","         [ 32,  28,  27]],\n"," \n","        [[ 40,  41,  45],\n","         [ 51,  48,  50],\n","         [ 59,  47,  47],\n","         ...,\n","         [ 32,  28,  27],\n","         [ 37,  33,  32],\n","         [ 40,  36,  35]],\n"," \n","        [[ 59,  60,  64],\n","         [ 61,  58,  60],\n","         [ 58,  46,  46],\n","         ...,\n","         [ 35,  31,  30],\n","         [ 42,  38,  37],\n","         [ 46,  42,  41]],\n"," \n","        ...,\n"," \n","        [[213, 222, 236],\n","         [213, 222, 236],\n","         [213, 222, 236],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [157, 170, 186],\n","         [158, 171, 187],\n","         [159, 172, 188]],\n"," \n","        [[208, 217, 231],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [156, 169, 185],\n","         [158, 171, 187],\n","         [158, 171, 187]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_255_jpg.rf.2a5370fe431de7b4ae97ad5b286432ff.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.8961429595947266, 'inference': 7.140874862670898, 'postprocess': 1.2161731719970703},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 34,  35,  39],\n","         [ 56,  53,  55],\n","         [ 76,  64,  64],\n","         ...,\n","         [ 28,  24,  23],\n","         [ 31,  27,  26],\n","         [ 32,  28,  27]],\n"," \n","        [[ 40,  41,  45],\n","         [ 51,  48,  50],\n","         [ 59,  47,  47],\n","         ...,\n","         [ 32,  28,  27],\n","         [ 37,  33,  32],\n","         [ 40,  36,  35]],\n"," \n","        [[ 59,  60,  64],\n","         [ 61,  58,  60],\n","         [ 58,  46,  46],\n","         ...,\n","         [ 35,  31,  30],\n","         [ 42,  38,  37],\n","         [ 46,  42,  41]],\n"," \n","        ...,\n"," \n","        [[213, 222, 236],\n","         [213, 222, 236],\n","         [213, 222, 236],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [211, 220, 234],\n","         ...,\n","         [157, 170, 186],\n","         [158, 171, 187],\n","         [159, 172, 188]],\n"," \n","        [[208, 217, 231],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [156, 169, 185],\n","         [158, 171, 187],\n","         [158, 171, 187]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_255_jpg.rf.b334d12480ed53a8623a21983c8e2fb0.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.890420913696289, 'inference': 7.139444351196289, 'postprocess': 1.2536048889160156},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  31,  35],\n","         [ 55,  52,  54],\n","         [ 75,  63,  63],\n","         ...,\n","         [ 24,  25,  23],\n","         [ 27,  28,  26],\n","         [ 28,  29,  27]],\n"," \n","        [[ 46,  47,  51],\n","         [ 61,  58,  60],\n","         [ 69,  57,  57],\n","         ...,\n","         [ 28,  29,  27],\n","         [ 33,  34,  32],\n","         [ 36,  37,  35]],\n"," \n","        [[ 54,  55,  59],\n","         [ 61,  58,  60],\n","         [ 62,  50,  50],\n","         ...,\n","         [ 31,  32,  30],\n","         [ 38,  39,  37],\n","         [ 42,  43,  41]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [158, 171, 187],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[209, 218, 232],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_256_jpg.rf.143ef39f59c937557a71263909d8378c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9195079803466797, 'inference': 7.128000259399414, 'postprocess': 1.1837482452392578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 50,  43,  46],\n","         [ 38,  31,  34],\n","         [ 43,  38,  40],\n","         ...,\n","         [ 84,  99,  91],\n","         [ 90, 107,  98],\n","         [101, 118, 109]],\n"," \n","        [[ 72,  65,  68],\n","         [ 55,  48,  51],\n","         [ 37,  32,  34],\n","         ...,\n","         [ 92, 109, 100],\n","         [ 88, 105,  96],\n","         [ 87, 104,  95]],\n"," \n","        [[ 81,  74,  77],\n","         [ 73,  66,  69],\n","         [ 39,  34,  36],\n","         ...,\n","         [ 95, 114, 105],\n","         [ 97, 116, 107],\n","         [100, 119, 110]],\n"," \n","        ...,\n"," \n","        [[196, 205, 219],\n","         [196, 205, 219],\n","         [196, 205, 219],\n","         ...,\n","         [159, 173, 192],\n","         [159, 173, 192],\n","         [159, 173, 192]],\n"," \n","        [[196, 205, 219],\n","         [196, 205, 219],\n","         [196, 205, 219],\n","         ...,\n","         [162, 176, 195],\n","         [162, 176, 195],\n","         [163, 177, 196]],\n"," \n","        [[196, 205, 219],\n","         [196, 205, 219],\n","         [196, 205, 219],\n","         ...,\n","         [164, 178, 197],\n","         [165, 179, 198],\n","         [165, 179, 198]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_256_jpg.rf.4cd18ce9e5b778a8021e9d79bd4651de.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9595623016357422, 'inference': 7.167816162109375, 'postprocess': 1.287221908569336},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 30,  31,  35],\n","         [ 55,  52,  54],\n","         [ 75,  63,  63],\n","         ...,\n","         [ 24,  25,  23],\n","         [ 27,  28,  26],\n","         [ 28,  29,  27]],\n"," \n","        [[ 46,  47,  51],\n","         [ 61,  58,  60],\n","         [ 69,  57,  57],\n","         ...,\n","         [ 28,  29,  27],\n","         [ 33,  34,  32],\n","         [ 36,  37,  35]],\n"," \n","        [[ 54,  55,  59],\n","         [ 61,  58,  60],\n","         [ 62,  50,  50],\n","         ...,\n","         [ 31,  32,  30],\n","         [ 38,  39,  37],\n","         [ 42,  43,  41]],\n"," \n","        ...,\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [158, 171, 187],\n","         [160, 173, 189],\n","         [161, 174, 190]],\n"," \n","        [[210, 219, 233],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [158, 171, 187],\n","         [159, 172, 188],\n","         [160, 173, 189]],\n"," \n","        [[209, 218, 232],\n","         [209, 218, 232],\n","         [210, 219, 233],\n","         ...,\n","         [157, 170, 186],\n","         [159, 172, 188],\n","         [159, 172, 188]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_256_jpg.rf.f14842f456a1c5567fab2a3a7d7ba8f0.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.9962787628173828, 'inference': 7.2078704833984375, 'postprocess': 1.3005733489990234},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 56,  50,  51],\n","         [ 46,  40,  41],\n","         [ 52,  47,  48],\n","         ...,\n","         [ 94, 111,  97],\n","         [ 97, 116, 101],\n","         [101, 120, 105]],\n"," \n","        [[ 67,  61,  62],\n","         [ 57,  51,  52],\n","         [ 54,  49,  50],\n","         ...,\n","         [ 93, 112,  97],\n","         [ 88, 107,  92],\n","         [ 81, 100,  85]],\n"," \n","        [[ 77,  71,  72],\n","         [ 68,  62,  63],\n","         [ 53,  48,  49],\n","         ...,\n","         [ 97, 118, 103],\n","         [ 99, 120, 105],\n","         [ 98, 119, 104]],\n"," \n","        ...,\n"," \n","        [[198, 205, 222],\n","         [198, 205, 222],\n","         [198, 205, 222],\n","         ...,\n","         [159, 173, 192],\n","         [159, 173, 192],\n","         [160, 174, 193]],\n"," \n","        [[198, 205, 222],\n","         [198, 205, 222],\n","         [198, 205, 222],\n","         ...,\n","         [163, 177, 196],\n","         [163, 177, 196],\n","         [163, 177, 196]],\n"," \n","        [[198, 205, 222],\n","         [198, 205, 222],\n","         [198, 205, 222],\n","         ...,\n","         [165, 179, 198],\n","         [166, 180, 199],\n","         [166, 180, 199]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_257_jpg.rf.c30832d4fac283445eccb9370ed4e423.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 1.8832683563232422, 'inference': 7.632970809936523, 'postprocess': 1.3294219970703125},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 28,  30,  40],\n","         [ 50,  49,  58],\n","         [ 68,  57,  60],\n","         ...,\n","         [ 20,  21,  19],\n","         [ 24,  25,  23],\n","         [ 28,  29,  27]],\n"," \n","        [[ 41,  44,  52],\n","         [ 60,  58,  64],\n","         [ 72,  61,  64],\n","         ...,\n","         [ 26,  27,  25],\n","         [ 32,  33,  31],\n","         [ 37,  38,  36]],\n"," \n","        [[ 44,  47,  52],\n","         [ 56,  55,  59],\n","         [ 62,  51,  53],\n","         ...,\n","         [ 30,  31,  29],\n","         [ 38,  39,  37],\n","         [ 43,  44,  42]],\n"," \n","        ...,\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [214, 223, 237],\n","         ...,\n","         [151, 161, 178],\n","         [151, 161, 178],\n","         [151, 161, 178]],\n"," \n","        [[215, 224, 238],\n","         [214, 223, 237],\n","         [212, 221, 235],\n","         ...,\n","         [151, 161, 178],\n","         [151, 161, 178],\n","         [151, 161, 178]],\n"," \n","        [[215, 224, 238],\n","         [213, 222, 236],\n","         [210, 219, 233],\n","         ...,\n","         [151, 161, 178],\n","         [151, 161, 178],\n","         [151, 161, 178]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_258_jpg.rf.fdfaa9339b57036dc1a0ef2a3d81c6aa.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.229928970336914, 'inference': 13.828754425048828, 'postprocess': 1.8405914306640625},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  34,  39],\n","         [ 57,  52,  54],\n","         [ 73,  63,  63],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 29,  30,  26],\n","         [ 27,  28,  24]],\n"," \n","        [[ 53,  49,  54],\n","         [ 61,  56,  58],\n","         [ 65,  55,  55],\n","         ...,\n","         [ 26,  27,  23],\n","         [ 37,  38,  34],\n","         [ 36,  37,  33]],\n"," \n","        [[ 61,  57,  62],\n","         [ 62,  57,  59],\n","         [ 58,  48,  48],\n","         ...,\n","         [ 30,  31,  27],\n","         [ 42,  43,  39],\n","         [ 42,  43,  39]],\n"," \n","        ...,\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [214, 223, 237],\n","         ...,\n","         [146, 156, 173],\n","         [148, 158, 175],\n","         [149, 159, 176]],\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [146, 156, 173],\n","         [147, 157, 174],\n","         [148, 158, 175]],\n"," \n","        [[209, 218, 232],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [145, 155, 172],\n","         [147, 157, 174],\n","         [147, 157, 174]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_259_jpg.rf.232857fde2743b4936d704c8f871f1dd.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.4411678314208984, 'inference': 10.888099670410156, 'postprocess': 1.8656253814697266},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  34,  39],\n","         [ 57,  52,  54],\n","         [ 73,  63,  63],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 29,  30,  26],\n","         [ 27,  28,  24]],\n"," \n","        [[ 53,  49,  54],\n","         [ 61,  56,  58],\n","         [ 65,  55,  55],\n","         ...,\n","         [ 26,  27,  23],\n","         [ 37,  38,  34],\n","         [ 36,  37,  33]],\n"," \n","        [[ 61,  57,  62],\n","         [ 62,  57,  59],\n","         [ 58,  48,  48],\n","         ...,\n","         [ 30,  31,  27],\n","         [ 42,  43,  39],\n","         [ 42,  43,  39]],\n"," \n","        ...,\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [214, 223, 237],\n","         ...,\n","         [146, 156, 173],\n","         [148, 158, 175],\n","         [149, 159, 176]],\n"," \n","        [[212, 221, 235],\n","         [212, 221, 235],\n","         [212, 221, 235],\n","         ...,\n","         [146, 156, 173],\n","         [147, 157, 174],\n","         [148, 158, 175]],\n"," \n","        [[209, 218, 232],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [145, 155, 172],\n","         [147, 157, 174],\n","         [147, 157, 174]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_259_jpg.rf.708954ae4c941b58048a0e77304cd7fb.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.4733543395996094, 'inference': 10.41555404663086, 'postprocess': 1.8603801727294922},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 40,  35,  44],\n","         [ 58,  51,  58],\n","         [ 68,  57,  59],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 28,  29,  25],\n","         [ 26,  27,  23]],\n"," \n","        [[ 54,  49,  58],\n","         [ 62,  56,  61],\n","         [ 61,  50,  52],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 36,  37,  33],\n","         [ 35,  36,  32]],\n"," \n","        [[ 58,  54,  60],\n","         [ 60,  54,  59],\n","         [ 55,  44,  46],\n","         ...,\n","         [ 29,  30,  26],\n","         [ 41,  42,  38],\n","         [ 41,  42,  38]],\n"," \n","        ...,\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [215, 224, 238],\n","         ...,\n","         [139, 150, 164],\n","         [141, 152, 166],\n","         [143, 154, 168]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [213, 222, 236],\n","         ...,\n","         [139, 150, 164],\n","         [142, 153, 167],\n","         [143, 154, 168]],\n"," \n","        [[209, 218, 232],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [139, 150, 164],\n","         [142, 153, 167],\n","         [144, 155, 169]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_260_jpg.rf.51f2f0097765bdf00f208a80161bbd10.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.309560775756836, 'inference': 10.004043579101562, 'postprocess': 1.9023418426513672},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 40,  35,  44],\n","         [ 58,  51,  58],\n","         [ 68,  57,  59],\n","         ...,\n","         [ 20,  21,  17],\n","         [ 28,  29,  25],\n","         [ 26,  27,  23]],\n"," \n","        [[ 54,  49,  58],\n","         [ 62,  56,  61],\n","         [ 61,  50,  52],\n","         ...,\n","         [ 25,  26,  22],\n","         [ 36,  37,  33],\n","         [ 35,  36,  32]],\n"," \n","        [[ 58,  54,  60],\n","         [ 60,  54,  59],\n","         [ 55,  44,  46],\n","         ...,\n","         [ 29,  30,  26],\n","         [ 41,  42,  38],\n","         [ 41,  42,  38]],\n"," \n","        ...,\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [215, 224, 238],\n","         ...,\n","         [139, 150, 164],\n","         [141, 152, 166],\n","         [143, 154, 168]],\n"," \n","        [[211, 220, 234],\n","         [211, 220, 234],\n","         [213, 222, 236],\n","         ...,\n","         [139, 150, 164],\n","         [142, 153, 167],\n","         [143, 154, 168]],\n"," \n","        [[209, 218, 232],\n","         [210, 219, 233],\n","         [211, 220, 234],\n","         ...,\n","         [139, 150, 164],\n","         [142, 153, 167],\n","         [144, 155, 169]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_260_jpg.rf.e1e7f12db0d4b332f6433ed68a1c637f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.521038055419922, 'inference': 8.265256881713867, 'postprocess': 1.5957355499267578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 68,  53,  57],\n","         [ 37,  22,  26],\n","         [ 60,  46,  50],\n","         ...,\n","         [ 77,  97,  84],\n","         [105, 125, 112],\n","         [ 93, 113, 100]],\n"," \n","        [[ 78,  63,  67],\n","         [ 55,  40,  44],\n","         [ 63,  49,  53],\n","         ...,\n","         [ 81, 101,  88],\n","         [ 95, 115, 102],\n","         [ 73,  96,  82]],\n"," \n","        [[ 86,  71,  75],\n","         [ 75,  60,  64],\n","         [ 63,  49,  53],\n","         ...,\n","         [ 89, 112,  98],\n","         [106, 129, 115],\n","         [ 92, 117, 103]],\n"," \n","        ...,\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [158, 172, 191],\n","         [158, 172, 191],\n","         [158, 172, 191]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [161, 175, 194],\n","         [161, 175, 194],\n","         [161, 175, 194]],\n"," \n","        [[199, 206, 223],\n","         [199, 206, 223],\n","         [199, 206, 223],\n","         ...,\n","         [164, 178, 197],\n","         [164, 178, 197],\n","         [164, 178, 197]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_261_jpg.rf.06ab92238876794707155f2471b98b4c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2699832916259766, 'inference': 9.094476699829102, 'postprocess': 1.8687248229980469},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 27,  33,  32],\n","         [ 69,  72,  70],\n","         [ 78,  69,  66],\n","         ...,\n","         [ 26,  22,  21],\n","         [ 28,  24,  23],\n","         [ 30,  26,  25]],\n"," \n","        [[ 38,  44,  43],\n","         [ 71,  72,  70],\n","         [ 68,  59,  56],\n","         ...,\n","         [ 31,  27,  26],\n","         [ 35,  31,  30],\n","         [ 38,  34,  33]],\n"," \n","        [[ 45,  50,  49],\n","         [ 66,  67,  65],\n","         [ 59,  50,  47],\n","         ...,\n","         [ 34,  30,  29],\n","         [ 40,  36,  35],\n","         [ 45,  41,  40]],\n"," \n","        ...,\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [214, 223, 237],\n","         ...,\n","         [136, 147, 161],\n","         [138, 149, 163],\n","         [139, 150, 164]],\n"," \n","        [[214, 223, 237],\n","         [214, 223, 237],\n","         [214, 223, 237],\n","         ...,\n","         [136, 147, 161],\n","         [137, 148, 162],\n","         [138, 149, 163]],\n"," \n","        [[213, 222, 236],\n","         [213, 222, 236],\n","         [213, 222, 236],\n","         ...,\n","         [135, 146, 160],\n","         [137, 148, 162],\n","         [137, 148, 162]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_261_jpg.rf.efd95b49d5d12cfb7df31eee450cb95e.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.3124217987060547, 'inference': 8.013725280761719, 'postprocess': 1.856088638305664},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 43,  38,  39],\n","         [ 56,  51,  52],\n","         [ 42,  40,  40],\n","         ...,\n","         [ 91, 104, 102],\n","         [ 96, 110, 108],\n","         [ 99, 113, 111]],\n"," \n","        [[ 66,  61,  62],\n","         [ 64,  59,  60],\n","         [ 35,  33,  33],\n","         ...,\n","         [ 82,  96,  94],\n","         [ 87, 101,  99],\n","         [ 92, 106, 104]],\n"," \n","        [[ 79,  74,  75],\n","         [ 73,  68,  69],\n","         [ 39,  37,  37],\n","         ...,\n","         [ 86, 103,  99],\n","         [ 98, 115, 111],\n","         [110, 127, 123]],\n"," \n","        ...,\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [159, 173, 192],\n","         [159, 173, 192],\n","         [159, 173, 192]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [160, 174, 193],\n","         [160, 174, 193],\n","         [160, 174, 193]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [160, 174, 193],\n","         [160, 174, 193],\n","         [160, 174, 193]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_263_jpg.rf.2cb166273cb2029d450ed79b22a39dbd.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.338409423828125, 'inference': 8.363962173461914, 'postprocess': 2.1071434020996094},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 43,  38,  39],\n","         [ 56,  51,  52],\n","         [ 44,  42,  42],\n","         ...,\n","         [ 84,  92,  91],\n","         [113, 121, 120],\n","         [104, 112, 111]],\n"," \n","        [[ 65,  60,  61],\n","         [ 63,  58,  59],\n","         [ 36,  34,  34],\n","         ...,\n","         [ 82,  93,  91],\n","         [102, 110, 109],\n","         [ 83,  94,  92]],\n"," \n","        [[ 77,  72,  73],\n","         [ 71,  66,  67],\n","         [ 37,  35,  35],\n","         ...,\n","         [ 88, 102,  98],\n","         [111, 122, 119],\n","         [100, 114, 110]],\n"," \n","        ...,\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [157, 171, 190],\n","         [156, 170, 189],\n","         [156, 170, 189]],\n"," \n","        [[199, 208, 222],\n","         [199, 208, 222],\n","         [198, 207, 221],\n","         ...,\n","         [159, 173, 192],\n","         [158, 172, 191],\n","         [158, 172, 191]],\n"," \n","        [[200, 209, 223],\n","         [200, 209, 223],\n","         [199, 208, 222],\n","         ...,\n","         [160, 174, 193],\n","         [159, 173, 192],\n","         [159, 173, 192]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_264_jpg.rf.60444dc0892110a1a05c726c884c2191.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.405881881713867, 'inference': 8.188247680664062, 'postprocess': 1.6262531280517578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 62,  54,  61],\n","         [ 34,  26,  33],\n","         [ 45,  39,  44],\n","         ...,\n","         [ 86, 102,  91],\n","         [ 89, 106,  95],\n","         [ 97, 114, 103]],\n"," \n","        [[ 69,  61,  68],\n","         [ 48,  40,  47],\n","         [ 47,  41,  46],\n","         ...,\n","         [ 94, 111, 100],\n","         [ 89, 106,  95],\n","         [ 86, 103,  92]],\n"," \n","        [[ 72,  64,  71],\n","         [ 64,  56,  63],\n","         [ 47,  41,  46],\n","         ...,\n","         [ 97, 117, 105],\n","         [ 99, 119, 107],\n","         [102, 122, 110]],\n"," \n","        ...,\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [156, 170, 189],\n","         [155, 169, 188],\n","         [155, 169, 188]],\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [159, 173, 192],\n","         [159, 173, 192],\n","         [158, 172, 191]],\n"," \n","        [[198, 207, 221],\n","         [198, 207, 221],\n","         [198, 207, 221],\n","         ...,\n","         [161, 175, 194],\n","         [161, 175, 194],\n","         [161, 175, 194]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_266_jpg.rf.97bb1464553c03a5df00171b2c0978e0.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.285480499267578, 'inference': 8.361101150512695, 'postprocess': 1.5265941619873047},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 58,  47,  49],\n","         [ 30,  22,  23],\n","         [ 55,  47,  48],\n","         ...,\n","         [ 74,  91,  88],\n","         [ 95, 112, 109],\n","         [ 92, 109, 106]],\n"," \n","        [[ 78,  67,  69],\n","         [ 44,  36,  37],\n","         [ 47,  39,  40],\n","         ...,\n","         [ 90, 107, 104],\n","         [100, 117, 114],\n","         [ 87, 106, 103]],\n"," \n","        [[ 86,  75,  77],\n","         [ 63,  55,  56],\n","         [ 48,  40,  41],\n","         ...,\n","         [ 90, 110, 105],\n","         [ 98, 118, 113],\n","         [ 90, 112, 107]],\n"," \n","        ...,\n"," \n","        [[198, 205, 220],\n","         [198, 205, 220],\n","         [198, 205, 220],\n","         ...,\n","         [158, 173, 189],\n","         [158, 173, 189],\n","         [158, 173, 189]],\n"," \n","        [[198, 205, 220],\n","         [198, 205, 220],\n","         [198, 205, 220],\n","         ...,\n","         [161, 176, 192],\n","         [161, 176, 192],\n","         [161, 176, 192]],\n"," \n","        [[198, 205, 220],\n","         [198, 205, 220],\n","         [198, 205, 220],\n","         ...,\n","         [164, 179, 195],\n","         [164, 179, 195],\n","         [164, 179, 195]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_289_jpg.rf.e5e0734d490ccfefefa0123e17e0cc7c.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.31170654296875, 'inference': 7.689476013183594, 'postprocess': 1.6446113586425781},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 58,  53,  50],\n","         [ 36,  31,  28],\n","         [ 39,  36,  32],\n","         ...,\n","         [ 79,  98,  89],\n","         [ 88, 107,  98],\n","         [ 97, 116, 107]],\n"," \n","        [[ 66,  61,  58],\n","         [ 51,  46,  43],\n","         [ 42,  39,  35],\n","         ...,\n","         [ 89, 108,  99],\n","         [ 87, 106,  97],\n","         [ 82, 103,  94]],\n"," \n","        [[ 73,  68,  67],\n","         [ 69,  64,  63],\n","         [ 42,  38,  37],\n","         ...,\n","         [ 94, 115, 106],\n","         [ 96, 117, 108],\n","         [ 95, 119, 109]],\n"," \n","        ...,\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [161, 171, 188],\n","         [160, 170, 187],\n","         [160, 170, 187]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [164, 172, 189],\n","         [164, 172, 189],\n","         [164, 172, 189]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [166, 174, 191],\n","         [165, 173, 190],\n","         [165, 173, 190]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_292_jpg.rf.6ef2af9d2a4d1619b844e330d3f1db4e.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 5.02777099609375, 'inference': 8.758544921875, 'postprocess': 1.943349838256836},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 39,  33,  34],\n","         [ 52,  46,  47],\n","         [ 40,  35,  36],\n","         ...,\n","         [ 82, 102,  90],\n","         [ 86, 106,  94],\n","         [ 91, 111,  99]],\n"," \n","        [[ 64,  58,  59],\n","         [ 62,  56,  57],\n","         [ 34,  29,  30],\n","         ...,\n","         [ 98, 118, 106],\n","         [ 95, 115, 103],\n","         [ 88, 110,  98]],\n"," \n","        [[ 81,  75,  76],\n","         [ 75,  69,  70],\n","         [ 41,  36,  37],\n","         ...,\n","         [ 96, 119, 105],\n","         [ 97, 120, 106],\n","         [ 94, 119, 105]],\n"," \n","        ...,\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [154, 168, 187],\n","         [154, 168, 187],\n","         [154, 168, 187]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [157, 171, 190],\n","         [157, 171, 190],\n","         [157, 171, 190]],\n"," \n","        [[197, 206, 220],\n","         [197, 206, 220],\n","         [197, 206, 220],\n","         ...,\n","         [159, 173, 192],\n","         [159, 173, 192],\n","         [159, 173, 192]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_293_jpg.rf.0a0744ce10023924cf2468df43669093.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2842884063720703, 'inference': 8.172035217285156, 'postprocess': 1.8129348754882812},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 55,  49,  50],\n","         [ 38,  32,  33],\n","         [ 58,  53,  54],\n","         ...,\n","         [ 84, 103,  94],\n","         [ 92, 111, 102],\n","         [101, 120, 111]],\n"," \n","        [[ 72,  66,  67],\n","         [ 49,  43,  44],\n","         [ 45,  40,  41],\n","         ...,\n","         [ 86, 105,  96],\n","         [ 83, 102,  93],\n","         [ 78,  99,  90]],\n"," \n","        [[ 78,  72,  73],\n","         [ 68,  62,  63],\n","         [ 43,  38,  39],\n","         ...,\n","         [ 93, 115, 103],\n","         [ 96, 118, 106],\n","         [ 94, 118, 106]],\n"," \n","        ...,\n"," \n","        [[192, 199, 216],\n","         [192, 199, 216],\n","         [192, 199, 216],\n","         ...,\n","         [155, 169, 188],\n","         [155, 169, 188],\n","         [154, 168, 187]],\n"," \n","        [[192, 199, 216],\n","         [192, 199, 216],\n","         [192, 199, 216],\n","         ...,\n","         [157, 171, 190],\n","         [157, 171, 190],\n","         [157, 171, 190]],\n"," \n","        [[192, 199, 216],\n","         [192, 199, 216],\n","         [192, 199, 216],\n","         ...,\n","         [159, 173, 192],\n","         [159, 173, 192],\n","         [159, 173, 192]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_296_jpg.rf.7dbfb3956507fa83a7383eb4703db318.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.3012161254882812, 'inference': 7.800579071044922, 'postprocess': 1.5499591827392578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 42,  35,  40],\n","         [ 63,  54,  57],\n","         [ 55,  43,  43],\n","         ...,\n","         [ 16,  19,  17],\n","         [ 20,  23,  21],\n","         [ 24,  27,  25]],\n"," \n","        [[ 39,  32,  37],\n","         [ 65,  56,  59],\n","         [ 61,  49,  49],\n","         ...,\n","         [ 18,  21,  19],\n","         [ 24,  27,  25],\n","         [ 28,  31,  29]],\n"," \n","        [[ 36,  29,  32],\n","         [ 67,  59,  60],\n","         [ 65,  53,  53],\n","         ...,\n","         [ 19,  22,  20],\n","         [ 26,  29,  27],\n","         [ 32,  35,  33]],\n"," \n","        ...,\n"," \n","        [[197, 206, 226],\n","         [197, 206, 226],\n","         [197, 206, 226],\n","         ...,\n","         [158, 170, 188],\n","         [160, 172, 190],\n","         [161, 173, 191]],\n"," \n","        [[196, 205, 225],\n","         [196, 205, 225],\n","         [196, 205, 225],\n","         ...,\n","         [158, 170, 188],\n","         [160, 172, 190],\n","         [161, 173, 191]],\n"," \n","        [[195, 204, 224],\n","         [195, 204, 224],\n","         [195, 204, 224],\n","         ...,\n","         [158, 170, 188],\n","         [160, 172, 190],\n","         [161, 173, 191]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_300_jpg.rf.00bba315c367a74b065f6bb57b542bb9.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2881031036376953, 'inference': 7.9345703125, 'postprocess': 1.6086101531982422},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  28,  34],\n","         [ 56,  45,  48],\n","         [ 68,  54,  55],\n","         ...,\n","         [ 16,  17,  15],\n","         [ 22,  23,  21],\n","         [ 27,  28,  26]],\n"," \n","        [[ 45,  35,  41],\n","         [ 59,  48,  51],\n","         [ 63,  49,  50],\n","         ...,\n","         [ 18,  19,  17],\n","         [ 25,  26,  24],\n","         [ 31,  32,  30]],\n"," \n","        [[ 49,  39,  45],\n","         [ 61,  50,  53],\n","         [ 60,  46,  47],\n","         ...,\n","         [ 19,  20,  18],\n","         [ 28,  29,  27],\n","         [ 34,  35,  33]],\n"," \n","        ...,\n"," \n","        [[196, 205, 225],\n","         [196, 205, 225],\n","         [196, 205, 225],\n","         ...,\n","         [158, 170, 188],\n","         [160, 172, 190],\n","         [161, 173, 191]],\n"," \n","        [[197, 206, 226],\n","         [197, 206, 226],\n","         [197, 206, 226],\n","         ...,\n","         [158, 170, 188],\n","         [159, 171, 189],\n","         [160, 172, 190]],\n"," \n","        [[197, 206, 226],\n","         [197, 206, 226],\n","         [197, 206, 226],\n","         ...,\n","         [157, 169, 187],\n","         [159, 171, 189],\n","         [159, 171, 189]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_310_jpg.rf.8263816cf742d05caf60f1d003d3c258.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 3.2711029052734375, 'inference': 8.077383041381836, 'postprocess': 1.5375614166259766},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 24,  25,  29],\n","         [ 59,  56,  58],\n","         [ 68,  56,  56],\n","         ...,\n","         [ 19,  20,  16],\n","         [ 21,  22,  18],\n","         [ 24,  25,  21]],\n"," \n","        [[ 32,  33,  37],\n","         [ 61,  58,  60],\n","         [ 62,  50,  50],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 25,  26,  22],\n","         [ 28,  29,  25]],\n"," \n","        [[ 37,  39,  40],\n","         [ 63,  61,  61],\n","         [ 58,  46,  46],\n","         ...,\n","         [ 21,  22,  18],\n","         [ 27,  28,  24],\n","         [ 32,  33,  29]],\n"," \n","        ...,\n"," \n","        [[202, 209, 229],\n","         [202, 209, 229],\n","         [202, 209, 229],\n","         ...,\n","         [144, 154, 171],\n","         [146, 156, 173],\n","         [147, 157, 174]],\n"," \n","        [[202, 209, 229],\n","         [202, 209, 229],\n","         [202, 209, 229],\n","         ...,\n","         [144, 154, 171],\n","         [145, 155, 172],\n","         [146, 156, 173]],\n"," \n","        [[201, 208, 228],\n","         [201, 208, 228],\n","         [201, 208, 228],\n","         ...,\n","         [143, 153, 170],\n","         [145, 155, 172],\n","         [145, 155, 172]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_317_jpg.rf.cd5f13e808577ad5514b298c848607f2.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2192001342773438, 'inference': 7.627010345458984, 'postprocess': 1.5316009521484375},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 93,  93,  93],\n","         [ 93,  93,  93],\n","         [ 91,  91,  91],\n","         ...,\n","         [146, 146, 146],\n","         [152, 152, 152],\n","         [158, 158, 158]],\n"," \n","        [[ 97,  97,  97],\n","         [ 95,  95,  95],\n","         [ 92,  92,  92],\n","         ...,\n","         [149, 149, 149],\n","         [154, 154, 154],\n","         [159, 159, 159]],\n"," \n","        [[103, 103, 103],\n","         [101, 101, 101],\n","         [ 95,  95,  95],\n","         ...,\n","         [149, 149, 149],\n","         [151, 151, 151],\n","         [155, 155, 155]],\n"," \n","        ...,\n"," \n","        [[241, 241, 241],\n","         [231, 231, 231],\n","         [213, 213, 213],\n","         ...,\n","         [220, 220, 220],\n","         [219, 219, 219],\n","         [214, 214, 214]],\n"," \n","        [[243, 243, 243],\n","         [233, 233, 233],\n","         [217, 217, 217],\n","         ...,\n","         [232, 232, 232],\n","         [222, 222, 222],\n","         [209, 209, 209]],\n"," \n","        [[232, 232, 232],\n","         [234, 234, 234],\n","         [234, 234, 234],\n","         ...,\n","         [234, 234, 234],\n","         [226, 226, 226],\n","         [212, 212, 212]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_33_jpg.rf.de8c93cc0d9c53d2c2c0f85a695b6906.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.333402633666992, 'inference': 7.616519927978516, 'postprocess': 1.5838146209716797},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 68,  63,  64],\n","         [ 56,  51,  52],\n","         [ 46,  41,  42],\n","         ...,\n","         [ 90, 116, 102],\n","         [ 88, 115,  99],\n","         [ 84, 111,  95]],\n"," \n","        [[ 74,  69,  70],\n","         [ 60,  55,  56],\n","         [ 48,  43,  44],\n","         ...,\n","         [ 94, 120, 106],\n","         [ 94, 121, 105],\n","         [ 94, 121, 105]],\n"," \n","        [[ 83,  78,  79],\n","         [ 68,  63,  64],\n","         [ 52,  47,  48],\n","         ...,\n","         [ 93, 119, 103],\n","         [ 99, 125, 109],\n","         [104, 130, 114]],\n"," \n","        ...,\n"," \n","        [[219, 220, 234],\n","         [219, 220, 234],\n","         [219, 220, 234],\n","         ...,\n","         [166, 179, 195],\n","         [165, 178, 194],\n","         [165, 178, 194]],\n"," \n","        [[219, 220, 234],\n","         [219, 220, 234],\n","         [219, 220, 234],\n","         ...,\n","         [169, 182, 198],\n","         [169, 182, 198],\n","         [168, 181, 197]],\n"," \n","        [[219, 220, 234],\n","         [219, 220, 234],\n","         [219, 220, 234],\n","         ...,\n","         [171, 184, 200],\n","         [171, 184, 200],\n","         [171, 184, 200]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_34_jpg.rf.ddba711c0a149b1073fe2702a16265ba.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.267122268676758, 'inference': 7.819652557373047, 'postprocess': 1.504659652709961},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[214, 223, 220],\n","         [196, 205, 202],\n","         [165, 172, 169],\n","         ...,\n","         [110, 129, 114],\n","         [ 92, 113,  98],\n","         [ 87, 108,  93]],\n"," \n","        [[196, 205, 202],\n","         [175, 184, 181],\n","         [144, 151, 148],\n","         ...,\n","         [104, 123, 108],\n","         [ 94, 115, 100],\n","         [ 93, 114,  99]],\n"," \n","        [[153, 162, 159],\n","         [141, 150, 147],\n","         [126, 133, 130],\n","         ...,\n","         [ 93, 112,  97],\n","         [ 94, 115, 100],\n","         [ 98, 119, 104]],\n"," \n","        ...,\n"," \n","        [[231, 240, 250],\n","         [223, 232, 242],\n","         [214, 223, 233],\n","         ...,\n","         [ 75,  76,  80],\n","         [ 72,  73,  77],\n","         [ 68,  69,  73]],\n"," \n","        [[225, 234, 244],\n","         [222, 231, 241],\n","         [220, 229, 239],\n","         ...,\n","         [ 73,  74,  78],\n","         [ 67,  68,  72],\n","         [ 59,  60,  64]],\n"," \n","        [[224, 233, 243],\n","         [226, 235, 245],\n","         [229, 238, 248],\n","         ...,\n","         [ 64,  65,  69],\n","         [ 54,  55,  59],\n","         [ 42,  43,  47]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_4_jpg.rf.be2be5fef583fccc16a58d6600f14a83.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2399425506591797, 'inference': 10.110616683959961, 'postprocess': 1.8372535705566406},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 61,  47,  51],\n","         [ 59,  45,  47],\n","         [ 34,  18,  19],\n","         ...,\n","         [ 11,  11,  11],\n","         [  0,   0,   0],\n","         [  0,   0,   0]],\n"," \n","        [[107,  93,  97],\n","         [ 81,  67,  69],\n","         [ 39,  23,  24],\n","         ...,\n","         [ 10,  10,  10],\n","         [  5,   5,   5],\n","         [ 11,  11,  11]],\n"," \n","        [[148, 134, 138],\n","         [114, 100, 102],\n","         [ 68,  52,  53],\n","         ...,\n","         [  6,   6,   6],\n","         [  7,   7,   7],\n","         [ 12,  12,  12]],\n"," \n","        ...,\n"," \n","        [[195, 197, 208],\n","         [214, 216, 227],\n","         [198, 200, 211],\n","         ...,\n","         [170, 179, 192],\n","         [170, 179, 192],\n","         [169, 178, 191]],\n"," \n","        [[207, 209, 220],\n","         [213, 215, 226],\n","         [200, 202, 213],\n","         ...,\n","         [169, 178, 191],\n","         [169, 178, 191],\n","         [168, 177, 190]],\n"," \n","        [[205, 207, 218],\n","         [206, 208, 219],\n","         [215, 217, 228],\n","         ...,\n","         [156, 165, 178],\n","         [167, 176, 189],\n","         [177, 186, 199]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_53_jpg.rf.5225c1a3f20e432581ce9b91b01d7c4f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.580404281616211, 'inference': 8.562088012695312, 'postprocess': 1.7788410186767578},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 55,  52,  54],\n","         [ 48,  45,  47],\n","         [ 40,  37,  39],\n","         ...,\n","         [ 84,  98,  86],\n","         [ 91, 105,  93],\n","         [ 96, 110,  98]],\n"," \n","        [[ 61,  58,  60],\n","         [ 52,  49,  51],\n","         [ 42,  39,  41],\n","         ...,\n","         [ 85,  99,  87],\n","         [ 92, 106,  94],\n","         [ 99, 113, 101]],\n"," \n","        [[ 70,  67,  69],\n","         [ 59,  56,  58],\n","         [ 46,  43,  45],\n","         ...,\n","         [ 82,  96,  84],\n","         [ 91, 105,  93],\n","         [101, 115, 103]],\n"," \n","        ...,\n"," \n","        [[198, 206, 223],\n","         [198, 206, 223],\n","         [198, 206, 223],\n","         ...,\n","         [150, 163, 179],\n","         [149, 162, 178],\n","         [149, 162, 178]],\n"," \n","        [[198, 206, 223],\n","         [198, 206, 223],\n","         [198, 206, 223],\n","         ...,\n","         [152, 165, 181],\n","         [152, 165, 181],\n","         [152, 165, 181]],\n"," \n","        [[198, 206, 223],\n","         [198, 206, 223],\n","         [198, 206, 223],\n","         ...,\n","         [154, 167, 183],\n","         [154, 167, 183],\n","         [154, 167, 183]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_53_jpg.rf.9e4f3466092221422afc0fd157a0ad2b.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 3.1473636627197266, 'inference': 9.156465530395508, 'postprocess': 1.7676353454589844},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 45,  45,  45],\n","         [ 47,  47,  47],\n","         [ 37,  37,  37],\n","         ...,\n","         [ 46,  46,  46],\n","         [ 43,  43,  43],\n","         [ 44,  44,  44]],\n"," \n","        [[ 37,  37,  37],\n","         [ 37,  37,  37],\n","         [ 29,  29,  29],\n","         ...,\n","         [ 49,  49,  49],\n","         [ 45,  45,  45],\n","         [ 46,  46,  46]],\n"," \n","        [[ 30,  30,  30],\n","         [ 31,  31,  31],\n","         [ 27,  27,  27],\n","         ...,\n","         [ 37,  37,  37],\n","         [ 34,  34,  34],\n","         [ 40,  40,  40]],\n"," \n","        ...,\n"," \n","        [[223, 223, 223],\n","         [218, 218, 218],\n","         [226, 226, 226],\n","         ...,\n","         [ 81,  81,  81],\n","         [ 62,  62,  62],\n","         [ 24,  24,  24]],\n"," \n","        [[206, 206, 206],\n","         [212, 212, 212],\n","         [226, 226, 226],\n","         ...,\n","         [ 47,  47,  47],\n","         [ 35,  35,  35],\n","         [ 15,  15,  15]],\n"," \n","        [[188, 188, 188],\n","         [212, 212, 212],\n","         [237, 237, 237],\n","         ...,\n","         [ 18,  18,  18],\n","         [  9,   9,   9],\n","         [  7,   7,   7]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_54_jpg.rf.c9106a0f0a6ad928e63ea1bae305d6be.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.276897430419922, 'inference': 7.879018783569336, 'postprocess': 1.5323162078857422},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 71,  71,  71],\n","         [ 72,  72,  72],\n","         [ 71,  71,  71],\n","         ...,\n","         [  0,   0,   0],\n","         [ 81,  81,  81],\n","         [168, 168, 168]],\n"," \n","        [[ 52,  52,  52],\n","         [ 38,  38,  38],\n","         [ 32,  32,  32],\n","         ...,\n","         [  9,   9,   9],\n","         [ 87,  87,  87],\n","         [135, 135, 135]],\n"," \n","        [[ 19,  19,  19],\n","         [ 11,  11,  11],\n","         [  4,   4,   4],\n","         ...,\n","         [  6,   6,   6],\n","         [ 74,  74,  74],\n","         [104, 104, 104]],\n"," \n","        ...,\n"," \n","        [[179, 179, 179],\n","         [179, 179, 179],\n","         [176, 176, 176],\n","         ...,\n","         [110, 110, 110],\n","         [114, 114, 114],\n","         [123, 123, 123]],\n"," \n","        [[181, 181, 181],\n","         [172, 172, 172],\n","         [167, 167, 167],\n","         ...,\n","         [ 95,  95,  95],\n","         [115, 115, 115],\n","         [135, 135, 135]],\n"," \n","        [[185, 185, 185],\n","         [171, 171, 171],\n","         [166, 166, 166],\n","         ...,\n","         [110, 110, 110],\n","         [121, 121, 121],\n","         [126, 126, 126]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_62_jpg.rf.af83013739b7cf375b0813d0d85f83e0.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.264738082885742, 'inference': 7.93910026550293, 'postprocess': 1.5761852264404297},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 21,  11,  17],\n","         [ 18,   7,  10],\n","         [ 18,   4,   5],\n","         ...,\n","         [ 26,  26,  26],\n","         [  9,   9,   9],\n","         [  0,   0,   0]],\n"," \n","        [[ 38,  28,  34],\n","         [ 29,  18,  21],\n","         [ 27,  13,  14],\n","         ...,\n","         [ 22,  22,  22],\n","         [ 11,  11,  11],\n","         [  6,   6,   6]],\n"," \n","        [[ 58,  48,  54],\n","         [ 37,  26,  29],\n","         [ 25,  11,  12],\n","         ...,\n","         [  7,   7,   7],\n","         [  3,   3,   3],\n","         [  3,   3,   3]],\n"," \n","        ...,\n"," \n","        [[171, 179, 196],\n","         [165, 173, 190],\n","         [171, 179, 196],\n","         ...,\n","         [130, 142, 160],\n","         [134, 146, 164],\n","         [137, 149, 167]],\n"," \n","        [[165, 173, 190],\n","         [168, 176, 193],\n","         [176, 184, 201],\n","         ...,\n","         [127, 139, 157],\n","         [132, 144, 162],\n","         [135, 147, 165]],\n"," \n","        [[157, 165, 182],\n","         [169, 177, 194],\n","         [180, 188, 205],\n","         ...,\n","         [122, 134, 152],\n","         [126, 138, 156],\n","         [129, 141, 159]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_86_jpg.rf.4b22b1105238426807d4e4a5c800de5f.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.480030059814453, 'inference': 10.85519790649414, 'postprocess': 1.6596317291259766},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[118, 116, 122],\n","         [136, 132, 137],\n","         [155, 150, 152],\n","         ...,\n","         [103, 106, 104],\n","         [ 96,  99,  97],\n","         [ 95,  98,  96]],\n"," \n","        [[136, 134, 140],\n","         [137, 133, 138],\n","         [139, 134, 136],\n","         ...,\n","         [ 90,  93,  91],\n","         [ 92,  95,  93],\n","         [ 97, 100,  98]],\n"," \n","        [[136, 134, 140],\n","         [133, 129, 134],\n","         [130, 125, 127],\n","         ...,\n","         [ 88,  91,  89],\n","         [100, 103, 101],\n","         [111, 114, 112]],\n"," \n","        ...,\n"," \n","        [[248, 252, 253],\n","         [245, 249, 250],\n","         [240, 244, 245],\n","         ...,\n","         [230, 238, 251],\n","         [218, 226, 239],\n","         [213, 221, 234]],\n"," \n","        [[249, 253, 254],\n","         [247, 251, 252],\n","         [244, 248, 249],\n","         ...,\n","         [227, 235, 248],\n","         [220, 228, 241],\n","         [220, 228, 241]],\n"," \n","        [[244, 248, 249],\n","         [248, 252, 253],\n","         [251, 255, 255],\n","         ...,\n","         [207, 215, 228],\n","         [215, 223, 236],\n","         [235, 243, 255]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_93_jpg.rf.d19720cdc7bcf5b8d789d9bfaeca2022.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.562284469604492, 'inference': 8.060932159423828, 'postprocess': 0.8685588836669922},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[136, 140, 141],\n","         [175, 179, 180],\n","         [189, 191, 192],\n","         ...,\n","         [163, 184, 176],\n","         [159, 180, 172],\n","         [166, 187, 179]],\n"," \n","        [[128, 132, 133],\n","         [154, 158, 159],\n","         [168, 170, 171],\n","         ...,\n","         [171, 192, 184],\n","         [167, 188, 180],\n","         [165, 186, 178]],\n"," \n","        [[142, 146, 147],\n","         [147, 151, 152],\n","         [155, 157, 158],\n","         ...,\n","         [168, 189, 181],\n","         [170, 191, 183],\n","         [165, 186, 178]],\n"," \n","        ...,\n"," \n","        [[244, 245, 255],\n","         [242, 243, 253],\n","         [229, 230, 240],\n","         ...,\n","         [213, 222, 232],\n","         [216, 225, 235],\n","         [206, 215, 225]],\n"," \n","        [[245, 246, 255],\n","         [244, 245, 255],\n","         [232, 233, 243],\n","         ...,\n","         [199, 208, 218],\n","         [209, 218, 228],\n","         [225, 234, 244]],\n"," \n","        [[232, 233, 243],\n","         [242, 243, 253],\n","         [246, 247, 255],\n","         ...,\n","         [214, 223, 233],\n","         [198, 207, 217],\n","         [207, 216, 226]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_94_jpg.rf.a7fea66027fa9e855c8d150fc40eda50.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.2590160369873047, 'inference': 7.839441299438477, 'postprocess': 1.5749931335449219},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[ 38,  32,  43],\n","         [ 48,  40,  50],\n","         [ 77,  69,  76],\n","         ...,\n","         [  0,   0,   0],\n","         [  5,   5,   5],\n","         [  8,   8,   8]],\n"," \n","        [[ 37,  31,  42],\n","         [ 52,  44,  54],\n","         [ 88,  77,  85],\n","         ...,\n","         [ 18,  18,  18],\n","         [  9,   9,   9],\n","         [  0,   0,   0]],\n"," \n","        [[ 39,  31,  42],\n","         [ 51,  43,  53],\n","         [ 84,  74,  80],\n","         ...,\n","         [ 68,  68,  68],\n","         [ 30,  30,  30],\n","         [  3,   3,   3]],\n"," \n","        ...,\n"," \n","        [[210, 214, 225],\n","         [222, 226, 237],\n","         [215, 219, 230],\n","         ...,\n","         [120, 129, 142],\n","         [144, 153, 166],\n","         [171, 180, 193]],\n"," \n","        [[208, 212, 223],\n","         [222, 226, 237],\n","         [210, 214, 225],\n","         ...,\n","         [120, 129, 142],\n","         [152, 161, 174],\n","         [182, 191, 204]],\n"," \n","        [[201, 205, 216],\n","         [217, 221, 232],\n","         [203, 207, 218],\n","         ...,\n","         [123, 132, 145],\n","         [160, 169, 182],\n","         [192, 201, 214]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/image_97_jpg.rf.c9701142df40271a2a17a9c0f3e64001.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.604246139526367, 'inference': 11.799812316894531, 'postprocess': 3.908395767211914},\n"," ultralytics.engine.results.Results object with attributes:\n"," \n"," boxes: ultralytics.engine.results.Boxes object\n"," keypoints: None\n"," masks: None\n"," names: {0: 'Gloves', 1: 'Hard_hat', 2: 'Person', 3: 'Safety_boots', 4: 'Vest'}\n"," orig_img: array([[[249, 233, 216],\n","         [249, 233, 216],\n","         [249, 233, 216],\n","         ...,\n","         [255, 247, 240],\n","         [255, 247, 240],\n","         [255, 247, 240]],\n"," \n","        [[249, 233, 216],\n","         [249, 233, 216],\n","         [249, 233, 216],\n","         ...,\n","         [255, 247, 240],\n","         [255, 247, 240],\n","         [255, 247, 240]],\n"," \n","        [[249, 233, 216],\n","         [249, 233, 216],\n","         [249, 233, 216],\n","         ...,\n","         [255, 247, 240],\n","         [255, 247, 240],\n","         [255, 247, 240]],\n"," \n","        ...,\n"," \n","        [[152, 134, 111],\n","         [152, 134, 111],\n","         [151, 133, 110],\n","         ...,\n","         [132, 127, 128],\n","         [140, 134, 135],\n","         [143, 137, 138]],\n"," \n","        [[156, 139, 113],\n","         [156, 139, 113],\n","         [155, 138, 112],\n","         ...,\n","         [125, 120, 121],\n","         [132, 126, 127],\n","         [135, 129, 130]],\n"," \n","        [[160, 143, 117],\n","         [159, 142, 116],\n","         [158, 141, 115],\n","         ...,\n","         [117, 112, 113],\n","         [122, 116, 117],\n","         [125, 119, 120]]], dtype=uint8)\n"," orig_shape: (640, 640)\n"," path: '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images/images-2022-07-04T012922_jpg.rf.a1091a2a972babb350e51c636f857222.jpg'\n"," probs: None\n"," save_dir: 'runs/detect/predict4'\n"," speed: {'preprocess': 2.580404281616211, 'inference': 9.669303894042969, 'postprocess': 2.001523971557617}]"]},"metadata":{},"execution_count":9}],"source":["from ultralytics import YOLO\n","\n","# Load a pretrained YOLOv8n model\n","model = YOLO('/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/runs/detect/train/weights/best.pt')\n","\n","# Run inference on 'bus.jpg' with arguments\n","model.predict('/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/test/images', save=True, imgsz=640, conf=0.5, save_txt= True)"]},{"cell_type":"markdown","source":["# **Evaluation**"],"metadata":{"id":"FvfMau0JuzzN"}},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","import os\n","\n","def visualize_images_in_folder(folder_path):\n","    # Get a list of all files in the folder\n","    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    for image_file in image_files:\n","        # Construct the full path to the image\n","        image_path = os.path.join(folder_path, image_file)\n","\n","        # Read the image\n","        img = cv2.imread(image_path)\n","\n","        # Convert from BGR to RGB (OpenCV uses BGR by default)\n","        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        # Display the image\n","        plt.imshow(img_rgb)\n","        plt.title(image_file)  # Set the title to the image file name\n","        plt.axis('off')  # Turn off axis labels\n","        plt.show()\n","\n","# Example usage:\n","test_folder_path = '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/runs/detect/val'\n","visualize_images_in_folder(test_folder_path)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1HcE35d_9671eXjlb80slH7twBYnjALZu"},"id":"rSlycOtuuwfz","executionInfo":{"status":"ok","timestamp":1703788996087,"user_tz":-300,"elapsed":16634,"user":{"displayName":"Muhammad Mehran","userId":"12810853850038077088"}},"outputId":"64e8806b-6c1d-4ec3-fd9a-761f05e69a3c"},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["# **Visualise Image**"],"metadata":{"id":"rmKxwJM9FXX1"}},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","import os\n","\n","def visualize_images_in_folder(folder_path):\n","    # Get a list of all files in the folder\n","    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","    for image_file in image_files:\n","        # Construct the full path to the image\n","        image_path = os.path.join(folder_path, image_file)\n","\n","        # Read the image\n","        img = cv2.imread(image_path)\n","\n","        # Convert from BGR to RGB (OpenCV uses BGR by default)\n","        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","\n","        # Display the image\n","        plt.imshow(img_rgb)\n","        plt.title(image_file)  # Set the title to the image file name\n","        plt.axis('off')  # Turn off axis labels\n","        plt.show()\n","\n","# Example usage:\n","test_folder_path = '/content/gdrive/MyDrive/AIInternship/Object Detection System/PPEDETECTION.v4i.yolov8/runs/detect/predict4'\n","visualize_images_in_folder(test_folder_path)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1QvengI3YcHRH8TVEPgW3aqXz6571matU"},"id":"eJHOz1ApEAXp","outputId":"b8f2ec67-8da3-4e13-f946-0d199def0f06","executionInfo":{"status":"ok","timestamp":1703788032170,"user_tz":-300,"elapsed":132045,"user":{"displayName":"Muhammad Mehran","userId":"12810853850038077088"}}},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}